2023-09-03 22:43:02,276 - root - INFO - --------------------- Iniciando Novo Treinamento 77 ---------------------
2023-09-03 22:43:02,276 - root - INFO - Parametros
2023-09-03 22:43:02,276 - root - INFO - {'batch_size': 32,
 'dataset': 'CIFAR10',
 'epochs': 25,
 'learning_rate': 0.001,
 'network': 'VGG11',
 'num_workers': 1}
2023-09-03 22:43:02,276 - root - INFO - Construindo dataset para a rede VGG11
2023-09-03 22:43:04,155 - root - INFO - VGG11(
  (layer1): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer3): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
  )
  (layer4): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer5): Sequential(
    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
  )
  (layer6): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer7): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
  )
  (layer8): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=4096, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (fc2): Sequential(
    (0): Linear(in_features=4096, out_features=10, bias=True)
  )
)
2023-09-03 22:43:04,155 - root - INFO - Iniciando treinamento
2023-09-03 22:43:04,155 - root - INFO - Epoch 1
-------------------------------
2023-09-03 22:46:42,484 - root - INFO - Validation loss decreased from : inf ----> 2.3026444679260254 ----> Saving Model.......
2023-09-03 22:46:42,484 - root - INFO - Validation acc:  10.47
2023-09-03 22:46:42,484 - root - INFO - Best Test acc from 0 ----> 10.0
2023-09-03 22:46:42,484 - root - INFO - Época 1/25
2023-09-03 22:46:42,484 - root - INFO - loss: 2.3093157424926756 - accuracy: 9.7525 - val_loss: 2.3026444679260254 - val_accuracy: 10.47
2023-09-03 22:46:42,484 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3028629795074465
2023-09-03 22:46:42,484 - root - INFO - test acc from best model : 10.0
2023-09-03 22:46:42,484 - root - INFO - Epoch 2
-------------------------------
2023-09-03 22:50:20,396 - root - INFO - Época 2/25
2023-09-03 22:50:20,396 - root - INFO - loss: 2.30297802734375 - accuracy: 9.805 - val_loss: 2.302688109588623 - val_accuracy: 10.09
2023-09-03 22:50:20,396 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026364406585693
2023-09-03 22:50:20,396 - root - INFO - test acc from best model : 10.0
2023-09-03 22:50:20,396 - root - INFO - Epoch 3
-------------------------------
2023-09-03 22:53:58,535 - root - INFO - Época 3/25
2023-09-03 22:53:58,536 - root - INFO - loss: 2.302813818359375 - accuracy: 9.84 - val_loss: 2.30287631149292 - val_accuracy: 9.75
2023-09-03 22:53:58,536 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026703258514405
2023-09-03 22:53:58,536 - root - INFO - test acc from best model : 10.0
2023-09-03 22:53:58,536 - root - INFO - Epoch 4
-------------------------------
2023-09-03 22:57:36,891 - root - INFO - Época 4/25
2023-09-03 22:57:36,891 - root - INFO - loss: 2.302813427734375 - accuracy: 9.7425 - val_loss: 2.3026790016174314 - val_accuracy: 9.75
2023-09-03 22:57:36,891 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026097557067873
2023-09-03 22:57:36,891 - root - INFO - test acc from best model : 10.0
2023-09-03 22:57:36,891 - root - INFO - Epoch 5
-------------------------------
2023-09-03 23:01:15,745 - root - INFO - Época 5/25
2023-09-03 23:01:15,746 - root - INFO - loss: 2.30277626953125 - accuracy: 9.76 - val_loss: 2.302802946090698 - val_accuracy: 9.64
2023-09-03 23:01:15,746 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026343521118164
2023-09-03 23:01:15,746 - root - INFO - test acc from best model : 10.0
2023-09-03 23:01:15,746 - root - INFO - Epoch 6
-------------------------------
2023-09-03 23:04:54,159 - root - INFO - Época 6/25
2023-09-03 23:04:54,159 - root - INFO - loss: 2.302738134765625 - accuracy: 9.7625 - val_loss: 2.302726319885254 - val_accuracy: 9.83
2023-09-03 23:04:54,159 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302636517715454
2023-09-03 23:04:54,159 - root - INFO - test acc from best model : 10.0
2023-09-03 23:04:54,159 - root - INFO - Epoch 7
-------------------------------
2023-09-03 23:08:32,406 - root - INFO - Validation loss decreased from : 2.3026444679260254 ----> 2.302613919830322 ----> Saving Model.......
2023-09-03 23:08:32,406 - root - INFO - Validation acc:  9.950000000000001
2023-09-03 23:08:32,406 - root - INFO - Best Test acc from 10.0 ----> 10.0
2023-09-03 23:08:32,406 - root - INFO - Época 7/25
2023-09-03 23:08:32,406 - root - INFO - loss: 2.30274541015625 - accuracy: 10.0125 - val_loss: 2.302613919830322 - val_accuracy: 9.950000000000001
2023-09-03 23:08:32,406 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026099323272704
2023-09-03 23:08:32,406 - root - INFO - test acc from best model : 10.0
2023-09-03 23:08:32,406 - root - INFO - Epoch 8
-------------------------------
2023-09-03 23:12:10,596 - root - INFO - Época 8/25
2023-09-03 23:12:10,596 - root - INFO - loss: 2.302732958984375 - accuracy: 9.77 - val_loss: 2.302930744934082 - val_accuracy: 9.75
2023-09-03 23:12:10,596 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302664881896973
2023-09-03 23:12:10,596 - root - INFO - test acc from best model : 10.0
2023-09-03 23:12:10,596 - root - INFO - Epoch 9
-------------------------------
2023-09-03 23:15:48,863 - root - INFO - Época 9/25
2023-09-03 23:15:48,863 - root - INFO - loss: 2.3027927734375 - accuracy: 9.815 - val_loss: 2.3028834106445313 - val_accuracy: 9.64
2023-09-03 23:15:48,863 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302658038711548
2023-09-03 23:15:48,864 - root - INFO - test acc from best model : 10.0
2023-09-03 23:15:48,864 - root - INFO - Epoch 10
-------------------------------
2023-09-03 23:19:26,862 - root - INFO - Época 10/25
2023-09-03 23:19:26,862 - root - INFO - loss: 2.30279345703125 - accuracy: 9.83 - val_loss: 2.302749006652832 - val_accuracy: 9.64
2023-09-03 23:19:26,862 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302616502380371
2023-09-03 23:19:26,862 - root - INFO - test acc from best model : 10.0
2023-09-03 23:19:26,862 - root - INFO - Epoch 11
-------------------------------
2023-09-03 23:23:04,955 - root - INFO - Época 11/25
2023-09-03 23:23:04,955 - root - INFO - loss: 2.30278369140625 - accuracy: 9.9325 - val_loss: 2.302703465270996 - val_accuracy: 9.64
2023-09-03 23:23:04,955 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302633459472656
2023-09-03 23:23:04,955 - root - INFO - test acc from best model : 10.0
2023-09-03 23:23:04,955 - root - INFO - Epoch 12
-------------------------------
2023-09-03 23:26:43,094 - root - INFO - Época 12/25
2023-09-03 23:26:43,094 - root - INFO - loss: 2.302705029296875 - accuracy: 9.875 - val_loss: 2.302734051132202 - val_accuracy: 9.75
2023-09-03 23:26:43,094 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026612327575684
2023-09-03 23:26:43,094 - root - INFO - test acc from best model : 10.0
2023-09-03 23:26:43,094 - root - INFO - Epoch 13
-------------------------------
2023-09-03 23:30:21,419 - root - INFO - Época 13/25
2023-09-03 23:30:21,420 - root - INFO - loss: 2.30276435546875 - accuracy: 9.8925 - val_loss: 2.3028186420440675 - val_accuracy: 9.91
2023-09-03 23:30:21,420 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026734577178956
2023-09-03 23:30:21,420 - root - INFO - test acc from best model : 10.0
2023-09-03 23:30:21,420 - root - INFO - Epoch 14
-------------------------------
2023-09-03 23:33:59,850 - root - INFO - Época 14/25
2023-09-03 23:33:59,850 - root - INFO - loss: 2.302783203125 - accuracy: 9.86 - val_loss: 2.3027358993530274 - val_accuracy: 9.83
2023-09-03 23:33:59,850 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302620520019531
2023-09-03 23:33:59,850 - root - INFO - test acc from best model : 10.0
2023-09-03 23:33:59,850 - root - INFO - Epoch 15
-------------------------------
2023-09-03 23:37:37,845 - root - INFO - Época 15/25
2023-09-03 23:37:37,845 - root - INFO - loss: 2.302785009765625 - accuracy: 9.825 - val_loss: 2.3027428951263427 - val_accuracy: 10.09
2023-09-03 23:37:37,845 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026271995544434
2023-09-03 23:37:37,845 - root - INFO - test acc from best model : 10.0
2023-09-03 23:37:37,845 - root - INFO - Epoch 16
-------------------------------
2023-09-03 23:41:15,909 - root - INFO - Época 16/25
2023-09-03 23:41:15,909 - root - INFO - loss: 2.302770849609375 - accuracy: 9.9625 - val_loss: 2.302775213623047 - val_accuracy: 9.64
2023-09-03 23:41:15,909 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302649391555786
2023-09-03 23:41:15,909 - root - INFO - test acc from best model : 10.0
2023-09-03 23:41:15,909 - root - INFO - Epoch 17
-------------------------------
2023-09-03 23:44:54,373 - root - INFO - Época 17/25
2023-09-03 23:44:54,373 - root - INFO - loss: 2.3027935546875 - accuracy: 9.9875 - val_loss: 2.302716493225098 - val_accuracy: 9.64
2023-09-03 23:44:54,373 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.30261296043396
2023-09-03 23:44:54,373 - root - INFO - test acc from best model : 10.0
2023-09-03 23:44:54,373 - root - INFO - Epoch 18
-------------------------------
2023-09-03 23:48:32,774 - root - INFO - Época 18/25
2023-09-03 23:48:32,774 - root - INFO - loss: 2.302751171875 - accuracy: 9.9675 - val_loss: 2.302790467834473 - val_accuracy: 9.75
2023-09-03 23:48:32,774 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026479595184326
2023-09-03 23:48:32,774 - root - INFO - test acc from best model : 10.0
2023-09-03 23:48:32,774 - root - INFO - Epoch 19
-------------------------------
2023-09-03 23:52:11,074 - root - INFO - Época 19/25
2023-09-03 23:52:11,074 - root - INFO - loss: 2.302729638671875 - accuracy: 10.015 - val_loss: 2.3028482528686522 - val_accuracy: 9.64
2023-09-03 23:52:11,074 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026516525268557
2023-09-03 23:52:11,074 - root - INFO - test acc from best model : 10.0
2023-09-03 23:52:11,074 - root - INFO - Epoch 20
-------------------------------
2023-09-03 23:55:49,110 - root - INFO - Época 20/25
2023-09-03 23:55:49,110 - root - INFO - loss: 2.30274638671875 - accuracy: 9.9575 - val_loss: 2.3027943157196047 - val_accuracy: 9.64
2023-09-03 23:55:49,110 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302672220993042
2023-09-03 23:55:49,110 - root - INFO - test acc from best model : 10.0
2023-09-03 23:55:49,110 - root - INFO - Epoch 21
-------------------------------
2023-09-03 23:59:27,367 - root - INFO - Validation loss decreased from : 2.302613919830322 ----> 2.302602547073364 ----> Saving Model.......
2023-09-03 23:59:27,368 - root - INFO - Validation acc:  9.91
2023-09-03 23:59:27,368 - root - INFO - Best Test acc from 10.0 ----> 10.0
2023-09-03 23:59:27,368 - root - INFO - Época 21/25
2023-09-03 23:59:27,368 - root - INFO - loss: 2.302790234375 - accuracy: 9.9 - val_loss: 2.302602547073364 - val_accuracy: 9.91
2023-09-03 23:59:27,368 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302588101196289
2023-09-03 23:59:27,368 - root - INFO - test acc from best model : 10.0
2023-09-03 23:59:27,368 - root - INFO - Epoch 22
-------------------------------
2023-09-04 00:03:05,877 - root - INFO - Época 22/25
2023-09-04 00:03:05,878 - root - INFO - loss: 2.3027390625 - accuracy: 9.985 - val_loss: 2.3029100063323975 - val_accuracy: 9.75
2023-09-04 00:03:05,878 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302692002105713
2023-09-04 00:03:05,878 - root - INFO - test acc from best model : 10.0
2023-09-04 00:03:05,878 - root - INFO - Epoch 23
-------------------------------
2023-09-04 00:06:44,217 - root - INFO - Época 23/25
2023-09-04 00:06:44,217 - root - INFO - loss: 2.302778857421875 - accuracy: 9.885 - val_loss: 2.3026692268371582 - val_accuracy: 9.83
2023-09-04 00:06:44,217 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026297477722166
2023-09-04 00:06:44,217 - root - INFO - test acc from best model : 10.0
2023-09-04 00:06:44,217 - root - INFO - Epoch 24
-------------------------------
2023-09-04 00:10:22,501 - root - INFO - Época 24/25
2023-09-04 00:10:22,501 - root - INFO - loss: 2.302788916015625 - accuracy: 9.6225 - val_loss: 2.302725630569458 - val_accuracy: 9.64
2023-09-04 00:10:22,501 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026306468963624
2023-09-04 00:10:22,501 - root - INFO - test acc from best model : 10.0
2023-09-04 00:10:22,501 - root - INFO - Epoch 25
-------------------------------
2023-09-04 00:14:01,217 - root - INFO - Época 25/25
2023-09-04 00:14:01,217 - root - INFO - loss: 2.302776806640625 - accuracy: 9.865 - val_loss: 2.3028374938964844 - val_accuracy: 9.75
2023-09-04 00:14:01,217 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026333114624022
2023-09-04 00:14:01,217 - root - INFO - test acc from best model : 10.0
2023-09-04 00:14:01,217 - root - INFO - Tempo treinamento:  5457.06 seconds
2023-09-04 00:14:01,217 - root - INFO - Menor loss: 2.302602547073364
2023-09-04 00:14:01,217 - root - INFO - Acurácia de teste do melhor modelo: 10.0
2023-09-04 00:14:01,217 - root - INFO - Métricas
2023-09-04 00:14:01,217 - root - INFO - ACC
2023-09-04 00:14:01,217 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25],
 'test_acc': [10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0],
 'train_acc': [9.7525,
               9.805,
               9.84,
               9.7425,
               9.76,
               9.7625,
               10.0125,
               9.77,
               9.815,
               9.83,
               9.9325,
               9.875,
               9.8925,
               9.86,
               9.825,
               9.9625,
               9.9875,
               9.9675,
               10.015,
               9.9575,
               9.9,
               9.985,
               9.885,
               9.6225,
               9.865],
 'val_acc': [10.47,
             10.09,
             9.75,
             9.75,
             9.64,
             9.83,
             9.950000000000001,
             9.75,
             9.64,
             9.64,
             9.64,
             9.75,
             9.91,
             9.83,
             10.09,
             9.64,
             9.64,
             9.75,
             9.64,
             9.64,
             9.91,
             9.75,
             9.83,
             9.64,
             9.75]}
2023-09-04 00:14:01,217 - root - INFO - LOSS
2023-09-04 00:14:01,217 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25],
 'test_loss': [2.3028629795074465,
               2.3026364406585693,
               2.3026703258514405,
               2.3026097557067873,
               2.3026343521118164,
               2.302636517715454,
               2.3026099323272704,
               2.302664881896973,
               2.302658038711548,
               2.302616502380371,
               2.302633459472656,
               2.3026612327575684,
               2.3026734577178956,
               2.302620520019531,
               2.3026271995544434,
               2.302649391555786,
               2.30261296043396,
               2.3026479595184326,
               2.3026516525268557,
               2.302672220993042,
               2.302588101196289,
               2.302692002105713,
               2.3026297477722166,
               2.3026306468963624,
               2.3026333114624022],
 'train_loss': [2.3093157424926756,
                2.30297802734375,
                2.302813818359375,
                2.302813427734375,
                2.30277626953125,
                2.302738134765625,
                2.30274541015625,
                2.302732958984375,
                2.3027927734375,
                2.30279345703125,
                2.30278369140625,
                2.302705029296875,
                2.30276435546875,
                2.302783203125,
                2.302785009765625,
                2.302770849609375,
                2.3027935546875,
                2.302751171875,
                2.302729638671875,
                2.30274638671875,
                2.302790234375,
                2.3027390625,
                2.302778857421875,
                2.302788916015625,
                2.302776806640625],
 'val_loss': [2.3026444679260254,
              2.302688109588623,
              2.30287631149292,
              2.3026790016174314,
              2.302802946090698,
              2.302726319885254,
              2.302613919830322,
              2.302930744934082,
              2.3028834106445313,
              2.302749006652832,
              2.302703465270996,
              2.302734051132202,
              2.3028186420440675,
              2.3027358993530274,
              2.3027428951263427,
              2.302775213623047,
              2.302716493225098,
              2.302790467834473,
              2.3028482528686522,
              2.3027943157196047,
              2.302602547073364,
              2.3029100063323975,
              2.3026692268371582,
              2.302725630569458,
              2.3028374938964844]}
