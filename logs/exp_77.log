2023-09-03 22:43:02,276 - root - INFO - --------------------- Iniciando Novo Treinamento 77 ---------------------
2023-09-03 22:43:02,276 - root - INFO - Parametros
2023-09-03 22:43:02,276 - root - INFO - {'batch_size': 32,
 'dataset': 'CIFAR10',
 'epochs': 25,
 'learning_rate': 0.001,
 'network': 'VGG11',
 'num_workers': 1}
2023-09-03 22:43:02,276 - root - INFO - Construindo dataset para a rede VGG11
2023-09-03 22:43:04,155 - root - INFO - VGG11(
  (layer1): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer3): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
  )
  (layer4): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer5): Sequential(
    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
  )
  (layer6): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer7): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
  )
  (layer8): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=4096, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (fc2): Sequential(
    (0): Linear(in_features=4096, out_features=10, bias=True)
  )
)
2023-09-03 22:43:04,155 - root - INFO - Iniciando treinamento
2023-09-03 22:43:04,155 - root - INFO - Epoch 1
-------------------------------
2023-09-03 22:46:42,484 - root - INFO - Validation loss decreased from : inf ----> 2.3026444679260254 ----> Saving Model.......
2023-09-03 22:46:42,484 - root - INFO - Validation acc:  10.47
2023-09-03 22:46:42,484 - root - INFO - Best Test acc from 0 ----> 10.0
2023-09-03 22:46:42,484 - root - INFO - Época 1/25
2023-09-03 22:46:42,484 - root - INFO - loss: 2.3093157424926756 - accuracy: 9.7525 - val_loss: 2.3026444679260254 - val_accuracy: 10.47
2023-09-03 22:46:42,484 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3028629795074465
2023-09-03 22:46:42,484 - root - INFO - test acc from best model : 10.0
2023-09-03 22:46:42,484 - root - INFO - Epoch 2
-------------------------------
2023-09-03 22:50:20,396 - root - INFO - Época 2/25
2023-09-03 22:50:20,396 - root - INFO - loss: 2.30297802734375 - accuracy: 9.805 - val_loss: 2.302688109588623 - val_accuracy: 10.09
2023-09-03 22:50:20,396 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026364406585693
2023-09-03 22:50:20,396 - root - INFO - test acc from best model : 10.0
2023-09-03 22:50:20,396 - root - INFO - Epoch 3
-------------------------------
2023-09-03 22:53:58,535 - root - INFO - Época 3/25
2023-09-03 22:53:58,536 - root - INFO - loss: 2.302813818359375 - accuracy: 9.84 - val_loss: 2.30287631149292 - val_accuracy: 9.75
2023-09-03 22:53:58,536 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026703258514405
2023-09-03 22:53:58,536 - root - INFO - test acc from best model : 10.0
2023-09-03 22:53:58,536 - root - INFO - Epoch 4
-------------------------------
2023-09-03 22:57:36,891 - root - INFO - Época 4/25
2023-09-03 22:57:36,891 - root - INFO - loss: 2.302813427734375 - accuracy: 9.7425 - val_loss: 2.3026790016174314 - val_accuracy: 9.75
2023-09-03 22:57:36,891 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026097557067873
2023-09-03 22:57:36,891 - root - INFO - test acc from best model : 10.0
2023-09-03 22:57:36,891 - root - INFO - Epoch 5
-------------------------------
2023-09-03 23:01:15,745 - root - INFO - Época 5/25
2023-09-03 23:01:15,746 - root - INFO - loss: 2.30277626953125 - accuracy: 9.76 - val_loss: 2.302802946090698 - val_accuracy: 9.64
2023-09-03 23:01:15,746 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026343521118164
2023-09-03 23:01:15,746 - root - INFO - test acc from best model : 10.0
2023-09-03 23:01:15,746 - root - INFO - Epoch 6
-------------------------------
2023-09-03 23:04:54,159 - root - INFO - Época 6/25
2023-09-03 23:04:54,159 - root - INFO - loss: 2.302738134765625 - accuracy: 9.7625 - val_loss: 2.302726319885254 - val_accuracy: 9.83
2023-09-03 23:04:54,159 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302636517715454
2023-09-03 23:04:54,159 - root - INFO - test acc from best model : 10.0
2023-09-03 23:04:54,159 - root - INFO - Epoch 7
-------------------------------
2023-09-03 23:08:32,406 - root - INFO - Validation loss decreased from : 2.3026444679260254 ----> 2.302613919830322 ----> Saving Model.......
2023-09-03 23:08:32,406 - root - INFO - Validation acc:  9.950000000000001
2023-09-03 23:08:32,406 - root - INFO - Best Test acc from 10.0 ----> 10.0
2023-09-03 23:08:32,406 - root - INFO - Época 7/25
2023-09-03 23:08:32,406 - root - INFO - loss: 2.30274541015625 - accuracy: 10.0125 - val_loss: 2.302613919830322 - val_accuracy: 9.950000000000001
2023-09-03 23:08:32,406 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026099323272704
2023-09-03 23:08:32,406 - root - INFO - test acc from best model : 10.0
2023-09-03 23:08:32,406 - root - INFO - Epoch 8
-------------------------------
2023-09-03 23:12:10,596 - root - INFO - Época 8/25
2023-09-03 23:12:10,596 - root - INFO - loss: 2.302732958984375 - accuracy: 9.77 - val_loss: 2.302930744934082 - val_accuracy: 9.75
2023-09-03 23:12:10,596 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302664881896973
2023-09-03 23:12:10,596 - root - INFO - test acc from best model : 10.0
2023-09-03 23:12:10,596 - root - INFO - Epoch 9
-------------------------------
2023-09-03 23:15:48,863 - root - INFO - Época 9/25
2023-09-03 23:15:48,863 - root - INFO - loss: 2.3027927734375 - accuracy: 9.815 - val_loss: 2.3028834106445313 - val_accuracy: 9.64
2023-09-03 23:15:48,863 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302658038711548
2023-09-03 23:15:48,864 - root - INFO - test acc from best model : 10.0
2023-09-03 23:15:48,864 - root - INFO - Epoch 10
-------------------------------
2023-09-03 23:19:26,862 - root - INFO - Época 10/25
2023-09-03 23:19:26,862 - root - INFO - loss: 2.30279345703125 - accuracy: 9.83 - val_loss: 2.302749006652832 - val_accuracy: 9.64
2023-09-03 23:19:26,862 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302616502380371
2023-09-03 23:19:26,862 - root - INFO - test acc from best model : 10.0
2023-09-03 23:19:26,862 - root - INFO - Epoch 11
-------------------------------
2023-09-03 23:23:04,955 - root - INFO - Época 11/25
2023-09-03 23:23:04,955 - root - INFO - loss: 2.30278369140625 - accuracy: 9.9325 - val_loss: 2.302703465270996 - val_accuracy: 9.64
2023-09-03 23:23:04,955 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302633459472656
2023-09-03 23:23:04,955 - root - INFO - test acc from best model : 10.0
2023-09-03 23:23:04,955 - root - INFO - Epoch 12
-------------------------------
2023-09-03 23:26:43,094 - root - INFO - Época 12/25
2023-09-03 23:26:43,094 - root - INFO - loss: 2.302705029296875 - accuracy: 9.875 - val_loss: 2.302734051132202 - val_accuracy: 9.75
2023-09-03 23:26:43,094 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026612327575684
2023-09-03 23:26:43,094 - root - INFO - test acc from best model : 10.0
2023-09-03 23:26:43,094 - root - INFO - Epoch 13
-------------------------------
2023-09-03 23:30:21,419 - root - INFO - Época 13/25
2023-09-03 23:30:21,420 - root - INFO - loss: 2.30276435546875 - accuracy: 9.8925 - val_loss: 2.3028186420440675 - val_accuracy: 9.91
2023-09-03 23:30:21,420 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026734577178956
2023-09-03 23:30:21,420 - root - INFO - test acc from best model : 10.0
2023-09-03 23:30:21,420 - root - INFO - Epoch 14
-------------------------------
2023-09-03 23:33:59,850 - root - INFO - Época 14/25
2023-09-03 23:33:59,850 - root - INFO - loss: 2.302783203125 - accuracy: 9.86 - val_loss: 2.3027358993530274 - val_accuracy: 9.83
2023-09-03 23:33:59,850 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302620520019531
2023-09-03 23:33:59,850 - root - INFO - test acc from best model : 10.0
2023-09-03 23:33:59,850 - root - INFO - Epoch 15
-------------------------------
2023-09-03 23:37:37,845 - root - INFO - Época 15/25
2023-09-03 23:37:37,845 - root - INFO - loss: 2.302785009765625 - accuracy: 9.825 - val_loss: 2.3027428951263427 - val_accuracy: 10.09
2023-09-03 23:37:37,845 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026271995544434
2023-09-03 23:37:37,845 - root - INFO - test acc from best model : 10.0
2023-09-03 23:37:37,845 - root - INFO - Epoch 16
-------------------------------
2023-09-03 23:41:15,909 - root - INFO - Época 16/25
2023-09-03 23:41:15,909 - root - INFO - loss: 2.302770849609375 - accuracy: 9.9625 - val_loss: 2.302775213623047 - val_accuracy: 9.64
2023-09-03 23:41:15,909 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302649391555786
2023-09-03 23:41:15,909 - root - INFO - test acc from best model : 10.0
2023-09-03 23:41:15,909 - root - INFO - Epoch 17
-------------------------------
2023-09-03 23:44:54,373 - root - INFO - Época 17/25
2023-09-03 23:44:54,373 - root - INFO - loss: 2.3027935546875 - accuracy: 9.9875 - val_loss: 2.302716493225098 - val_accuracy: 9.64
2023-09-03 23:44:54,373 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.30261296043396
2023-09-03 23:44:54,373 - root - INFO - test acc from best model : 10.0
2023-09-03 23:44:54,373 - root - INFO - Epoch 18
-------------------------------
2023-09-03 23:48:32,774 - root - INFO - Época 18/25
2023-09-03 23:48:32,774 - root - INFO - loss: 2.302751171875 - accuracy: 9.9675 - val_loss: 2.302790467834473 - val_accuracy: 9.75
2023-09-03 23:48:32,774 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026479595184326
2023-09-03 23:48:32,774 - root - INFO - test acc from best model : 10.0
2023-09-03 23:48:32,774 - root - INFO - Epoch 19
-------------------------------
2023-09-03 23:52:11,074 - root - INFO - Época 19/25
2023-09-03 23:52:11,074 - root - INFO - loss: 2.302729638671875 - accuracy: 10.015 - val_loss: 2.3028482528686522 - val_accuracy: 9.64
2023-09-03 23:52:11,074 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026516525268557
2023-09-03 23:52:11,074 - root - INFO - test acc from best model : 10.0
2023-09-03 23:52:11,074 - root - INFO - Epoch 20
-------------------------------
2023-09-03 23:55:49,110 - root - INFO - Época 20/25
2023-09-03 23:55:49,110 - root - INFO - loss: 2.30274638671875 - accuracy: 9.9575 - val_loss: 2.3027943157196047 - val_accuracy: 9.64
2023-09-03 23:55:49,110 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302672220993042
2023-09-03 23:55:49,110 - root - INFO - test acc from best model : 10.0
2023-09-03 23:55:49,110 - root - INFO - Epoch 21
-------------------------------
2023-09-03 23:59:27,367 - root - INFO - Validation loss decreased from : 2.302613919830322 ----> 2.302602547073364 ----> Saving Model.......
2023-09-03 23:59:27,368 - root - INFO - Validation acc:  9.91
2023-09-03 23:59:27,368 - root - INFO - Best Test acc from 10.0 ----> 10.0
2023-09-03 23:59:27,368 - root - INFO - Época 21/25
2023-09-03 23:59:27,368 - root - INFO - loss: 2.302790234375 - accuracy: 9.9 - val_loss: 2.302602547073364 - val_accuracy: 9.91
2023-09-03 23:59:27,368 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302588101196289
2023-09-03 23:59:27,368 - root - INFO - test acc from best model : 10.0
2023-09-03 23:59:27,368 - root - INFO - Epoch 22
-------------------------------
2023-09-04 00:03:05,877 - root - INFO - Época 22/25
2023-09-04 00:03:05,878 - root - INFO - loss: 2.3027390625 - accuracy: 9.985 - val_loss: 2.3029100063323975 - val_accuracy: 9.75
2023-09-04 00:03:05,878 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.302692002105713
2023-09-04 00:03:05,878 - root - INFO - test acc from best model : 10.0
2023-09-04 00:03:05,878 - root - INFO - Epoch 23
-------------------------------
2023-09-04 00:06:44,217 - root - INFO - Época 23/25
2023-09-04 00:06:44,217 - root - INFO - loss: 2.302778857421875 - accuracy: 9.885 - val_loss: 2.3026692268371582 - val_accuracy: 9.83
2023-09-04 00:06:44,217 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026297477722166
2023-09-04 00:06:44,217 - root - INFO - test acc from best model : 10.0
2023-09-04 00:06:44,217 - root - INFO - Epoch 24
-------------------------------
2023-09-04 00:10:22,501 - root - INFO - Época 24/25
2023-09-04 00:10:22,501 - root - INFO - loss: 2.302788916015625 - accuracy: 9.6225 - val_loss: 2.302725630569458 - val_accuracy: 9.64
2023-09-04 00:10:22,501 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026306468963624
2023-09-04 00:10:22,501 - root - INFO - test acc from best model : 10.0
2023-09-04 00:10:22,501 - root - INFO - Epoch 25
-------------------------------
2023-09-04 00:14:01,217 - root - INFO - Época 25/25
2023-09-04 00:14:01,217 - root - INFO - loss: 2.302776806640625 - accuracy: 9.865 - val_loss: 2.3028374938964844 - val_accuracy: 9.75
2023-09-04 00:14:01,217 - root - INFO - [Test] ---> accuracy: 10.0 - loss: 2.3026333114624022
2023-09-04 00:14:01,217 - root - INFO - test acc from best model : 10.0
2023-09-04 00:14:01,217 - root - INFO - Tempo treinamento:  5457.06 seconds
2023-09-04 00:14:01,217 - root - INFO - Menor loss: 2.302602547073364
2023-09-04 00:14:01,217 - root - INFO - Acurácia de teste do melhor modelo: 10.0
2023-09-04 00:14:01,217 - root - INFO - Métricas
2023-09-04 00:14:01,217 - root - INFO - ACC
2023-09-04 00:14:01,217 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25],
 'test_acc': [10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0,
              10.0],
 'train_acc': [9.7525,
               9.805,
               9.84,
               9.7425,
               9.76,
               9.7625,
               10.0125,
               9.77,
               9.815,
               9.83,
               9.9325,
               9.875,
               9.8925,
               9.86,
               9.825,
               9.9625,
               9.9875,
               9.9675,
               10.015,
               9.9575,
               9.9,
               9.985,
               9.885,
               9.6225,
               9.865],
 'val_acc': [10.47,
             10.09,
             9.75,
             9.75,
             9.64,
             9.83,
             9.950000000000001,
             9.75,
             9.64,
             9.64,
             9.64,
             9.75,
             9.91,
             9.83,
             10.09,
             9.64,
             9.64,
             9.75,
             9.64,
             9.64,
             9.91,
             9.75,
             9.83,
             9.64,
             9.75]}
2023-09-04 00:14:01,217 - root - INFO - LOSS
2023-09-04 00:14:01,217 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25],
 'test_loss': [2.3028629795074465,
               2.3026364406585693,
               2.3026703258514405,
               2.3026097557067873,
               2.3026343521118164,
               2.302636517715454,
               2.3026099323272704,
               2.302664881896973,
               2.302658038711548,
               2.302616502380371,
               2.302633459472656,
               2.3026612327575684,
               2.3026734577178956,
               2.302620520019531,
               2.3026271995544434,
               2.302649391555786,
               2.30261296043396,
               2.3026479595184326,
               2.3026516525268557,
               2.302672220993042,
               2.302588101196289,
               2.302692002105713,
               2.3026297477722166,
               2.3026306468963624,
               2.3026333114624022],
 'train_loss': [2.3093157424926756,
                2.30297802734375,
                2.302813818359375,
                2.302813427734375,
                2.30277626953125,
                2.302738134765625,
                2.30274541015625,
                2.302732958984375,
                2.3027927734375,
                2.30279345703125,
                2.30278369140625,
                2.302705029296875,
                2.30276435546875,
                2.302783203125,
                2.302785009765625,
                2.302770849609375,
                2.3027935546875,
                2.302751171875,
                2.302729638671875,
                2.30274638671875,
                2.302790234375,
                2.3027390625,
                2.302778857421875,
                2.302788916015625,
                2.302776806640625],
 'val_loss': [2.3026444679260254,
              2.302688109588623,
              2.30287631149292,
              2.3026790016174314,
              2.302802946090698,
              2.302726319885254,
              2.302613919830322,
              2.302930744934082,
              2.3028834106445313,
              2.302749006652832,
              2.302703465270996,
              2.302734051132202,
              2.3028186420440675,
              2.3027358993530274,
              2.3027428951263427,
              2.302775213623047,
              2.302716493225098,
              2.302790467834473,
              2.3028482528686522,
              2.3027943157196047,
              2.302602547073364,
              2.3029100063323975,
              2.3026692268371582,
              2.302725630569458,
              2.3028374938964844]}
2023-09-04 04:30:48,810 - root - INFO - --------------------- Iniciando Novo Treinamento 77 ---------------------
2023-09-04 04:30:48,810 - root - INFO - Parametros
2023-09-04 04:30:48,810 - root - INFO - {'batch_size': 32,
 'dataset': 'CIFAR10',
 'epochs': 25,
 'learning_rate': 0.0001,
 'network': 'VGG11',
 'num_workers': 1}
2023-09-04 04:30:48,810 - root - INFO - Construindo dataset para a rede VGG11
2023-09-04 04:30:50,691 - root - INFO - VGG11(
  (layer1): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer3): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
  )
  (layer4): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer5): Sequential(
    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
  )
  (layer6): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer7): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
  )
  (layer8): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=4096, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (fc2): Sequential(
    (0): Linear(in_features=4096, out_features=10, bias=True)
  )
)
2023-09-04 04:30:50,692 - root - INFO - Iniciando treinamento
2023-09-04 04:30:50,692 - root - INFO - Epoch 1
-------------------------------
2023-09-04 04:34:26,933 - root - INFO - Validation loss decreased from : inf ----> 1.3443198501586915 ----> Saving Model.......
2023-09-04 04:34:26,933 - root - INFO - Validation acc:  52.87
2023-09-04 04:34:26,933 - root - INFO - Best Test acc from 0 ----> 53.269999999999996
2023-09-04 04:34:26,933 - root - INFO - Época 1/25
2023-09-04 04:34:26,933 - root - INFO - loss: 1.810281413078308 - accuracy: 33.23 - val_loss: 1.3443198501586915 - val_accuracy: 52.87
2023-09-04 04:34:26,933 - root - INFO - [Test] ---> accuracy: 53.269999999999996 - loss: 1.3456522954940795
2023-09-04 04:34:26,933 - root - INFO - test acc from best model : 53.269999999999996
2023-09-04 04:34:26,934 - root - INFO - Epoch 2
-------------------------------
2023-09-04 04:38:03,268 - root - INFO - Validation loss decreased from : 1.3443198501586915 ----> 0.9952601190567016 ----> Saving Model.......
2023-09-04 04:38:03,268 - root - INFO - Validation acc:  65.08
2023-09-04 04:38:03,268 - root - INFO - Best Test acc from 53.269999999999996 ----> 65.96
2023-09-04 04:38:03,268 - root - INFO - Época 2/25
2023-09-04 04:38:03,268 - root - INFO - loss: 1.1795919346809387 - accuracy: 58.3675 - val_loss: 0.9952601190567016 - val_accuracy: 65.08
2023-09-04 04:38:03,268 - root - INFO - [Test] ---> accuracy: 65.96 - loss: 0.9986505857467651
2023-09-04 04:38:03,268 - root - INFO - test acc from best model : 65.96
2023-09-04 04:38:03,268 - root - INFO - Epoch 3
-------------------------------
2023-09-04 04:41:38,956 - root - INFO - Validation loss decreased from : 0.9952601190567016 ----> 0.8585382937431335 ----> Saving Model.......
2023-09-04 04:41:38,957 - root - INFO - Validation acc:  70.78
2023-09-04 04:41:38,957 - root - INFO - Best Test acc from 65.96 ----> 70.04
2023-09-04 04:41:38,957 - root - INFO - Época 3/25
2023-09-04 04:41:38,957 - root - INFO - loss: 0.8430515431642532 - accuracy: 71.0325 - val_loss: 0.8585382937431335 - val_accuracy: 70.78
2023-09-04 04:41:38,957 - root - INFO - [Test] ---> accuracy: 70.04 - loss: 0.8736262948036194
2023-09-04 04:41:38,957 - root - INFO - test acc from best model : 70.04
2023-09-04 04:41:38,957 - root - INFO - Epoch 4
-------------------------------
2023-09-04 04:45:14,882 - root - INFO - Validation loss decreased from : 0.8585382937431335 ----> 0.8027504696846008 ----> Saving Model.......
2023-09-04 04:45:14,882 - root - INFO - Validation acc:  73.46000000000001
2023-09-04 04:45:14,882 - root - INFO - Best Test acc from 70.04 ----> 73.08
2023-09-04 04:45:14,882 - root - INFO - Época 4/25
2023-09-04 04:45:14,882 - root - INFO - loss: 0.5962290066957474 - accuracy: 79.3825 - val_loss: 0.8027504696846008 - val_accuracy: 73.46000000000001
2023-09-04 04:45:14,882 - root - INFO - [Test] ---> accuracy: 73.08 - loss: 0.8183080505371094
2023-09-04 04:45:14,882 - root - INFO - test acc from best model : 73.08
2023-09-04 04:45:14,882 - root - INFO - Epoch 5
-------------------------------
2023-09-04 04:48:50,931 - root - INFO - Época 5/25
2023-09-04 04:48:50,931 - root - INFO - loss: 0.3589143226593733 - accuracy: 87.69 - val_loss: 0.8078969767570495 - val_accuracy: 74.91
2023-09-04 04:48:50,931 - root - INFO - [Test] ---> accuracy: 73.98 - loss: 0.8312844655036926
2023-09-04 04:48:50,931 - root - INFO - test acc from best model : 73.08
2023-09-04 04:48:50,931 - root - INFO - Epoch 6
-------------------------------
2023-09-04 04:52:26,820 - root - INFO - Época 6/25
2023-09-04 04:52:26,820 - root - INFO - loss: 0.18867726397812368 - accuracy: 93.595 - val_loss: 1.0081819412231445 - val_accuracy: 73.92
2023-09-04 04:52:26,820 - root - INFO - [Test] ---> accuracy: 74.11999999999999 - loss: 1.0231133766174316
2023-09-04 04:52:26,820 - root - INFO - test acc from best model : 73.08
2023-09-04 04:52:26,820 - root - INFO - Epoch 7
-------------------------------
2023-09-04 04:56:03,232 - root - INFO - Época 7/25
2023-09-04 04:56:03,232 - root - INFO - loss: 0.11601978771686554 - accuracy: 96.1825 - val_loss: 1.0601330603122712 - val_accuracy: 73.5
2023-09-04 04:56:03,232 - root - INFO - [Test] ---> accuracy: 73.04 - loss: 1.0935970323562623
2023-09-04 04:56:03,232 - root - INFO - test acc from best model : 73.08
2023-09-04 04:56:03,232 - root - INFO - Epoch 8
-------------------------------
2023-09-04 04:59:39,567 - root - INFO - Época 8/25
2023-09-04 04:59:39,567 - root - INFO - loss: 0.09294995424449444 - accuracy: 96.96 - val_loss: 1.17068807554245 - val_accuracy: 74.33
2023-09-04 04:59:39,567 - root - INFO - [Test] ---> accuracy: 73.85000000000001 - loss: 1.1955453343868256
2023-09-04 04:59:39,567 - root - INFO - test acc from best model : 73.08
2023-09-04 04:59:39,567 - root - INFO - Epoch 9
-------------------------------
2023-09-04 05:03:15,991 - root - INFO - Época 9/25
2023-09-04 05:03:15,991 - root - INFO - loss: 0.0758436085999012 - accuracy: 97.5675 - val_loss: 1.209551497745514 - val_accuracy: 74.49
2023-09-04 05:03:15,991 - root - INFO - [Test] ---> accuracy: 73.85000000000001 - loss: 1.242265368461609
2023-09-04 05:03:15,992 - root - INFO - test acc from best model : 73.08
2023-09-04 05:03:15,992 - root - INFO - Epoch 10
-------------------------------
2023-09-04 05:06:52,282 - root - INFO - Época 10/25
2023-09-04 05:06:52,282 - root - INFO - loss: 0.06069359790980816 - accuracy: 98.0625 - val_loss: 1.2849484449863433 - val_accuracy: 74.83
2023-09-04 05:06:52,282 - root - INFO - [Test] ---> accuracy: 74.35000000000001 - loss: 1.3118879122257232
2023-09-04 05:06:52,282 - root - INFO - test acc from best model : 73.08
2023-09-04 05:06:52,282 - root - INFO - Epoch 11
-------------------------------
2023-09-04 05:10:28,467 - root - INFO - Época 11/25
2023-09-04 05:10:28,467 - root - INFO - loss: 0.05860068426728249 - accuracy: 98.085 - val_loss: 1.2624981471061707 - val_accuracy: 73.45
2023-09-04 05:10:28,467 - root - INFO - [Test] ---> accuracy: 73.92999999999999 - loss: 1.2825474133968353
2023-09-04 05:10:28,467 - root - INFO - test acc from best model : 73.08
2023-09-04 05:10:28,467 - root - INFO - Epoch 12
-------------------------------
2023-09-04 05:14:04,879 - root - INFO - Época 12/25
2023-09-04 05:14:04,879 - root - INFO - loss: 0.0520585989356041 - accuracy: 98.34 - val_loss: 1.4298467157363892 - val_accuracy: 74.63
2023-09-04 05:14:04,879 - root - INFO - [Test] ---> accuracy: 73.97 - loss: 1.4775114540576935
2023-09-04 05:14:04,879 - root - INFO - test acc from best model : 73.08
2023-09-04 05:14:04,879 - root - INFO - Epoch 13
-------------------------------
2023-09-04 05:17:41,049 - root - INFO - Época 13/25
2023-09-04 05:17:41,049 - root - INFO - loss: 0.04971355749964714 - accuracy: 98.39 - val_loss: 1.4023285331249238 - val_accuracy: 74.67
2023-09-04 05:17:41,049 - root - INFO - [Test] ---> accuracy: 74.62 - loss: 1.4077505491256714
2023-09-04 05:17:41,049 - root - INFO - test acc from best model : 73.08
2023-09-04 05:17:41,049 - root - INFO - Epoch 14
-------------------------------
2023-09-04 05:21:16,788 - root - INFO - Época 14/25
2023-09-04 05:21:16,788 - root - INFO - loss: 0.041997481283545496 - accuracy: 98.69 - val_loss: 1.37358073925972 - val_accuracy: 74.15
2023-09-04 05:21:16,788 - root - INFO - [Test] ---> accuracy: 73.63 - loss: 1.4167679096221923
2023-09-04 05:21:16,788 - root - INFO - test acc from best model : 73.08
2023-09-04 05:21:16,788 - root - INFO - Epoch 15
-------------------------------
2023-09-04 05:24:52,931 - root - INFO - Época 15/25
2023-09-04 05:24:52,931 - root - INFO - loss: 0.04306897040009498 - accuracy: 98.55 - val_loss: 1.2803501502513885 - val_accuracy: 74.92999999999999
2023-09-04 05:24:52,931 - root - INFO - [Test] ---> accuracy: 74.4 - loss: 1.3262833790779114
2023-09-04 05:24:52,931 - root - INFO - test acc from best model : 73.08
2023-09-04 05:24:52,931 - root - INFO - Epoch 16
-------------------------------
2023-09-04 05:28:28,843 - root - INFO - Época 16/25
2023-09-04 05:28:28,843 - root - INFO - loss: 0.04119207317531109 - accuracy: 98.76 - val_loss: 1.2748819034576415 - val_accuracy: 74.89
2023-09-04 05:28:28,843 - root - INFO - [Test] ---> accuracy: 74.25 - loss: 1.3012363557815552
2023-09-04 05:28:28,843 - root - INFO - test acc from best model : 73.08
2023-09-04 05:28:28,843 - root - INFO - Epoch 17
-------------------------------
2023-09-04 05:32:04,982 - root - INFO - Época 17/25
2023-09-04 05:32:04,982 - root - INFO - loss: 0.03368082382380962 - accuracy: 98.955 - val_loss: 1.4303215028762817 - val_accuracy: 74.97
2023-09-04 05:32:04,982 - root - INFO - [Test] ---> accuracy: 74.35000000000001 - loss: 1.4865299225330353
2023-09-04 05:32:04,982 - root - INFO - test acc from best model : 73.08
2023-09-04 05:32:04,982 - root - INFO - Epoch 18
-------------------------------
2023-09-04 05:35:41,302 - root - INFO - Época 18/25
2023-09-04 05:35:41,302 - root - INFO - loss: 0.035740999555587766 - accuracy: 98.7825 - val_loss: 1.2444719638347626 - val_accuracy: 75.5
2023-09-04 05:35:41,302 - root - INFO - [Test] ---> accuracy: 75.14999999999999 - loss: 1.2668718446731568
2023-09-04 05:35:41,302 - root - INFO - test acc from best model : 73.08
2023-09-04 05:35:41,302 - root - INFO - Epoch 19
-------------------------------
2023-09-04 05:39:17,551 - root - INFO - Época 19/25
2023-09-04 05:39:17,551 - root - INFO - loss: 0.032054449352622034 - accuracy: 98.95 - val_loss: 1.427960056591034 - val_accuracy: 74.55000000000001
2023-09-04 05:39:17,552 - root - INFO - [Test] ---> accuracy: 74.72 - loss: 1.4652208700180054
2023-09-04 05:39:17,552 - root - INFO - test acc from best model : 73.08
2023-09-04 05:39:17,552 - root - INFO - Epoch 20
-------------------------------
2023-09-04 05:42:53,669 - root - INFO - Época 20/25
2023-09-04 05:42:53,669 - root - INFO - loss: 0.03131115039885044 - accuracy: 98.96 - val_loss: 1.2417808206796646 - val_accuracy: 74.92
2023-09-04 05:42:53,669 - root - INFO - [Test] ---> accuracy: 74.44 - loss: 1.293877610874176
2023-09-04 05:42:53,669 - root - INFO - test acc from best model : 73.08
2023-09-04 05:42:53,669 - root - INFO - Epoch 21
-------------------------------
2023-09-04 05:46:30,166 - root - INFO - Época 21/25
2023-09-04 05:46:30,166 - root - INFO - loss: 0.027351805508136748 - accuracy: 99.0725 - val_loss: 1.8398339270353317 - val_accuracy: 73.05
2023-09-04 05:46:30,166 - root - INFO - [Test] ---> accuracy: 72.78999999999999 - loss: 1.8568986666679381
2023-09-04 05:46:30,166 - root - INFO - test acc from best model : 73.08
2023-09-04 05:46:30,166 - root - INFO - Epoch 22
-------------------------------
2023-09-04 05:50:06,344 - root - INFO - Época 22/25
2023-09-04 05:50:06,344 - root - INFO - loss: 0.0274141229480505 - accuracy: 99.1375 - val_loss: 1.4679156264781952 - val_accuracy: 75.22
2023-09-04 05:50:06,344 - root - INFO - [Test] ---> accuracy: 74.83 - loss: 1.5086303454875947
2023-09-04 05:50:06,344 - root - INFO - test acc from best model : 73.08
2023-09-04 05:50:06,344 - root - INFO - Epoch 23
-------------------------------
2023-09-04 05:53:42,071 - root - INFO - Época 23/25
2023-09-04 05:53:42,072 - root - INFO - loss: 0.024347113594412804 - accuracy: 99.2275 - val_loss: 1.4326426353454589 - val_accuracy: 75.14999999999999
2023-09-04 05:53:42,072 - root - INFO - [Test] ---> accuracy: 74.11 - loss: 1.493360187625885
2023-09-04 05:53:42,072 - root - INFO - test acc from best model : 73.08
2023-09-04 05:53:42,072 - root - INFO - Epoch 24
-------------------------------
2023-09-04 05:57:18,277 - root - INFO - Época 24/25
2023-09-04 05:57:18,277 - root - INFO - loss: 0.026225077709555625 - accuracy: 99.155 - val_loss: 1.571057488965988 - val_accuracy: 74.46000000000001
2023-09-04 05:57:18,277 - root - INFO - [Test] ---> accuracy: 74.39 - loss: 1.6039673003196717
2023-09-04 05:57:18,277 - root - INFO - test acc from best model : 73.08
2023-09-04 05:57:18,277 - root - INFO - Epoch 25
-------------------------------
2023-09-04 06:00:54,314 - root - INFO - Época 25/25
2023-09-04 06:00:54,314 - root - INFO - loss: 0.025746935245394707 - accuracy: 99.2025 - val_loss: 1.3636099130630492 - val_accuracy: 75.07000000000001
2023-09-04 06:00:54,314 - root - INFO - [Test] ---> accuracy: 74.11 - loss: 1.3809185701847075
2023-09-04 06:00:54,314 - root - INFO - test acc from best model : 73.08
2023-09-04 06:00:54,314 - root - INFO - Tempo treinamento:  5403.62 seconds
2023-09-04 06:00:54,314 - root - INFO - Menor loss: 0.8027504696846008
2023-09-04 06:00:54,314 - root - INFO - Acurácia de teste do melhor modelo: 73.08
2023-09-04 06:00:54,314 - root - INFO - Métricas
2023-09-04 06:00:54,314 - root - INFO - ACC
2023-09-04 06:00:54,314 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25],
 'test_acc': [53.269999999999996,
              65.96,
              70.04,
              73.08,
              73.98,
              74.11999999999999,
              73.04,
              73.85000000000001,
              73.85000000000001,
              74.35000000000001,
              73.92999999999999,
              73.97,
              74.62,
              73.63,
              74.4,
              74.25,
              74.35000000000001,
              75.14999999999999,
              74.72,
              74.44,
              72.78999999999999,
              74.83,
              74.11,
              74.39,
              74.11],
 'train_acc': [33.23,
               58.3675,
               71.0325,
               79.3825,
               87.69,
               93.595,
               96.1825,
               96.96,
               97.5675,
               98.0625,
               98.085,
               98.34,
               98.39,
               98.69,
               98.55,
               98.76,
               98.955,
               98.7825,
               98.95,
               98.96,
               99.0725,
               99.1375,
               99.2275,
               99.155,
               99.2025],
 'val_acc': [52.87,
             65.08,
             70.78,
             73.46000000000001,
             74.91,
             73.92,
             73.5,
             74.33,
             74.49,
             74.83,
             73.45,
             74.63,
             74.67,
             74.15,
             74.92999999999999,
             74.89,
             74.97,
             75.5,
             74.55000000000001,
             74.92,
             73.05,
             75.22,
             75.14999999999999,
             74.46000000000001,
             75.07000000000001]}
2023-09-04 06:00:54,314 - root - INFO - LOSS
2023-09-04 06:00:54,315 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25],
 'test_loss': [1.3456522954940795,
               0.9986505857467651,
               0.8736262948036194,
               0.8183080505371094,
               0.8312844655036926,
               1.0231133766174316,
               1.0935970323562623,
               1.1955453343868256,
               1.242265368461609,
               1.3118879122257232,
               1.2825474133968353,
               1.4775114540576935,
               1.4077505491256714,
               1.4167679096221923,
               1.3262833790779114,
               1.3012363557815552,
               1.4865299225330353,
               1.2668718446731568,
               1.4652208700180054,
               1.293877610874176,
               1.8568986666679381,
               1.5086303454875947,
               1.493360187625885,
               1.6039673003196717,
               1.3809185701847075],
 'train_loss': [1.810281413078308,
                1.1795919346809387,
                0.8430515431642532,
                0.5962290066957474,
                0.3589143226593733,
                0.18867726397812368,
                0.11601978771686554,
                0.09294995424449444,
                0.0758436085999012,
                0.06069359790980816,
                0.05860068426728249,
                0.0520585989356041,
                0.04971355749964714,
                0.041997481283545496,
                0.04306897040009498,
                0.04119207317531109,
                0.03368082382380962,
                0.035740999555587766,
                0.032054449352622034,
                0.03131115039885044,
                0.027351805508136748,
                0.0274141229480505,
                0.024347113594412804,
                0.026225077709555625,
                0.025746935245394707],
 'val_loss': [1.3443198501586915,
              0.9952601190567016,
              0.8585382937431335,
              0.8027504696846008,
              0.8078969767570495,
              1.0081819412231445,
              1.0601330603122712,
              1.17068807554245,
              1.209551497745514,
              1.2849484449863433,
              1.2624981471061707,
              1.4298467157363892,
              1.4023285331249238,
              1.37358073925972,
              1.2803501502513885,
              1.2748819034576415,
              1.4303215028762817,
              1.2444719638347626,
              1.427960056591034,
              1.2417808206796646,
              1.8398339270353317,
              1.4679156264781952,
              1.4326426353454589,
              1.571057488965988,
              1.3636099130630492]}
