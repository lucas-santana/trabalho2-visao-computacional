2023-09-02 14:53:57,971 - root - INFO - --------------------- Iniciando Novo Treinamento 23 ---------------------
2023-09-02 14:53:57,971 - root - INFO - Parametros
2023-09-02 14:53:57,971 - root - INFO - {'batch_size': 32,
 'dataset': 'CIFAR10',
 'epochs': 10,
 'learning_rate': 0.001,
 'network': 'ALEXNET',
 'num_workers': 1}
2023-09-02 14:53:57,971 - root - INFO - Construindo dataset para a rede ALEXNET
2023-09-02 14:53:59,398 - root - INFO - Construindo modelo para a rede ALEXNET
2023-09-02 14:54:01,621 - root - INFO - AlexNet(
  (layer1): Sequential(
    (0): Conv2d(3, 288, kernel_size=(11, 11), stride=(4, 4))
    (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer2): Sequential(
    (0): Conv2d(288, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer3): Sequential(
    (0): Conv2d(768, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer4): Sequential(
    (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer5): Sequential(
    (0): Conv2d(1152, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=27648, out_features=12288, bias=True)
    (2): ReLU()
  )
  (fc1): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=12288, out_features=12288, bias=True)
    (2): ReLU()
  )
  (fc2): Sequential(
    (0): Linear(in_features=12288, out_features=10, bias=True)
  )
)
2023-09-02 14:54:01,622 - root - INFO - Iniciando treinamento
2023-09-02 14:54:01,622 - root - INFO - Epoch 1
-------------------------------
2023-09-02 14:59:43,397 - root - INFO - Validation loss decreased from : inf ----> 1.9555323417194355 ----> Saving Model.......
2023-09-02 14:59:43,397 - root - INFO - Validation acc:  19.73
2023-09-02 14:59:43,397 - root - INFO - Época: 1 - Test Acc: 19.79 - Val Acc: 19.73
2023-09-02 14:59:43,397 - root - INFO - Epoch 2
-------------------------------
2023-09-02 15:05:25,874 - root - INFO - Validation loss decreased from : 1.9555323417194355 ----> 1.9096690359207007 ----> Saving Model.......
2023-09-02 15:05:25,874 - root - INFO - Validation acc:  22.14
2023-09-02 15:05:25,874 - root - INFO - Época: 2 - Test Acc: 22.71 - Val Acc: 22.14
2023-09-02 15:05:25,874 - root - INFO - Epoch 3
-------------------------------
2023-09-02 15:11:08,080 - root - INFO - Época: 3 - Test Acc: 21.51 - Val Acc: 21.36
2023-09-02 15:11:08,081 - root - INFO - Epoch 4
-------------------------------
2023-09-02 15:16:50,561 - root - INFO - Época: 4 - Test Acc: 24.65 - Val Acc: 24.740000000000002
2023-09-02 15:16:50,561 - root - INFO - Epoch 5
-------------------------------
2023-09-02 15:22:33,087 - root - INFO - Época: 5 - Test Acc: 23.35 - Val Acc: 22.68
2023-09-02 15:22:33,087 - root - INFO - Epoch 6
-------------------------------
2023-09-02 15:28:15,334 - root - INFO - Época: 6 - Test Acc: 25.019999999999996 - Val Acc: 24.12
2023-09-02 15:28:15,334 - root - INFO - Epoch 7
-------------------------------
2023-09-02 15:33:57,430 - root - INFO - Validation loss decreased from : 1.9096690359207007 ----> 1.9027295234485175 ----> Saving Model.......
2023-09-02 15:33:57,430 - root - INFO - Validation acc:  25.509999999999998
2023-09-02 15:33:57,430 - root - INFO - Época: 7 - Test Acc: 26.44 - Val Acc: 25.509999999999998
2023-09-02 15:33:57,430 - root - INFO - Epoch 8
-------------------------------
2023-09-02 15:39:39,878 - root - INFO - Validation loss decreased from : 1.9027295234485175 ----> 1.8869433669617381 ----> Saving Model.......
2023-09-02 15:39:39,878 - root - INFO - Validation acc:  29.03
2023-09-02 15:39:39,878 - root - INFO - Época: 8 - Test Acc: 29.73 - Val Acc: 29.03
2023-09-02 15:39:39,878 - root - INFO - Epoch 9
-------------------------------
2023-09-02 15:45:22,167 - root - INFO - Validation loss decreased from : 1.8869433669617381 ----> 1.8256870770987612 ----> Saving Model.......
2023-09-02 15:45:22,167 - root - INFO - Validation acc:  30.2
2023-09-02 15:45:22,167 - root - INFO - Época: 9 - Test Acc: 31.130000000000003 - Val Acc: 30.2
2023-09-02 15:45:22,167 - root - INFO - Epoch 10
-------------------------------
2023-09-02 15:51:04,574 - root - INFO - Validation loss decreased from : 1.8256870770987612 ----> 1.766143106804869 ----> Saving Model.......
2023-09-02 15:51:04,574 - root - INFO - Validation acc:  27.029999999999998
2023-09-02 15:51:04,574 - root - INFO - Época: 10 - Test Acc: 27.36 - Val Acc: 27.029999999999998
2023-09-02 15:51:04,574 - root - INFO - Tempo treinamento:  3422.95 seconds
2023-09-02 15:51:04,574 - root - INFO - Métricas
2023-09-02 15:51:04,574 - root - INFO - ACC
2023-09-02 15:51:04,574 - root - INFO - {'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
 'test_acc': [19.79,
              22.71,
              21.51,
              24.65,
              23.35,
              25.019999999999996,
              26.44,
              29.73,
              31.130000000000003,
              27.36],
 'train_acc': [15.7575,
               18.0775,
               18.85,
               19.4325,
               19.42,
               19.3175,
               20.1975,
               21.01,
               22.4575,
               23.3675],
 'val_acc': [19.73,
             22.14,
             21.36,
             24.740000000000002,
             22.68,
             24.12,
             25.509999999999998,
             29.03,
             30.2,
             27.029999999999998]}
2023-09-02 15:51:04,574 - root - INFO - LOSS
2023-09-02 15:51:04,574 - root - INFO - {'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
 'test_loss': [1.9545150180213369,
               1.9057647957207677,
               1.9189828135335028,
               1.9179125765261178,
               1.9695981249641688,
               1.9214110747693827,
               1.8947395718516633,
               1.8798220953621423,
               1.8152302694015992,
               1.7619003544981107],
 'train_loss': [2.9885099400520323,
                2.038896804332733,
                2.0307925161361693,
                2.017978804397583,
                2.0295837231636047,
                2.016014971065521,
                2.0050063336372377,
                1.9947867664337158,
                1.9725774450302125,
                1.9427296823501587],
 'val_loss': [1.9555323417194355,
              1.9096690359207007,
              1.9209740059063458,
              1.9193009819847326,
              1.967657181401603,
              1.928920977412702,
              1.9027295234485175,
              1.8869433669617381,
              1.8256870770987612,
              1.766143106804869]}
2023-09-02 15:51:14,794 - root - INFO - Rodando evaluation
2023-09-02 15:51:14,794 - root - INFO - Construindo dataset para a rede ALEXNET
2023-09-05 02:09:56,360 - root - INFO - --------------------- Iniciando Novo Treinamento 23 ---------------------
2023-09-05 02:09:56,361 - root - INFO - Parametros
2023-09-05 02:09:56,361 - root - INFO - {'batch_size': 32,
 'dataset': 'CIFAR10',
 'epochs': 10,
 'learning_rate': 0.001,
 'network': 'ALEXNET',
 'num_workers': 1}
2023-09-05 02:09:56,361 - root - INFO - Construindo dataset para a rede ALEXNET
2023-09-05 02:09:57,945 - root - INFO - AlexNet(
  (layer1): Sequential(
    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer2): Sequential(
    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer3): Sequential(
    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer4): Sequential(
    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer5): Sequential(
    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU()
  )
  (fc1): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=4096, out_features=4096, bias=True)
    (2): ReLU()
  )
  (fc2): Sequential(
    (0): Linear(in_features=4096, out_features=10, bias=True)
  )
)
2023-09-05 02:09:57,946 - root - INFO - Iniciando treinamento
2023-09-05 02:09:57,946 - root - INFO - Epoch 1
-------------------------------
2023-09-05 02:11:59,553 - root - INFO - Validation loss decreased from : inf ----> 2.1182395217895507 ----> Saving Model.......
2023-09-05 02:11:59,554 - root - INFO - Validation acc:  15.479999999999999
2023-09-05 02:11:59,554 - root - INFO - Best Test acc from 0 ----> 15.409999999999998
2023-09-05 02:11:59,554 - root - INFO - Época 1/10
2023-09-05 02:11:59,554 - root - INFO - loss: 2.326033462524414 - accuracy: 15.395 - val_loss: 2.1182395217895507 - val_accuracy: 15.479999999999999
2023-09-05 02:11:59,554 - root - INFO - [Test] ---> accuracy: 15.409999999999998 - loss: 2.114192194747925
2023-09-05 02:11:59,554 - root - INFO - test acc from best model : 15.409999999999998
2023-09-05 02:11:59,554 - root - INFO - Epoch 2
-------------------------------
2023-09-05 02:14:01,688 - root - INFO - Validation loss decreased from : 2.1182395217895507 ----> 2.0564303113937377 ----> Saving Model.......
2023-09-05 02:14:01,688 - root - INFO - Validation acc:  20.349999999999998
2023-09-05 02:14:01,688 - root - INFO - Best Test acc from 15.409999999999998 ----> 20.13
2023-09-05 02:14:01,688 - root - INFO - Época 2/10
2023-09-05 02:14:01,688 - root - INFO - loss: 2.0539182434082033 - accuracy: 19.115 - val_loss: 2.0564303113937377 - val_accuracy: 20.349999999999998
2023-09-05 02:14:01,688 - root - INFO - [Test] ---> accuracy: 20.13 - loss: 2.0590209075927732
2023-09-05 02:14:01,688 - root - INFO - test acc from best model : 20.13
2023-09-05 02:14:01,688 - root - INFO - Epoch 3
-------------------------------
2023-09-05 02:16:03,498 - root - INFO - Validation loss decreased from : 2.0564303113937377 ----> 1.9598783405303954 ----> Saving Model.......
2023-09-05 02:16:03,498 - root - INFO - Validation acc:  23.369999999999997
2023-09-05 02:16:03,498 - root - INFO - Best Test acc from 20.13 ----> 24.04
2023-09-05 02:16:03,498 - root - INFO - Época 3/10
2023-09-05 02:16:03,498 - root - INFO - loss: 2.0127281311035157 - accuracy: 20.4975 - val_loss: 1.9598783405303954 - val_accuracy: 23.369999999999997
2023-09-05 02:16:03,498 - root - INFO - [Test] ---> accuracy: 24.04 - loss: 1.9627798908233642
2023-09-05 02:16:03,498 - root - INFO - test acc from best model : 24.04
2023-09-05 02:16:03,498 - root - INFO - Epoch 4
-------------------------------
2023-09-05 02:18:05,768 - root - INFO - Validation loss decreased from : 1.9598783405303954 ----> 1.942398168182373 ----> Saving Model.......
2023-09-05 02:18:05,769 - root - INFO - Validation acc:  27.310000000000002
2023-09-05 02:18:05,769 - root - INFO - Best Test acc from 24.04 ----> 26.52
2023-09-05 02:18:05,769 - root - INFO - Época 4/10
2023-09-05 02:18:05,769 - root - INFO - loss: 1.9645008544921876 - accuracy: 21.5275 - val_loss: 1.942398168182373 - val_accuracy: 27.310000000000002
2023-09-05 02:18:05,769 - root - INFO - [Test] ---> accuracy: 26.52 - loss: 1.9466232204437255
2023-09-05 02:18:05,769 - root - INFO - test acc from best model : 26.52
2023-09-05 02:18:05,769 - root - INFO - Epoch 5
-------------------------------
2023-09-05 02:20:07,146 - root - INFO - Validation loss decreased from : 1.942398168182373 ----> 1.8884746889114379 ----> Saving Model.......
2023-09-05 02:20:07,147 - root - INFO - Validation acc:  28.13
2023-09-05 02:20:07,147 - root - INFO - Best Test acc from 26.52 ----> 28.4
2023-09-05 02:20:07,147 - root - INFO - Época 5/10
2023-09-05 02:20:07,147 - root - INFO - loss: 1.9479048309326172 - accuracy: 22.3675 - val_loss: 1.8884746889114379 - val_accuracy: 28.13
2023-09-05 02:20:07,147 - root - INFO - [Test] ---> accuracy: 28.4 - loss: 1.8923910562515258
2023-09-05 02:20:07,147 - root - INFO - test acc from best model : 28.4
2023-09-05 02:20:07,373 - root - INFO - Epoch 6
-------------------------------
2023-09-05 02:22:13,059 - root - INFO - Validation loss decreased from : 1.8884746889114379 ----> 1.8348392635345459 ----> Saving Model.......
2023-09-05 02:22:13,060 - root - INFO - Validation acc:  28.73
2023-09-05 02:22:13,060 - root - INFO - Best Test acc from 28.4 ----> 28.22
2023-09-05 02:22:13,060 - root - INFO - Época 6/10
2023-09-05 02:22:13,060 - root - INFO - loss: 1.9327814372062684 - accuracy: 23.12 - val_loss: 1.8348392635345459 - val_accuracy: 28.73
2023-09-05 02:22:13,060 - root - INFO - [Test] ---> accuracy: 28.22 - loss: 1.836755936050415
2023-09-05 02:22:13,060 - root - INFO - test acc from best model : 28.22
2023-09-05 02:22:13,060 - root - INFO - Epoch 7
-------------------------------
2023-09-05 02:24:18,663 - root - INFO - Época 7/10
2023-09-05 02:24:18,663 - root - INFO - loss: 1.8950315155029296 - accuracy: 23.98 - val_loss: 1.9081265228271485 - val_accuracy: 24.39
2023-09-05 02:24:18,663 - root - INFO - [Test] ---> accuracy: 23.84 - loss: 1.9093045345306396
2023-09-05 02:24:18,663 - root - INFO - test acc from best model : 28.22
2023-09-05 02:24:18,663 - root - INFO - Epoch 8
-------------------------------
2023-09-05 02:26:24,703 - root - INFO - Validation loss decreased from : 1.8348392635345459 ----> 1.8326002731323243 ----> Saving Model.......
2023-09-05 02:26:24,703 - root - INFO - Validation acc:  27.35
2023-09-05 02:26:24,703 - root - INFO - Best Test acc from 28.22 ----> 26.44
2023-09-05 02:26:24,703 - root - INFO - Época 8/10
2023-09-05 02:26:24,704 - root - INFO - loss: 1.8753048736572266 - accuracy: 24.0325 - val_loss: 1.8326002731323243 - val_accuracy: 27.35
2023-09-05 02:26:24,704 - root - INFO - [Test] ---> accuracy: 26.44 - loss: 1.8379403427124024
2023-09-05 02:26:24,704 - root - INFO - test acc from best model : 26.44
2023-09-05 02:26:24,704 - root - INFO - Epoch 9
-------------------------------
2023-09-05 02:28:30,328 - root - INFO - Validation loss decreased from : 1.8326002731323243 ----> 1.7913451705932617 ----> Saving Model.......
2023-09-05 02:28:30,329 - root - INFO - Validation acc:  30.39
2023-09-05 02:28:30,329 - root - INFO - Best Test acc from 26.44 ----> 29.78
2023-09-05 02:28:30,329 - root - INFO - Época 9/10
2023-09-05 02:28:30,329 - root - INFO - loss: 1.8672217339515687 - accuracy: 24.8625 - val_loss: 1.7913451705932617 - val_accuracy: 30.39
2023-09-05 02:28:30,329 - root - INFO - [Test] ---> accuracy: 29.78 - loss: 1.7994854919433594
2023-09-05 02:28:30,329 - root - INFO - test acc from best model : 29.78
2023-09-05 02:28:30,329 - root - INFO - Epoch 10
-------------------------------
2023-09-05 02:30:36,961 - root - INFO - Validation loss decreased from : 1.7913451705932617 ----> 1.75036096534729 ----> Saving Model.......
2023-09-05 02:30:36,961 - root - INFO - Validation acc:  30.85
2023-09-05 02:30:36,961 - root - INFO - Best Test acc from 29.78 ----> 30.45
2023-09-05 02:30:36,961 - root - INFO - Época 10/10
2023-09-05 02:30:36,961 - root - INFO - loss: 1.8318313613891601 - accuracy: 26.1875 - val_loss: 1.75036096534729 - val_accuracy: 30.85
2023-09-05 02:30:36,961 - root - INFO - [Test] ---> accuracy: 30.45 - loss: 1.7527482814788817
2023-09-05 02:30:36,961 - root - INFO - test acc from best model : 30.45
2023-09-05 02:30:37,160 - root - INFO - Tempo treinamento:  1239.21 seconds
2023-09-05 02:30:37,160 - root - INFO - Menor loss: 1.75036096534729
2023-09-05 02:30:37,160 - root - INFO - Acurácia de teste do melhor modelo: 30.45
2023-09-05 02:30:37,160 - root - INFO - Métricas
2023-09-05 02:30:37,160 - root - INFO - ACC
2023-09-05 02:30:37,161 - root - INFO - {'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
 'test_acc': [15.409999999999998,
              20.13,
              24.04,
              26.52,
              28.4,
              28.22,
              23.84,
              26.44,
              29.78,
              30.45],
 'train_acc': [15.395,
               19.115,
               20.4975,
               21.5275,
               22.3675,
               23.12,
               23.98,
               24.0325,
               24.8625,
               26.1875],
 'val_acc': [15.479999999999999,
             20.349999999999998,
             23.369999999999997,
             27.310000000000002,
             28.13,
             28.73,
             24.39,
             27.35,
             30.39,
             30.85]}
2023-09-05 02:30:37,161 - root - INFO - LOSS
2023-09-05 02:30:37,161 - root - INFO - {'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
 'test_loss': [2.114192194747925,
               2.0590209075927732,
               1.9627798908233642,
               1.9466232204437255,
               1.8923910562515258,
               1.836755936050415,
               1.9093045345306396,
               1.8379403427124024,
               1.7994854919433594,
               1.7527482814788817],
 'train_loss': [2.326033462524414,
                2.0539182434082033,
                2.0127281311035157,
                1.9645008544921876,
                1.9479048309326172,
                1.9327814372062684,
                1.8950315155029296,
                1.8753048736572266,
                1.8672217339515687,
                1.8318313613891601],
 'val_loss': [2.1182395217895507,
              2.0564303113937377,
              1.9598783405303954,
              1.942398168182373,
              1.8884746889114379,
              1.8348392635345459,
              1.9081265228271485,
              1.8326002731323243,
              1.7913451705932617,
              1.75036096534729]}
