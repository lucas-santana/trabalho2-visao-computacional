2023-09-04 22:04:07,657 - root - INFO - --------------------- Iniciando Novo Treinamento 81 ---------------------
2023-09-04 22:04:07,657 - root - INFO - Parametros
2023-09-04 22:04:07,657 - root - INFO - {'batch_size': 32,
 'dataset': 'CIFAR10',
 'epochs': 100,
 'learning_rate': 0.001,
 'network': 'ALEXNET',
 'num_workers': 1}
2023-09-04 22:04:07,657 - root - INFO - Construindo dataset para a rede ALEXNET
2023-09-04 22:04:09,265 - root - INFO - AlexNet(
  (layer1): Sequential(
    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer2): Sequential(
    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer3): Sequential(
    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer4): Sequential(
    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer5): Sequential(
    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU()
  )
  (fc1): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=4096, out_features=4096, bias=True)
    (2): ReLU()
  )
  (fc2): Sequential(
    (0): Linear(in_features=4096, out_features=10, bias=True)
  )
)
2023-09-04 22:04:09,265 - root - INFO - Iniciando treinamento
2023-09-04 22:04:09,265 - root - INFO - Epoch 1
-------------------------------
2023-09-04 22:06:23,746 - root - INFO - Validation loss decreased from : inf ----> 2.1182395217895507 ----> Saving Model.......
2023-09-04 22:06:23,746 - root - INFO - Validation acc:  15.479999999999999
2023-09-04 22:06:23,746 - root - INFO - Best Test acc from 0 ----> 15.409999999999998
2023-09-04 22:06:23,746 - root - INFO - Época 1/100
2023-09-04 22:06:23,746 - root - INFO - loss: 2.326033462524414 - accuracy: 15.395 - val_loss: 2.1182395217895507 - val_accuracy: 15.479999999999999
2023-09-04 22:06:23,746 - root - INFO - [Test] ---> accuracy: 15.409999999999998 - loss: 2.114192194747925
2023-09-04 22:06:23,746 - root - INFO - test acc from best model : 15.409999999999998
2023-09-04 22:06:23,746 - root - INFO - Epoch 2
-------------------------------
2023-09-04 22:08:37,472 - root - INFO - Validation loss decreased from : 2.1182395217895507 ----> 2.0564303113937377 ----> Saving Model.......
2023-09-04 22:08:37,472 - root - INFO - Validation acc:  20.349999999999998
2023-09-04 22:08:37,472 - root - INFO - Best Test acc from 15.409999999999998 ----> 20.13
2023-09-04 22:08:37,472 - root - INFO - Época 2/100
2023-09-04 22:08:37,472 - root - INFO - loss: 2.0539182434082033 - accuracy: 19.115 - val_loss: 2.0564303113937377 - val_accuracy: 20.349999999999998
2023-09-04 22:08:37,472 - root - INFO - [Test] ---> accuracy: 20.13 - loss: 2.0590209075927732
2023-09-04 22:08:37,472 - root - INFO - test acc from best model : 20.13
2023-09-04 22:08:37,472 - root - INFO - Epoch 3
-------------------------------
2023-09-04 22:10:50,995 - root - INFO - Validation loss decreased from : 2.0564303113937377 ----> 1.9598783405303954 ----> Saving Model.......
2023-09-04 22:10:50,995 - root - INFO - Validation acc:  23.369999999999997
2023-09-04 22:10:50,995 - root - INFO - Best Test acc from 20.13 ----> 24.04
2023-09-04 22:10:50,995 - root - INFO - Época 3/100
2023-09-04 22:10:50,995 - root - INFO - loss: 2.0127281311035157 - accuracy: 20.4975 - val_loss: 1.9598783405303954 - val_accuracy: 23.369999999999997
2023-09-04 22:10:50,995 - root - INFO - [Test] ---> accuracy: 24.04 - loss: 1.9627798908233642
2023-09-04 22:10:50,995 - root - INFO - test acc from best model : 24.04
2023-09-04 22:10:50,995 - root - INFO - Epoch 4
-------------------------------
2023-09-04 22:13:05,004 - root - INFO - Validation loss decreased from : 1.9598783405303954 ----> 1.942398168182373 ----> Saving Model.......
2023-09-04 22:13:05,005 - root - INFO - Validation acc:  27.310000000000002
2023-09-04 22:13:05,005 - root - INFO - Best Test acc from 24.04 ----> 26.52
2023-09-04 22:13:05,005 - root - INFO - Época 4/100
2023-09-04 22:13:05,005 - root - INFO - loss: 1.9645008544921876 - accuracy: 21.5275 - val_loss: 1.942398168182373 - val_accuracy: 27.310000000000002
2023-09-04 22:13:05,005 - root - INFO - [Test] ---> accuracy: 26.52 - loss: 1.9466232204437255
2023-09-04 22:13:05,005 - root - INFO - test acc from best model : 26.52
2023-09-04 22:13:05,005 - root - INFO - Epoch 5
-------------------------------
2023-09-04 22:15:18,778 - root - INFO - Validation loss decreased from : 1.942398168182373 ----> 1.8884746889114379 ----> Saving Model.......
2023-09-04 22:15:18,778 - root - INFO - Validation acc:  28.13
2023-09-04 22:15:18,778 - root - INFO - Best Test acc from 26.52 ----> 28.4
2023-09-04 22:15:18,778 - root - INFO - Época 5/100
2023-09-04 22:15:18,778 - root - INFO - loss: 1.9479048309326172 - accuracy: 22.3675 - val_loss: 1.8884746889114379 - val_accuracy: 28.13
2023-09-04 22:15:18,778 - root - INFO - [Test] ---> accuracy: 28.4 - loss: 1.8923910562515258
2023-09-04 22:15:18,778 - root - INFO - test acc from best model : 28.4
2023-09-04 22:15:18,870 - root - INFO - Epoch 6
-------------------------------
2023-09-04 22:17:35,089 - root - INFO - Validation loss decreased from : 1.8884746889114379 ----> 1.8348392635345459 ----> Saving Model.......
2023-09-04 22:17:35,089 - root - INFO - Validation acc:  28.73
2023-09-04 22:17:35,089 - root - INFO - Best Test acc from 28.4 ----> 28.22
2023-09-04 22:17:35,089 - root - INFO - Época 6/100
2023-09-04 22:17:35,089 - root - INFO - loss: 1.9327814372062684 - accuracy: 23.12 - val_loss: 1.8348392635345459 - val_accuracy: 28.73
2023-09-04 22:17:35,089 - root - INFO - [Test] ---> accuracy: 28.22 - loss: 1.836755936050415
2023-09-04 22:17:35,089 - root - INFO - test acc from best model : 28.22
2023-09-04 22:17:35,089 - root - INFO - Epoch 7
-------------------------------
2023-09-04 22:19:51,107 - root - INFO - Época 7/100
2023-09-04 22:19:51,107 - root - INFO - loss: 1.8950315155029296 - accuracy: 23.98 - val_loss: 1.9081265228271485 - val_accuracy: 24.39
2023-09-04 22:19:51,107 - root - INFO - [Test] ---> accuracy: 23.84 - loss: 1.9093045345306396
2023-09-04 22:19:51,107 - root - INFO - test acc from best model : 28.22
2023-09-04 22:19:51,107 - root - INFO - Epoch 8
-------------------------------
2023-09-04 22:22:07,495 - root - INFO - Validation loss decreased from : 1.8348392635345459 ----> 1.8326002731323243 ----> Saving Model.......
2023-09-04 22:22:07,495 - root - INFO - Validation acc:  27.35
2023-09-04 22:22:07,495 - root - INFO - Best Test acc from 28.22 ----> 26.44
2023-09-04 22:22:07,495 - root - INFO - Época 8/100
2023-09-04 22:22:07,495 - root - INFO - loss: 1.8753048736572266 - accuracy: 24.0325 - val_loss: 1.8326002731323243 - val_accuracy: 27.35
2023-09-04 22:22:07,495 - root - INFO - [Test] ---> accuracy: 26.44 - loss: 1.8379403427124024
2023-09-04 22:22:07,495 - root - INFO - test acc from best model : 26.44
2023-09-04 22:22:07,495 - root - INFO - Epoch 9
-------------------------------
2023-09-04 22:24:23,352 - root - INFO - Validation loss decreased from : 1.8326002731323243 ----> 1.7913451705932617 ----> Saving Model.......
2023-09-04 22:24:23,352 - root - INFO - Validation acc:  30.39
2023-09-04 22:24:23,352 - root - INFO - Best Test acc from 26.44 ----> 29.78
2023-09-04 22:24:23,352 - root - INFO - Época 9/100
2023-09-04 22:24:23,352 - root - INFO - loss: 1.8672217339515687 - accuracy: 24.8625 - val_loss: 1.7913451705932617 - val_accuracy: 30.39
2023-09-04 22:24:23,352 - root - INFO - [Test] ---> accuracy: 29.78 - loss: 1.7994854919433594
2023-09-04 22:24:23,352 - root - INFO - test acc from best model : 29.78
2023-09-04 22:24:23,352 - root - INFO - Epoch 10
-------------------------------
2023-09-04 22:26:39,457 - root - INFO - Validation loss decreased from : 1.7913451705932617 ----> 1.75036096534729 ----> Saving Model.......
2023-09-04 22:26:39,457 - root - INFO - Validation acc:  30.85
2023-09-04 22:26:39,457 - root - INFO - Best Test acc from 29.78 ----> 30.45
2023-09-04 22:26:39,457 - root - INFO - Época 10/100
2023-09-04 22:26:39,457 - root - INFO - loss: 1.8318313613891601 - accuracy: 26.1875 - val_loss: 1.75036096534729 - val_accuracy: 30.85
2023-09-04 22:26:39,457 - root - INFO - [Test] ---> accuracy: 30.45 - loss: 1.7527482814788817
2023-09-04 22:26:39,457 - root - INFO - test acc from best model : 30.45
2023-09-04 22:26:39,535 - root - INFO - Epoch 11
-------------------------------
2023-09-04 22:28:57,926 - root - INFO - Época 11/100
2023-09-04 22:28:57,926 - root - INFO - loss: 1.7760307242393494 - accuracy: 28.3975 - val_loss: 1.783675594329834 - val_accuracy: 32.59
2023-09-04 22:28:57,926 - root - INFO - [Test] ---> accuracy: 31.91 - loss: 1.7923979181289673
2023-09-04 22:28:57,926 - root - INFO - test acc from best model : 30.45
2023-09-04 22:28:57,926 - root - INFO - Epoch 12
-------------------------------
2023-09-04 22:31:16,265 - root - INFO - Validation loss decreased from : 1.75036096534729 ----> 1.6405277690887452 ----> Saving Model.......
2023-09-04 22:31:16,265 - root - INFO - Validation acc:  36.63
2023-09-04 22:31:16,265 - root - INFO - Best Test acc from 30.45 ----> 36.55
2023-09-04 22:31:16,265 - root - INFO - Época 12/100
2023-09-04 22:31:16,265 - root - INFO - loss: 1.735482334804535 - accuracy: 30.34 - val_loss: 1.6405277690887452 - val_accuracy: 36.63
2023-09-04 22:31:16,265 - root - INFO - [Test] ---> accuracy: 36.55 - loss: 1.6423573808670044
2023-09-04 22:31:16,265 - root - INFO - test acc from best model : 36.55
2023-09-04 22:31:16,265 - root - INFO - Epoch 13
-------------------------------
2023-09-04 22:33:34,151 - root - INFO - Validation loss decreased from : 1.6405277690887452 ----> 1.6033670886993407 ----> Saving Model.......
2023-09-04 22:33:34,151 - root - INFO - Validation acc:  37.79
2023-09-04 22:33:34,151 - root - INFO - Best Test acc from 36.55 ----> 37.66
2023-09-04 22:33:34,151 - root - INFO - Época 13/100
2023-09-04 22:33:34,151 - root - INFO - loss: 1.6616251173973084 - accuracy: 34.2275 - val_loss: 1.6033670886993407 - val_accuracy: 37.79
2023-09-04 22:33:34,151 - root - INFO - [Test] ---> accuracy: 37.66 - loss: 1.6076911539077758
2023-09-04 22:33:34,151 - root - INFO - test acc from best model : 37.66
2023-09-04 22:33:34,151 - root - INFO - Epoch 14
-------------------------------
2023-09-04 22:35:51,926 - root - INFO - Validation loss decreased from : 1.6033670886993407 ----> 1.269368257522583 ----> Saving Model.......
2023-09-04 22:35:51,926 - root - INFO - Validation acc:  55.489999999999995
2023-09-04 22:35:51,926 - root - INFO - Best Test acc from 37.66 ----> 55.26
2023-09-04 22:35:51,926 - root - INFO - Época 14/100
2023-09-04 22:35:51,926 - root - INFO - loss: 1.4786832658290863 - accuracy: 44.6375 - val_loss: 1.269368257522583 - val_accuracy: 55.489999999999995
2023-09-04 22:35:51,926 - root - INFO - [Test] ---> accuracy: 55.26 - loss: 1.2792566398620606
2023-09-04 22:35:51,926 - root - INFO - test acc from best model : 55.26
2023-09-04 22:35:51,926 - root - INFO - Epoch 15
-------------------------------
2023-09-04 22:38:09,654 - root - INFO - Validation loss decreased from : 1.269368257522583 ----> 1.1487375593185425 ----> Saving Model.......
2023-09-04 22:38:09,655 - root - INFO - Validation acc:  60.08
2023-09-04 22:38:09,655 - root - INFO - Best Test acc from 55.26 ----> 59.589999999999996
2023-09-04 22:38:09,655 - root - INFO - Época 15/100
2023-09-04 22:38:09,655 - root - INFO - loss: 1.1778849575042725 - accuracy: 58.63 - val_loss: 1.1487375593185425 - val_accuracy: 60.08
2023-09-04 22:38:09,655 - root - INFO - [Test] ---> accuracy: 59.589999999999996 - loss: 1.1564958667755127
2023-09-04 22:38:09,655 - root - INFO - test acc from best model : 59.589999999999996
2023-09-04 22:38:09,733 - root - INFO - Epoch 16
-------------------------------
2023-09-04 22:40:29,222 - root - INFO - Época 16/100
2023-09-04 22:40:29,222 - root - INFO - loss: 1.0063882896661758 - accuracy: 64.9875 - val_loss: 1.170508519935608 - val_accuracy: 59.64
2023-09-04 22:40:29,222 - root - INFO - [Test] ---> accuracy: 60.209999999999994 - loss: 1.1692074193954467
2023-09-04 22:40:29,222 - root - INFO - test acc from best model : 59.589999999999996
2023-09-04 22:40:29,222 - root - INFO - Epoch 17
-------------------------------
2023-09-04 22:42:49,279 - root - INFO - Validation loss decreased from : 1.1487375593185425 ----> 0.8877777485847473 ----> Saving Model.......
2023-09-04 22:42:49,279 - root - INFO - Validation acc:  69.17
2023-09-04 22:42:49,279 - root - INFO - Best Test acc from 59.589999999999996 ----> 69.98
2023-09-04 22:42:49,279 - root - INFO - Época 17/100
2023-09-04 22:42:49,279 - root - INFO - loss: 0.8841121549844742 - accuracy: 69.7475 - val_loss: 0.8877777485847473 - val_accuracy: 69.17
2023-09-04 22:42:49,279 - root - INFO - [Test] ---> accuracy: 69.98 - loss: 0.882500066280365
2023-09-04 22:42:49,279 - root - INFO - test acc from best model : 69.98
2023-09-04 22:42:49,279 - root - INFO - Epoch 18
-------------------------------
2023-09-04 22:45:08,829 - root - INFO - Validation loss decreased from : 0.8877777485847473 ----> 0.7764234422683716 ----> Saving Model.......
2023-09-04 22:45:08,829 - root - INFO - Validation acc:  73.72
2023-09-04 22:45:08,829 - root - INFO - Best Test acc from 69.98 ----> 73.50999999999999
2023-09-04 22:45:08,829 - root - INFO - Época 18/100
2023-09-04 22:45:08,829 - root - INFO - loss: 0.7952214593172073 - accuracy: 72.68 - val_loss: 0.7764234422683716 - val_accuracy: 73.72
2023-09-04 22:45:08,829 - root - INFO - [Test] ---> accuracy: 73.50999999999999 - loss: 0.7788986131668091
2023-09-04 22:45:08,829 - root - INFO - test acc from best model : 73.50999999999999
2023-09-04 22:45:08,829 - root - INFO - Epoch 19
-------------------------------
2023-09-04 22:47:28,860 - root - INFO - Validation loss decreased from : 0.7764234422683716 ----> 0.7399538298606873 ----> Saving Model.......
2023-09-04 22:47:28,860 - root - INFO - Validation acc:  74.35000000000001
2023-09-04 22:47:28,860 - root - INFO - Best Test acc from 73.50999999999999 ----> 74.58
2023-09-04 22:47:28,860 - root - INFO - Época 19/100
2023-09-04 22:47:28,860 - root - INFO - loss: 0.7365865060925484 - accuracy: 74.8075 - val_loss: 0.7399538298606873 - val_accuracy: 74.35000000000001
2023-09-04 22:47:28,860 - root - INFO - [Test] ---> accuracy: 74.58 - loss: 0.7423319101333619
2023-09-04 22:47:28,860 - root - INFO - test acc from best model : 74.58
2023-09-04 22:47:28,860 - root - INFO - Epoch 20
-------------------------------
2023-09-04 22:49:48,976 - root - INFO - Época 20/100
2023-09-04 22:49:48,976 - root - INFO - loss: 0.6683504303455353 - accuracy: 77.0575 - val_loss: 0.8321264227867127 - val_accuracy: 71.55
2023-09-04 22:49:48,976 - root - INFO - [Test] ---> accuracy: 71.39 - loss: 0.8492052605628967
2023-09-04 22:49:48,976 - root - INFO - test acc from best model : 74.58
2023-09-04 22:49:49,063 - root - INFO - Epoch 21
-------------------------------
2023-09-04 22:52:10,506 - root - INFO - Validation loss decreased from : 0.7399538298606873 ----> 0.6684529737472534 ----> Saving Model.......
2023-09-04 22:52:10,506 - root - INFO - Validation acc:  76.75999999999999
2023-09-04 22:52:10,506 - root - INFO - Best Test acc from 74.58 ----> 77.17
2023-09-04 22:52:10,506 - root - INFO - Época 21/100
2023-09-04 22:52:10,506 - root - INFO - loss: 0.6278304683446884 - accuracy: 78.3475 - val_loss: 0.6684529737472534 - val_accuracy: 76.75999999999999
2023-09-04 22:52:10,506 - root - INFO - [Test] ---> accuracy: 77.17 - loss: 0.671641198015213
2023-09-04 22:52:10,506 - root - INFO - test acc from best model : 77.17
2023-09-04 22:52:10,506 - root - INFO - Epoch 22
-------------------------------
2023-09-04 22:54:32,353 - root - INFO - Época 22/100
2023-09-04 22:54:32,353 - root - INFO - loss: 0.5844931870937348 - accuracy: 80.1575 - val_loss: 0.7157380451202393 - val_accuracy: 76.1
2023-09-04 22:54:32,353 - root - INFO - [Test] ---> accuracy: 76.22 - loss: 0.7097757928848266
2023-09-04 22:54:32,353 - root - INFO - test acc from best model : 77.17
2023-09-04 22:54:32,353 - root - INFO - Epoch 23
-------------------------------
2023-09-04 22:56:54,518 - root - INFO - Época 23/100
2023-09-04 22:56:54,519 - root - INFO - loss: 0.5376224076390267 - accuracy: 81.4375 - val_loss: 0.6798519574642181 - val_accuracy: 77.06
2023-09-04 22:56:54,519 - root - INFO - [Test] ---> accuracy: 77.42 - loss: 0.6832233072280883
2023-09-04 22:56:54,519 - root - INFO - test acc from best model : 77.17
2023-09-04 22:56:54,519 - root - INFO - Epoch 24
-------------------------------
2023-09-04 22:59:15,972 - root - INFO - Validation loss decreased from : 0.6684529737472534 ----> 0.6612658009529114 ----> Saving Model.......
2023-09-04 22:59:15,972 - root - INFO - Validation acc:  77.71000000000001
2023-09-04 22:59:15,972 - root - INFO - Best Test acc from 77.17 ----> 77.17
2023-09-04 22:59:15,972 - root - INFO - Época 24/100
2023-09-04 22:59:15,972 - root - INFO - loss: 0.5011538100361824 - accuracy: 82.8325 - val_loss: 0.6612658009529114 - val_accuracy: 77.71000000000001
2023-09-04 22:59:15,972 - root - INFO - [Test] ---> accuracy: 77.17 - loss: 0.6854573731422424
2023-09-04 22:59:15,972 - root - INFO - test acc from best model : 77.17
2023-09-04 22:59:15,972 - root - INFO - Epoch 25
-------------------------------
2023-09-04 23:01:37,583 - root - INFO - Época 25/100
2023-09-04 23:01:37,583 - root - INFO - loss: 0.46863174087405207 - accuracy: 83.8 - val_loss: 0.6780993472099304 - val_accuracy: 77.25999999999999
2023-09-04 23:01:37,583 - root - INFO - [Test] ---> accuracy: 76.86 - loss: 0.6988263836860656
2023-09-04 23:01:37,584 - root - INFO - test acc from best model : 77.17
2023-09-04 23:01:37,663 - root - INFO - Epoch 26
-------------------------------
2023-09-04 23:04:01,158 - root - INFO - Validation loss decreased from : 0.6612658009529114 ----> 0.6195021769523621 ----> Saving Model.......
2023-09-04 23:04:01,158 - root - INFO - Validation acc:  78.94
2023-09-04 23:04:01,158 - root - INFO - Best Test acc from 77.17 ----> 78.64999999999999
2023-09-04 23:04:01,158 - root - INFO - Época 26/100
2023-09-04 23:04:01,158 - root - INFO - loss: 0.4330073257297277 - accuracy: 84.9025 - val_loss: 0.6195021769523621 - val_accuracy: 78.94
2023-09-04 23:04:01,158 - root - INFO - [Test] ---> accuracy: 78.64999999999999 - loss: 0.6276711808204651
2023-09-04 23:04:01,158 - root - INFO - test acc from best model : 78.64999999999999
2023-09-04 23:04:01,158 - root - INFO - Epoch 27
-------------------------------
2023-09-04 23:06:24,593 - root - INFO - Época 27/100
2023-09-04 23:06:24,593 - root - INFO - loss: 0.4082994262248278 - accuracy: 85.9125 - val_loss: 0.6318772480964661 - val_accuracy: 78.95
2023-09-04 23:06:24,594 - root - INFO - [Test] ---> accuracy: 78.43 - loss: 0.6390324194908142
2023-09-04 23:06:24,594 - root - INFO - test acc from best model : 78.64999999999999
2023-09-04 23:06:24,594 - root - INFO - Epoch 28
-------------------------------
2023-09-04 23:47:47,457 - root - INFO - Época 28/100
2023-09-04 23:47:47,457 - root - INFO - loss: 0.37790866471529005 - accuracy: 86.8775 - val_loss: 0.6652390655040741 - val_accuracy: 78.19
2023-09-04 23:47:47,457 - root - INFO - [Test] ---> accuracy: 77.97 - loss: 0.6625468245983124
2023-09-04 23:47:47,457 - root - INFO - test acc from best model : 78.64999999999999
2023-09-04 23:47:47,457 - root - INFO - Epoch 29
-------------------------------
2023-09-04 23:50:10,874 - root - INFO - Época 29/100
2023-09-04 23:50:10,874 - root - INFO - loss: 0.3617685905843973 - accuracy: 87.5925 - val_loss: 0.6920778087854386 - val_accuracy: 78.53
2023-09-04 23:50:10,874 - root - INFO - [Test] ---> accuracy: 77.64999999999999 - loss: 0.7197536305427551
2023-09-04 23:50:10,874 - root - INFO - test acc from best model : 78.64999999999999
2023-09-04 23:50:10,874 - root - INFO - Epoch 30
-------------------------------
2023-09-04 23:52:34,696 - root - INFO - Época 30/100
2023-09-04 23:52:34,696 - root - INFO - loss: 0.3356365688741207 - accuracy: 88.405 - val_loss: 0.6749455214977265 - val_accuracy: 77.94
2023-09-04 23:52:34,696 - root - INFO - [Test] ---> accuracy: 77.79 - loss: 0.6882409098625183
2023-09-04 23:52:34,696 - root - INFO - test acc from best model : 78.64999999999999
2023-09-04 23:52:34,779 - root - INFO - Epoch 31
-------------------------------
2023-09-04 23:55:00,804 - root - INFO - Validation loss decreased from : 0.6195021769523621 ----> 0.6166287036657333 ----> Saving Model.......
2023-09-04 23:55:00,804 - root - INFO - Validation acc:  80.17999999999999
2023-09-04 23:55:00,804 - root - INFO - Best Test acc from 78.64999999999999 ----> 79.91
2023-09-04 23:55:00,804 - root - INFO - Época 31/100
2023-09-04 23:55:00,804 - root - INFO - loss: 0.3174362778484821 - accuracy: 89.225 - val_loss: 0.6166287036657333 - val_accuracy: 80.17999999999999
2023-09-04 23:55:00,804 - root - INFO - [Test] ---> accuracy: 79.91 - loss: 0.6404700518131257
2023-09-04 23:55:00,804 - root - INFO - test acc from best model : 79.91
2023-09-04 23:55:00,804 - root - INFO - Epoch 32
-------------------------------
2023-09-04 23:57:26,256 - root - INFO - Época 32/100
2023-09-04 23:57:26,256 - root - INFO - loss: 0.2958101069509983 - accuracy: 89.8875 - val_loss: 0.75913815908432 - val_accuracy: 77.42999999999999
2023-09-04 23:57:26,256 - root - INFO - [Test] ---> accuracy: 77.42999999999999 - loss: 0.7548455770015716
2023-09-04 23:57:26,256 - root - INFO - test acc from best model : 79.91
2023-09-04 23:57:26,256 - root - INFO - Epoch 33
-------------------------------
2023-09-04 23:59:51,991 - root - INFO - Época 33/100
2023-09-04 23:59:51,991 - root - INFO - loss: 0.288112797281146 - accuracy: 90.28 - val_loss: 0.6859689739227295 - val_accuracy: 79.23
2023-09-04 23:59:51,991 - root - INFO - [Test] ---> accuracy: 79.25 - loss: 0.681887575674057
2023-09-04 23:59:51,992 - root - INFO - test acc from best model : 79.91
2023-09-04 23:59:51,992 - root - INFO - Epoch 34
-------------------------------
2023-09-05 00:02:17,329 - root - INFO - Validation loss decreased from : 0.6166287036657333 ----> 0.6098167386293412 ----> Saving Model.......
2023-09-05 00:02:17,329 - root - INFO - Validation acc:  81.37
2023-09-05 00:02:17,329 - root - INFO - Best Test acc from 79.91 ----> 81.16
2023-09-05 00:02:17,329 - root - INFO - Época 34/100
2023-09-05 00:02:17,329 - root - INFO - loss: 0.2624661784529686 - accuracy: 91.215 - val_loss: 0.6098167386293412 - val_accuracy: 81.37
2023-09-05 00:02:17,329 - root - INFO - [Test] ---> accuracy: 81.16 - loss: 0.6239709537267685
2023-09-05 00:02:17,329 - root - INFO - test acc from best model : 81.16
2023-09-05 00:02:17,329 - root - INFO - Epoch 35
-------------------------------
2023-09-05 00:04:43,051 - root - INFO - Época 35/100
2023-09-05 00:04:43,051 - root - INFO - loss: 0.25569608822166917 - accuracy: 91.4275 - val_loss: 0.6329094537258149 - val_accuracy: 81.31
2023-09-05 00:04:43,051 - root - INFO - [Test] ---> accuracy: 80.2 - loss: 0.6541989131450653
2023-09-05 00:04:43,052 - root - INFO - test acc from best model : 81.16
2023-09-05 00:04:43,131 - root - INFO - Epoch 36
-------------------------------
2023-09-05 00:07:10,799 - root - INFO - Época 36/100
2023-09-05 00:07:10,800 - root - INFO - loss: 0.23501091201901436 - accuracy: 92.0 - val_loss: 0.646925405216217 - val_accuracy: 80.62
2023-09-05 00:07:10,800 - root - INFO - [Test] ---> accuracy: 79.78 - loss: 0.664357028722763
2023-09-05 00:07:10,800 - root - INFO - test acc from best model : 81.16
2023-09-05 00:07:10,800 - root - INFO - Epoch 37
-------------------------------
2023-09-05 00:09:38,127 - root - INFO - Época 37/100
2023-09-05 00:09:38,127 - root - INFO - loss: 0.2247560220569372 - accuracy: 92.4 - val_loss: 0.6294212791919708 - val_accuracy: 80.78999999999999
2023-09-05 00:09:38,127 - root - INFO - [Test] ---> accuracy: 80.17 - loss: 0.6462825572967529
2023-09-05 00:09:38,127 - root - INFO - test acc from best model : 81.16
2023-09-05 00:09:38,127 - root - INFO - Epoch 38
-------------------------------
2023-09-05 00:12:05,387 - root - INFO - Época 38/100
2023-09-05 00:12:05,388 - root - INFO - loss: 0.21951306509077548 - accuracy: 92.6325 - val_loss: 0.6424148235082626 - val_accuracy: 80.83
2023-09-05 00:12:05,388 - root - INFO - [Test] ---> accuracy: 80.25 - loss: 0.6771549742698669
2023-09-05 00:12:05,388 - root - INFO - test acc from best model : 81.16
2023-09-05 00:12:05,388 - root - INFO - Epoch 39
-------------------------------
2023-09-05 00:14:33,250 - root - INFO - Época 39/100
2023-09-05 00:14:33,251 - root - INFO - loss: 0.21644164247214795 - accuracy: 92.7425 - val_loss: 0.7108503046989441 - val_accuracy: 78.97
2023-09-05 00:14:33,251 - root - INFO - [Test] ---> accuracy: 78.7 - loss: 0.728313057756424
2023-09-05 00:14:33,251 - root - INFO - test acc from best model : 81.16
2023-09-05 00:14:33,251 - root - INFO - Epoch 40
-------------------------------
2023-09-05 00:17:01,488 - root - INFO - Época 40/100
2023-09-05 00:17:01,488 - root - INFO - loss: 0.20071102596521379 - accuracy: 93.32 - val_loss: 0.6332642207145691 - val_accuracy: 81.15
2023-09-05 00:17:01,488 - root - INFO - [Test] ---> accuracy: 81.13 - loss: 0.6582219343662262
2023-09-05 00:17:01,488 - root - INFO - test acc from best model : 81.16
2023-09-05 00:17:01,569 - root - INFO - Epoch 41
-------------------------------
2023-09-05 00:19:31,458 - root - INFO - Época 41/100
2023-09-05 00:19:31,459 - root - INFO - loss: 0.18841556832194328 - accuracy: 93.63 - val_loss: 0.6576570084810257 - val_accuracy: 81.57
2023-09-05 00:19:31,459 - root - INFO - [Test] ---> accuracy: 81.81 - loss: 0.6918084823608398
2023-09-05 00:19:31,459 - root - INFO - test acc from best model : 81.16
2023-09-05 00:19:31,459 - root - INFO - Epoch 42
-------------------------------
2023-09-05 00:22:00,923 - root - INFO - Época 42/100
2023-09-05 00:22:00,923 - root - INFO - loss: 0.19805256915986538 - accuracy: 93.4825 - val_loss: 0.6319839037418366 - val_accuracy: 81.15
2023-09-05 00:22:00,923 - root - INFO - [Test] ---> accuracy: 81.19 - loss: 0.6471849099874496
2023-09-05 00:22:00,923 - root - INFO - test acc from best model : 81.16
2023-09-05 00:22:00,923 - root - INFO - Epoch 43
-------------------------------
2023-09-05 00:24:30,409 - root - INFO - Época 43/100
2023-09-05 00:24:30,410 - root - INFO - loss: 0.17433802019953729 - accuracy: 94.1425 - val_loss: 0.6709957312345505 - val_accuracy: 80.16
2023-09-05 00:24:30,410 - root - INFO - [Test] ---> accuracy: 80.2 - loss: 0.7026894738674164
2023-09-05 00:24:30,410 - root - INFO - test acc from best model : 81.16
2023-09-05 00:24:30,410 - root - INFO - Epoch 44
-------------------------------
2023-09-05 00:26:59,700 - root - INFO - Época 44/100
2023-09-05 00:26:59,700 - root - INFO - loss: 0.17386590805351734 - accuracy: 94.215 - val_loss: 0.7852601150274277 - val_accuracy: 79.7
2023-09-05 00:26:59,700 - root - INFO - [Test] ---> accuracy: 79.45 - loss: 0.8074714514255523
2023-09-05 00:26:59,700 - root - INFO - test acc from best model : 81.16
2023-09-05 00:26:59,700 - root - INFO - Epoch 45
-------------------------------
2023-09-05 00:29:28,945 - root - INFO - Época 45/100
2023-09-05 00:29:28,945 - root - INFO - loss: 0.16096212057471276 - accuracy: 94.58 - val_loss: 0.6265435689210892 - val_accuracy: 81.85
2023-09-05 00:29:28,945 - root - INFO - [Test] ---> accuracy: 81.8 - loss: 0.657170248556137
2023-09-05 00:29:28,945 - root - INFO - test acc from best model : 81.16
2023-09-05 00:29:29,021 - root - INFO - Epoch 46
-------------------------------
2023-09-05 00:32:00,221 - root - INFO - Época 46/100
2023-09-05 00:32:00,221 - root - INFO - loss: 0.15974639518857003 - accuracy: 94.755 - val_loss: 0.6545328705787659 - val_accuracy: 81.78
2023-09-05 00:32:00,221 - root - INFO - [Test] ---> accuracy: 81.69999999999999 - loss: 0.6818619888305664
2023-09-05 00:32:00,221 - root - INFO - test acc from best model : 81.16
2023-09-05 00:32:00,221 - root - INFO - Epoch 47
-------------------------------
2023-09-05 00:34:31,574 - root - INFO - Época 47/100
2023-09-05 00:34:31,574 - root - INFO - loss: 0.1622056651443243 - accuracy: 94.6625 - val_loss: 0.726431486582756 - val_accuracy: 81.23
2023-09-05 00:34:31,574 - root - INFO - [Test] ---> accuracy: 80.85 - loss: 0.7557995871901512
2023-09-05 00:34:31,574 - root - INFO - test acc from best model : 81.16
2023-09-05 00:34:31,574 - root - INFO - Epoch 48
-------------------------------
2023-09-05 00:37:03,093 - root - INFO - Época 48/100
2023-09-05 00:37:03,093 - root - INFO - loss: 0.15108854891359805 - accuracy: 95.045 - val_loss: 0.6652149670362473 - val_accuracy: 81.51
2023-09-05 00:37:03,093 - root - INFO - [Test] ---> accuracy: 81.33 - loss: 0.7046606834888458
2023-09-05 00:37:03,093 - root - INFO - test acc from best model : 81.16
2023-09-05 00:37:03,093 - root - INFO - Epoch 49
-------------------------------
2023-09-05 00:39:34,344 - root - INFO - Época 49/100
2023-09-05 00:39:34,344 - root - INFO - loss: 0.1533267298281193 - accuracy: 95.0375 - val_loss: 0.63246739372015 - val_accuracy: 81.89
2023-09-05 00:39:34,344 - root - INFO - [Test] ---> accuracy: 80.96 - loss: 0.6829698043823242
2023-09-05 00:39:34,344 - root - INFO - test acc from best model : 81.16
2023-09-05 00:39:34,344 - root - INFO - Epoch 50
-------------------------------
2023-09-05 00:42:06,145 - root - INFO - Época 50/100
2023-09-05 00:42:06,145 - root - INFO - loss: 0.14359560829997062 - accuracy: 95.315 - val_loss: 0.6962653107643128 - val_accuracy: 80.36999999999999
2023-09-05 00:42:06,145 - root - INFO - [Test] ---> accuracy: 80.0 - loss: 0.7143791161060333
2023-09-05 00:42:06,145 - root - INFO - test acc from best model : 81.16
2023-09-05 00:42:06,228 - root - INFO - Epoch 51
-------------------------------
2023-09-05 00:44:40,200 - root - INFO - Época 51/100
2023-09-05 00:44:40,200 - root - INFO - loss: 0.14434874868392944 - accuracy: 95.345 - val_loss: 0.714704098534584 - val_accuracy: 81.46
2023-09-05 00:44:40,200 - root - INFO - [Test] ---> accuracy: 80.71000000000001 - loss: 0.7705912331104279
2023-09-05 00:44:40,200 - root - INFO - test acc from best model : 81.16
2023-09-05 00:44:40,200 - root - INFO - Epoch 52
-------------------------------
2023-09-05 00:47:13,691 - root - INFO - Época 52/100
2023-09-05 00:47:13,691 - root - INFO - loss: 0.13835382165908813 - accuracy: 95.4025 - val_loss: 0.6615014882147312 - val_accuracy: 81.78999999999999
2023-09-05 00:47:13,691 - root - INFO - [Test] ---> accuracy: 81.38 - loss: 0.6842747146129609
2023-09-05 00:47:13,691 - root - INFO - test acc from best model : 81.16
2023-09-05 00:47:13,691 - root - INFO - Epoch 53
-------------------------------
2023-09-05 00:49:47,015 - root - INFO - Época 53/100
2023-09-05 00:49:47,015 - root - INFO - loss: 0.13390409474372864 - accuracy: 95.8025 - val_loss: 0.6334512444257736 - val_accuracy: 82.05
2023-09-05 00:49:47,015 - root - INFO - [Test] ---> accuracy: 81.78999999999999 - loss: 0.6747740317344666
2023-09-05 00:49:47,015 - root - INFO - test acc from best model : 81.16
2023-09-05 00:49:47,015 - root - INFO - Epoch 54
-------------------------------
2023-09-05 00:52:20,959 - root - INFO - Época 54/100
2023-09-05 00:52:20,959 - root - INFO - loss: 0.12582911858558654 - accuracy: 96.025 - val_loss: 0.7551509688615798 - val_accuracy: 80.82000000000001
2023-09-05 00:52:20,959 - root - INFO - [Test] ---> accuracy: 80.58999999999999 - loss: 0.7815539556980133
2023-09-05 00:52:20,959 - root - INFO - test acc from best model : 81.16
2023-09-05 00:52:20,959 - root - INFO - Epoch 55
-------------------------------
2023-09-05 00:54:54,792 - root - INFO - Época 55/100
2023-09-05 00:54:54,792 - root - INFO - loss: 0.12763954542577266 - accuracy: 95.7975 - val_loss: 0.9816417651414872 - val_accuracy: 77.61
2023-09-05 00:54:54,792 - root - INFO - [Test] ---> accuracy: 77.45 - loss: 1.0101121420383454
2023-09-05 00:54:54,792 - root - INFO - test acc from best model : 81.16
2023-09-05 00:54:54,870 - root - INFO - Epoch 56
-------------------------------
2023-09-05 00:57:30,226 - root - INFO - Época 56/100
2023-09-05 00:57:30,226 - root - INFO - loss: 0.12624994773864745 - accuracy: 96.0125 - val_loss: 0.7548118794828653 - val_accuracy: 81.07
2023-09-05 00:57:30,226 - root - INFO - [Test] ---> accuracy: 81.44 - loss: 0.7628015208244324
2023-09-05 00:57:30,226 - root - INFO - test acc from best model : 81.16
2023-09-05 00:57:30,226 - root - INFO - Epoch 57
-------------------------------
2023-09-05 01:00:05,719 - root - INFO - Época 57/100
2023-09-05 01:00:05,719 - root - INFO - loss: 0.12692325660586357 - accuracy: 95.9675 - val_loss: 0.6787093587875366 - val_accuracy: 81.46
2023-09-05 01:00:05,719 - root - INFO - [Test] ---> accuracy: 81.17 - loss: 0.7006401941776276
2023-09-05 01:00:05,719 - root - INFO - test acc from best model : 81.16
2023-09-05 01:00:05,719 - root - INFO - Epoch 58
-------------------------------
2023-09-05 01:02:40,633 - root - INFO - Época 58/100
2023-09-05 01:02:40,634 - root - INFO - loss: 0.12173986706137657 - accuracy: 96.0925 - val_loss: 0.7181829864501953 - val_accuracy: 81.63
2023-09-05 01:02:40,634 - root - INFO - [Test] ---> accuracy: 81.36 - loss: 0.7434349426984787
2023-09-05 01:02:40,634 - root - INFO - test acc from best model : 81.16
2023-09-05 01:02:40,634 - root - INFO - Epoch 59
-------------------------------
2023-09-05 01:05:15,681 - root - INFO - Época 59/100
2023-09-05 01:05:15,681 - root - INFO - loss: 0.11341022970676422 - accuracy: 96.37 - val_loss: 0.6804045594215393 - val_accuracy: 81.11
2023-09-05 01:05:15,681 - root - INFO - [Test] ---> accuracy: 80.60000000000001 - loss: 0.7148997392177582
2023-09-05 01:05:15,681 - root - INFO - test acc from best model : 81.16
2023-09-05 01:05:15,681 - root - INFO - Epoch 60
-------------------------------
2023-09-05 01:07:51,386 - root - INFO - Época 60/100
2023-09-05 01:07:51,386 - root - INFO - loss: 0.11806865494549275 - accuracy: 96.23 - val_loss: 0.7148195631742478 - val_accuracy: 80.76
2023-09-05 01:07:51,386 - root - INFO - [Test] ---> accuracy: 81.55 - loss: 0.7224074882984162
2023-09-05 01:07:51,386 - root - INFO - test acc from best model : 81.16
2023-09-05 01:07:51,466 - root - INFO - Epoch 61
-------------------------------
2023-09-05 01:10:28,747 - root - INFO - Época 61/100
2023-09-05 01:10:28,747 - root - INFO - loss: 0.11145166303217412 - accuracy: 96.46 - val_loss: 0.7213523770332336 - val_accuracy: 82.13000000000001
2023-09-05 01:10:28,747 - root - INFO - [Test] ---> accuracy: 81.99 - loss: 0.7671113625526428
2023-09-05 01:10:28,747 - root - INFO - test acc from best model : 81.16
2023-09-05 01:10:28,747 - root - INFO - Epoch 62
-------------------------------
2023-09-05 01:13:05,822 - root - INFO - Época 62/100
2023-09-05 01:13:05,822 - root - INFO - loss: 0.11298678324520588 - accuracy: 96.5225 - val_loss: 0.7029774092674256 - val_accuracy: 82.28
2023-09-05 01:13:05,822 - root - INFO - [Test] ---> accuracy: 81.77 - loss: 0.7421630633234978
2023-09-05 01:13:05,822 - root - INFO - test acc from best model : 81.16
2023-09-05 01:13:05,822 - root - INFO - Epoch 63
-------------------------------
2023-09-05 01:15:42,889 - root - INFO - Época 63/100
2023-09-05 01:15:42,889 - root - INFO - loss: 0.11169760246276855 - accuracy: 96.4375 - val_loss: 0.6967541243314743 - val_accuracy: 81.71000000000001
2023-09-05 01:15:42,889 - root - INFO - [Test] ---> accuracy: 81.67 - loss: 0.7382054352998734
2023-09-05 01:15:42,889 - root - INFO - test acc from best model : 81.16
2023-09-05 01:15:42,889 - root - INFO - Epoch 64
-------------------------------
2023-09-05 01:18:20,200 - root - INFO - Época 64/100
2023-09-05 01:18:20,200 - root - INFO - loss: 0.10668407175540924 - accuracy: 96.62 - val_loss: 0.7061336977005005 - val_accuracy: 82.46
2023-09-05 01:18:20,200 - root - INFO - [Test] ---> accuracy: 82.16 - loss: 0.7491326471328735
2023-09-05 01:18:20,200 - root - INFO - test acc from best model : 81.16
2023-09-05 01:18:20,200 - root - INFO - Epoch 65
-------------------------------
2023-09-05 01:20:57,390 - root - INFO - Época 65/100
2023-09-05 01:20:57,390 - root - INFO - loss: 0.10240874201357365 - accuracy: 96.775 - val_loss: 0.726993879032135 - val_accuracy: 81.76
2023-09-05 01:20:57,390 - root - INFO - [Test] ---> accuracy: 82.0 - loss: 0.758790346288681
2023-09-05 01:20:57,390 - root - INFO - test acc from best model : 81.16
2023-09-05 01:20:57,476 - root - INFO - Epoch 66
-------------------------------
2023-09-05 01:23:36,678 - root - INFO - Época 66/100
2023-09-05 01:23:36,678 - root - INFO - loss: 0.1093020317196846 - accuracy: 96.645 - val_loss: 0.7058147246837616 - val_accuracy: 81.89
2023-09-05 01:23:36,678 - root - INFO - [Test] ---> accuracy: 81.84 - loss: 0.7319419445157052
2023-09-05 01:23:36,678 - root - INFO - test acc from best model : 81.16
2023-09-05 01:23:36,678 - root - INFO - Epoch 67
-------------------------------
2023-09-05 01:26:15,552 - root - INFO - Época 67/100
2023-09-05 01:26:15,552 - root - INFO - loss: 0.10334892293214798 - accuracy: 96.79 - val_loss: 0.8236826464176178 - val_accuracy: 79.11
2023-09-05 01:26:15,552 - root - INFO - [Test] ---> accuracy: 78.64 - loss: 0.8597828391075134
2023-09-05 01:26:15,552 - root - INFO - test acc from best model : 81.16
2023-09-05 01:26:15,552 - root - INFO - Epoch 68
-------------------------------
2023-09-05 01:28:55,087 - root - INFO - Época 68/100
2023-09-05 01:28:55,087 - root - INFO - loss: 0.10038743601739407 - accuracy: 96.9125 - val_loss: 0.6897205457210541 - val_accuracy: 82.55
2023-09-05 01:28:55,087 - root - INFO - [Test] ---> accuracy: 81.72 - loss: 0.7530332735776901
2023-09-05 01:28:55,087 - root - INFO - test acc from best model : 81.16
2023-09-05 01:28:55,087 - root - INFO - Epoch 69
-------------------------------
2023-09-05 01:31:34,362 - root - INFO - Época 69/100
2023-09-05 01:31:34,362 - root - INFO - loss: 0.11356953257620335 - accuracy: 96.635 - val_loss: 0.692133764076233 - val_accuracy: 82.6
2023-09-05 01:31:34,362 - root - INFO - [Test] ---> accuracy: 81.78999999999999 - loss: 0.7174050607681275
2023-09-05 01:31:34,362 - root - INFO - test acc from best model : 81.16
2023-09-05 01:31:34,362 - root - INFO - Epoch 70
-------------------------------
2023-09-05 01:34:14,690 - root - INFO - Época 70/100
2023-09-05 01:34:14,690 - root - INFO - loss: 0.09767484279870987 - accuracy: 96.9675 - val_loss: 0.7936740294218063 - val_accuracy: 81.47
2023-09-05 01:34:14,690 - root - INFO - [Test] ---> accuracy: 81.39 - loss: 0.8295620781183243
2023-09-05 01:34:14,690 - root - INFO - test acc from best model : 81.16
2023-09-05 01:34:14,780 - root - INFO - Epoch 71
-------------------------------
2023-09-05 01:36:55,638 - root - INFO - Época 71/100
2023-09-05 01:36:55,638 - root - INFO - loss: 0.09392793090939522 - accuracy: 97.1175 - val_loss: 0.8271798293232918 - val_accuracy: 81.35
2023-09-05 01:36:55,638 - root - INFO - [Test] ---> accuracy: 81.78 - loss: 0.8318727450609207
2023-09-05 01:36:55,638 - root - INFO - test acc from best model : 81.16
2023-09-05 01:36:55,638 - root - INFO - Epoch 72
-------------------------------
2023-09-05 01:39:36,905 - root - INFO - Época 72/100
2023-09-05 01:39:36,905 - root - INFO - loss: 0.10146165556013584 - accuracy: 96.965 - val_loss: 0.7534234078884124 - val_accuracy: 82.34
2023-09-05 01:39:36,905 - root - INFO - [Test] ---> accuracy: 81.85 - loss: 0.7994831505537033
2023-09-05 01:39:36,905 - root - INFO - test acc from best model : 81.16
2023-09-05 01:39:36,905 - root - INFO - Epoch 73
-------------------------------
2023-09-05 01:42:18,005 - root - INFO - Época 73/100
2023-09-05 01:42:18,005 - root - INFO - loss: 0.0914937890380621 - accuracy: 97.2275 - val_loss: 0.8938590287446976 - val_accuracy: 79.86999999999999
2023-09-05 01:42:18,005 - root - INFO - [Test] ---> accuracy: 79.57 - loss: 0.9229232183456421
2023-09-05 01:42:18,005 - root - INFO - test acc from best model : 81.16
2023-09-05 01:42:18,005 - root - INFO - Epoch 74
-------------------------------
2023-09-05 01:44:59,157 - root - INFO - Época 74/100
2023-09-05 01:44:59,157 - root - INFO - loss: 0.09599235569834709 - accuracy: 97.0375 - val_loss: 0.8142082316815853 - val_accuracy: 82.69
2023-09-05 01:44:59,157 - root - INFO - [Test] ---> accuracy: 82.6 - loss: 0.8536839132547378
2023-09-05 01:44:59,157 - root - INFO - test acc from best model : 81.16
2023-09-05 01:44:59,157 - root - INFO - Epoch 75
-------------------------------
2023-09-05 01:47:40,245 - root - INFO - Época 75/100
2023-09-05 01:47:40,245 - root - INFO - loss: 0.08827283857762813 - accuracy: 97.3075 - val_loss: 0.7716515335798264 - val_accuracy: 82.02000000000001
2023-09-05 01:47:40,245 - root - INFO - [Test] ---> accuracy: 81.65 - loss: 0.8097361855745315
2023-09-05 01:47:40,245 - root - INFO - test acc from best model : 81.16
2023-09-05 01:47:40,330 - root - INFO - Epoch 76
-------------------------------
2023-09-05 01:50:24,117 - root - INFO - Época 76/100
2023-09-05 01:50:24,117 - root - INFO - loss: 0.09458956009149551 - accuracy: 97.09 - val_loss: 0.751390380859375 - val_accuracy: 81.47999999999999
2023-09-05 01:50:24,117 - root - INFO - [Test] ---> accuracy: 81.52000000000001 - loss: 0.7668240172147751
2023-09-05 01:50:24,117 - root - INFO - test acc from best model : 81.16
2023-09-05 01:50:24,117 - root - INFO - Epoch 77
-------------------------------
2023-09-05 01:53:07,635 - root - INFO - Época 77/100
2023-09-05 01:53:07,635 - root - INFO - loss: 0.09235051701664924 - accuracy: 97.23 - val_loss: 0.7882193229198455 - val_accuracy: 82.12
2023-09-05 01:53:07,635 - root - INFO - [Test] ---> accuracy: 82.05 - loss: 0.8023887956142426
2023-09-05 01:53:07,635 - root - INFO - test acc from best model : 81.16
2023-09-05 01:53:07,635 - root - INFO - Epoch 78
-------------------------------
2023-09-05 01:55:51,322 - root - INFO - Época 78/100
2023-09-05 01:55:51,322 - root - INFO - loss: 0.08315027400851249 - accuracy: 97.4425 - val_loss: 0.9108350144267082 - val_accuracy: 80.27
2023-09-05 01:55:51,322 - root - INFO - [Test] ---> accuracy: 79.97 - loss: 0.9945329634189606
2023-09-05 01:55:51,322 - root - INFO - test acc from best model : 81.16
2023-09-05 01:55:51,322 - root - INFO - Epoch 79
-------------------------------
2023-09-05 01:58:35,037 - root - INFO - Época 79/100
2023-09-05 01:58:35,037 - root - INFO - loss: 0.08703762114346027 - accuracy: 97.4125 - val_loss: 0.7312053076028824 - val_accuracy: 82.97
2023-09-05 01:58:35,037 - root - INFO - [Test] ---> accuracy: 82.54 - loss: 0.7770234799027443
2023-09-05 01:58:35,037 - root - INFO - test acc from best model : 81.16
2023-09-05 01:58:35,037 - root - INFO - Epoch 80
-------------------------------
2023-09-05 02:01:18,920 - root - INFO - Época 80/100
2023-09-05 02:01:18,920 - root - INFO - loss: 0.08659378823637963 - accuracy: 97.335 - val_loss: 0.8339260102421046 - val_accuracy: 81.78
2023-09-05 02:01:18,920 - root - INFO - [Test] ---> accuracy: 81.32000000000001 - loss: 0.8674131199836731
2023-09-05 02:01:18,920 - root - INFO - test acc from best model : 81.16
2023-09-05 02:01:19,001 - root - INFO - Epoch 81
-------------------------------
2023-09-05 02:04:05,465 - root - INFO - Época 81/100
2023-09-05 02:04:05,466 - root - INFO - loss: 0.08852972481548786 - accuracy: 97.205 - val_loss: 0.7135952661275864 - val_accuracy: 81.75
2023-09-05 02:04:05,466 - root - INFO - [Test] ---> accuracy: 81.58999999999999 - loss: 0.7750437397003174
2023-09-05 02:04:05,466 - root - INFO - test acc from best model : 81.16
2023-09-05 02:04:05,466 - root - INFO - Epoch 82
-------------------------------
2023-09-05 02:06:51,549 - root - INFO - Época 82/100
2023-09-05 02:06:51,549 - root - INFO - loss: 0.08431957675218582 - accuracy: 97.345 - val_loss: 0.906541862475872 - val_accuracy: 82.05
2023-09-05 02:06:51,549 - root - INFO - [Test] ---> accuracy: 81.67 - loss: 0.949734015417099
2023-09-05 02:06:51,549 - root - INFO - test acc from best model : 81.16
2023-09-05 02:06:51,549 - root - INFO - Epoch 83
-------------------------------
2023-09-05 02:09:37,408 - root - INFO - Época 83/100
2023-09-05 02:09:37,409 - root - INFO - loss: 0.08554014118611812 - accuracy: 97.535 - val_loss: 0.7763978172063828 - val_accuracy: 82.49
2023-09-05 02:09:37,409 - root - INFO - [Test] ---> accuracy: 82.13000000000001 - loss: 0.8203060480117798
2023-09-05 02:09:37,409 - root - INFO - test acc from best model : 81.16
2023-09-05 02:09:37,409 - root - INFO - Epoch 84
-------------------------------
2023-09-05 02:12:22,813 - root - INFO - Época 84/100
2023-09-05 02:12:22,813 - root - INFO - loss: 0.08184937122762204 - accuracy: 97.555 - val_loss: 0.7888440956830979 - val_accuracy: 82.31
2023-09-05 02:12:22,813 - root - INFO - [Test] ---> accuracy: 81.34 - loss: 0.8754858816623687
2023-09-05 02:12:22,813 - root - INFO - test acc from best model : 81.16
2023-09-05 02:12:22,813 - root - INFO - Epoch 85
-------------------------------
2023-09-05 02:15:08,671 - root - INFO - Época 85/100
2023-09-05 02:15:08,671 - root - INFO - loss: 0.08136408534646035 - accuracy: 97.58 - val_loss: 0.8122626767873764 - val_accuracy: 81.77
2023-09-05 02:15:08,671 - root - INFO - [Test] ---> accuracy: 81.13 - loss: 0.8656597735881806
2023-09-05 02:15:08,671 - root - INFO - test acc from best model : 81.16
2023-09-05 02:15:08,750 - root - INFO - Epoch 86
-------------------------------
2023-09-05 02:17:56,032 - root - INFO - Época 86/100
2023-09-05 02:17:56,032 - root - INFO - loss: 0.08485820758342742 - accuracy: 97.5225 - val_loss: 0.761730721950531 - val_accuracy: 81.78
2023-09-05 02:17:56,032 - root - INFO - [Test] ---> accuracy: 81.26 - loss: 0.8060637669086457
2023-09-05 02:17:56,032 - root - INFO - test acc from best model : 81.16
2023-09-05 02:17:56,032 - root - INFO - Epoch 87
-------------------------------
2023-09-05 02:20:44,164 - root - INFO - Época 87/100
2023-09-05 02:20:44,164 - root - INFO - loss: 0.08262357258498669 - accuracy: 97.48 - val_loss: 0.7459494581818581 - val_accuracy: 82.97
2023-09-05 02:20:44,164 - root - INFO - [Test] ---> accuracy: 82.49 - loss: 0.7817513033151626
2023-09-05 02:20:44,164 - root - INFO - test acc from best model : 81.16
2023-09-05 02:20:44,164 - root - INFO - Epoch 88
-------------------------------
2023-09-05 02:23:32,226 - root - INFO - Época 88/100
2023-09-05 02:23:32,226 - root - INFO - loss: 0.07560306605994702 - accuracy: 97.6975 - val_loss: 0.874232849252224 - val_accuracy: 81.95
2023-09-05 02:23:32,226 - root - INFO - [Test] ---> accuracy: 81.64 - loss: 0.9070948182940483
2023-09-05 02:23:32,226 - root - INFO - test acc from best model : 81.16
2023-09-05 02:23:32,226 - root - INFO - Epoch 89
-------------------------------
2023-09-05 02:26:20,911 - root - INFO - Época 89/100
2023-09-05 02:26:20,911 - root - INFO - loss: 0.08325926666557788 - accuracy: 97.52 - val_loss: 0.7866749951362609 - val_accuracy: 82.35
2023-09-05 02:26:20,911 - root - INFO - [Test] ---> accuracy: 81.66 - loss: 0.8190360701084137
2023-09-05 02:26:20,911 - root - INFO - test acc from best model : 81.16
2023-09-05 02:26:20,911 - root - INFO - Epoch 90
-------------------------------
2023-09-05 02:29:08,825 - root - INFO - Época 90/100
2023-09-05 02:29:08,825 - root - INFO - loss: 0.07971543446779251 - accuracy: 97.65 - val_loss: 0.8311931800544262 - val_accuracy: 83.09
2023-09-05 02:29:08,826 - root - INFO - [Test] ---> accuracy: 82.89 - loss: 0.8708565112352371
2023-09-05 02:29:08,826 - root - INFO - test acc from best model : 81.16
2023-09-05 02:29:08,900 - root - INFO - Epoch 91
-------------------------------
2023-09-05 02:31:58,991 - root - INFO - Época 91/100
2023-09-05 02:31:58,991 - root - INFO - loss: 0.07349721403419972 - accuracy: 97.6925 - val_loss: 0.7536649668693542 - val_accuracy: 82.96
2023-09-05 02:31:58,991 - root - INFO - [Test] ---> accuracy: 82.28999999999999 - loss: 0.842755779838562
2023-09-05 02:31:58,991 - root - INFO - test acc from best model : 81.16
2023-09-05 02:31:58,991 - root - INFO - Epoch 92
-------------------------------
2023-09-05 02:34:48,615 - root - INFO - Época 92/100
2023-09-05 02:34:48,615 - root - INFO - loss: 0.08135561400651932 - accuracy: 97.55 - val_loss: 0.7090084392935038 - val_accuracy: 83.02000000000001
2023-09-05 02:34:48,615 - root - INFO - [Test] ---> accuracy: 82.92 - loss: 0.744089987897873
2023-09-05 02:34:48,615 - root - INFO - test acc from best model : 81.16
2023-09-05 02:34:48,615 - root - INFO - Epoch 93
-------------------------------
2023-09-05 02:37:37,999 - root - INFO - Época 93/100
2023-09-05 02:37:37,999 - root - INFO - loss: 0.07611187353432179 - accuracy: 97.8025 - val_loss: 0.8663070087194443 - val_accuracy: 81.78
2023-09-05 02:37:37,999 - root - INFO - [Test] ---> accuracy: 81.15 - loss: 0.8958698454141617
2023-09-05 02:37:37,999 - root - INFO - test acc from best model : 81.16
2023-09-05 02:37:37,999 - root - INFO - Epoch 94
-------------------------------
2023-09-05 02:40:26,839 - root - INFO - Época 94/100
2023-09-05 02:40:26,839 - root - INFO - loss: 0.08724847474694251 - accuracy: 97.42 - val_loss: 0.7425542665004731 - val_accuracy: 83.11
2023-09-05 02:40:26,839 - root - INFO - [Test] ---> accuracy: 82.35 - loss: 0.8274999970912933
2023-09-05 02:40:26,839 - root - INFO - test acc from best model : 81.16
2023-09-05 02:40:26,839 - root - INFO - Epoch 95
-------------------------------
2023-09-05 02:43:16,191 - root - INFO - Época 95/100
2023-09-05 02:43:16,191 - root - INFO - loss: 0.07527247611284256 - accuracy: 97.74 - val_loss: 0.7104715891361236 - val_accuracy: 82.91
2023-09-05 02:43:16,191 - root - INFO - [Test] ---> accuracy: 82.44 - loss: 0.7856296958684921
2023-09-05 02:43:16,191 - root - INFO - test acc from best model : 81.16
2023-09-05 02:43:16,272 - root - INFO - Epoch 96
-------------------------------
2023-09-05 02:46:06,977 - root - INFO - Época 96/100
2023-09-05 02:46:06,978 - root - INFO - loss: 0.08021354888975621 - accuracy: 97.8375 - val_loss: 0.9141750707626343 - val_accuracy: 80.91000000000001
2023-09-05 02:46:06,978 - root - INFO - [Test] ---> accuracy: 81.08 - loss: 0.9575593004226685
2023-09-05 02:46:06,978 - root - INFO - test acc from best model : 81.16
2023-09-05 02:46:06,978 - root - INFO - Epoch 97
-------------------------------
2023-09-05 02:48:58,300 - root - INFO - Época 97/100
2023-09-05 02:48:58,300 - root - INFO - loss: 0.0809052679926157 - accuracy: 97.6025 - val_loss: 0.816863122856617 - val_accuracy: 81.64
2023-09-05 02:48:58,300 - root - INFO - [Test] ---> accuracy: 81.44 - loss: 0.8790913969278336
2023-09-05 02:48:58,300 - root - INFO - test acc from best model : 81.16
2023-09-05 02:48:58,300 - root - INFO - Epoch 98
-------------------------------
2023-09-05 02:51:49,600 - root - INFO - Época 98/100
2023-09-05 02:51:49,600 - root - INFO - loss: 0.07093491787016391 - accuracy: 97.845 - val_loss: 0.7889081498146057 - val_accuracy: 82.73
2023-09-05 02:51:49,600 - root - INFO - [Test] ---> accuracy: 82.61 - loss: 0.8687393348455429
2023-09-05 02:51:49,600 - root - INFO - test acc from best model : 81.16
2023-09-05 02:51:49,600 - root - INFO - Epoch 99
-------------------------------
2023-09-05 02:54:41,385 - root - INFO - Época 99/100
2023-09-05 02:54:41,385 - root - INFO - loss: 0.07209028508365155 - accuracy: 97.8525 - val_loss: 1.0269593318462371 - val_accuracy: 81.53
2023-09-05 02:54:41,385 - root - INFO - [Test] ---> accuracy: 81.33 - loss: 1.119685047483444
2023-09-05 02:54:41,385 - root - INFO - test acc from best model : 81.16
2023-09-05 02:54:41,385 - root - INFO - Epoch 100
-------------------------------
2023-09-05 02:57:32,199 - root - INFO - Época 100/100
2023-09-05 02:57:32,199 - root - INFO - loss: 0.06878711622357368 - accuracy: 97.9125 - val_loss: 0.8756844629347325 - val_accuracy: 81.26
2023-09-05 02:57:32,199 - root - INFO - [Test] ---> accuracy: 81.08 - loss: 0.9034061002731323
2023-09-05 02:57:32,199 - root - INFO - test acc from best model : 81.16
2023-09-05 02:57:32,276 - root - INFO - Tempo treinamento:  17603.01 seconds
2023-09-05 02:57:32,276 - root - INFO - Menor loss: 0.6098167386293412
2023-09-05 02:57:32,276 - root - INFO - Acurácia de teste do melhor modelo: 81.16
2023-09-05 02:57:32,277 - root - INFO - Métricas
2023-09-05 02:57:32,277 - root - INFO - ACC
2023-09-05 02:57:32,277 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100],
 'test_acc': [15.409999999999998,
              20.13,
              24.04,
              26.52,
              28.4,
              28.22,
              23.84,
              26.44,
              29.78,
              30.45,
              31.91,
              36.55,
              37.66,
              55.26,
              59.589999999999996,
              60.209999999999994,
              69.98,
              73.50999999999999,
              74.58,
              71.39,
              77.17,
              76.22,
              77.42,
              77.17,
              76.86,
              78.64999999999999,
              78.43,
              77.97,
              77.64999999999999,
              77.79,
              79.91,
              77.42999999999999,
              79.25,
              81.16,
              80.2,
              79.78,
              80.17,
              80.25,
              78.7,
              81.13,
              81.81,
              81.19,
              80.2,
              79.45,
              81.8,
              81.69999999999999,
              80.85,
              81.33,
              80.96,
              80.0,
              80.71000000000001,
              81.38,
              81.78999999999999,
              80.58999999999999,
              77.45,
              81.44,
              81.17,
              81.36,
              80.60000000000001,
              81.55,
              81.99,
              81.77,
              81.67,
              82.16,
              82.0,
              81.84,
              78.64,
              81.72,
              81.78999999999999,
              81.39,
              81.78,
              81.85,
              79.57,
              82.6,
              81.65,
              81.52000000000001,
              82.05,
              79.97,
              82.54,
              81.32000000000001,
              81.58999999999999,
              81.67,
              82.13000000000001,
              81.34,
              81.13,
              81.26,
              82.49,
              81.64,
              81.66,
              82.89,
              82.28999999999999,
              82.92,
              81.15,
              82.35,
              82.44,
              81.08,
              81.44,
              82.61,
              81.33,
              81.08],
 'train_acc': [15.395,
               19.115,
               20.4975,
               21.5275,
               22.3675,
               23.12,
               23.98,
               24.0325,
               24.8625,
               26.1875,
               28.3975,
               30.34,
               34.2275,
               44.6375,
               58.63,
               64.9875,
               69.7475,
               72.68,
               74.8075,
               77.0575,
               78.3475,
               80.1575,
               81.4375,
               82.8325,
               83.8,
               84.9025,
               85.9125,
               86.8775,
               87.5925,
               88.405,
               89.225,
               89.8875,
               90.28,
               91.215,
               91.4275,
               92.0,
               92.4,
               92.6325,
               92.7425,
               93.32,
               93.63,
               93.4825,
               94.1425,
               94.215,
               94.58,
               94.755,
               94.6625,
               95.045,
               95.0375,
               95.315,
               95.345,
               95.4025,
               95.8025,
               96.025,
               95.7975,
               96.0125,
               95.9675,
               96.0925,
               96.37,
               96.23,
               96.46,
               96.5225,
               96.4375,
               96.62,
               96.775,
               96.645,
               96.79,
               96.9125,
               96.635,
               96.9675,
               97.1175,
               96.965,
               97.2275,
               97.0375,
               97.3075,
               97.09,
               97.23,
               97.4425,
               97.4125,
               97.335,
               97.205,
               97.345,
               97.535,
               97.555,
               97.58,
               97.5225,
               97.48,
               97.6975,
               97.52,
               97.65,
               97.6925,
               97.55,
               97.8025,
               97.42,
               97.74,
               97.8375,
               97.6025,
               97.845,
               97.8525,
               97.9125],
 'val_acc': [15.479999999999999,
             20.349999999999998,
             23.369999999999997,
             27.310000000000002,
             28.13,
             28.73,
             24.39,
             27.35,
             30.39,
             30.85,
             32.59,
             36.63,
             37.79,
             55.489999999999995,
             60.08,
             59.64,
             69.17,
             73.72,
             74.35000000000001,
             71.55,
             76.75999999999999,
             76.1,
             77.06,
             77.71000000000001,
             77.25999999999999,
             78.94,
             78.95,
             78.19,
             78.53,
             77.94,
             80.17999999999999,
             77.42999999999999,
             79.23,
             81.37,
             81.31,
             80.62,
             80.78999999999999,
             80.83,
             78.97,
             81.15,
             81.57,
             81.15,
             80.16,
             79.7,
             81.85,
             81.78,
             81.23,
             81.51,
             81.89,
             80.36999999999999,
             81.46,
             81.78999999999999,
             82.05,
             80.82000000000001,
             77.61,
             81.07,
             81.46,
             81.63,
             81.11,
             80.76,
             82.13000000000001,
             82.28,
             81.71000000000001,
             82.46,
             81.76,
             81.89,
             79.11,
             82.55,
             82.6,
             81.47,
             81.35,
             82.34,
             79.86999999999999,
             82.69,
             82.02000000000001,
             81.47999999999999,
             82.12,
             80.27,
             82.97,
             81.78,
             81.75,
             82.05,
             82.49,
             82.31,
             81.77,
             81.78,
             82.97,
             81.95,
             82.35,
             83.09,
             82.96,
             83.02000000000001,
             81.78,
             83.11,
             82.91,
             80.91000000000001,
             81.64,
             82.73,
             81.53,
             81.26]}
2023-09-05 02:57:32,277 - root - INFO - LOSS
2023-09-05 02:57:32,278 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100],
 'test_loss': [2.114192194747925,
               2.0590209075927732,
               1.9627798908233642,
               1.9466232204437255,
               1.8923910562515258,
               1.836755936050415,
               1.9093045345306396,
               1.8379403427124024,
               1.7994854919433594,
               1.7527482814788817,
               1.7923979181289673,
               1.6423573808670044,
               1.6076911539077758,
               1.2792566398620606,
               1.1564958667755127,
               1.1692074193954467,
               0.882500066280365,
               0.7788986131668091,
               0.7423319101333619,
               0.8492052605628967,
               0.671641198015213,
               0.7097757928848266,
               0.6832233072280883,
               0.6854573731422424,
               0.6988263836860656,
               0.6276711808204651,
               0.6390324194908142,
               0.6625468245983124,
               0.7197536305427551,
               0.6882409098625183,
               0.6404700518131257,
               0.7548455770015716,
               0.681887575674057,
               0.6239709537267685,
               0.6541989131450653,
               0.664357028722763,
               0.6462825572967529,
               0.6771549742698669,
               0.728313057756424,
               0.6582219343662262,
               0.6918084823608398,
               0.6471849099874496,
               0.7026894738674164,
               0.8074714514255523,
               0.657170248556137,
               0.6818619888305664,
               0.7557995871901512,
               0.7046606834888458,
               0.6829698043823242,
               0.7143791161060333,
               0.7705912331104279,
               0.6842747146129609,
               0.6747740317344666,
               0.7815539556980133,
               1.0101121420383454,
               0.7628015208244324,
               0.7006401941776276,
               0.7434349426984787,
               0.7148997392177582,
               0.7224074882984162,
               0.7671113625526428,
               0.7421630633234978,
               0.7382054352998734,
               0.7491326471328735,
               0.758790346288681,
               0.7319419445157052,
               0.8597828391075134,
               0.7530332735776901,
               0.7174050607681275,
               0.8295620781183243,
               0.8318727450609207,
               0.7994831505537033,
               0.9229232183456421,
               0.8536839132547378,
               0.8097361855745315,
               0.7668240172147751,
               0.8023887956142426,
               0.9945329634189606,
               0.7770234799027443,
               0.8674131199836731,
               0.7750437397003174,
               0.949734015417099,
               0.8203060480117798,
               0.8754858816623687,
               0.8656597735881806,
               0.8060637669086457,
               0.7817513033151626,
               0.9070948182940483,
               0.8190360701084137,
               0.8708565112352371,
               0.842755779838562,
               0.744089987897873,
               0.8958698454141617,
               0.8274999970912933,
               0.7856296958684921,
               0.9575593004226685,
               0.8790913969278336,
               0.8687393348455429,
               1.119685047483444,
               0.9034061002731323],
 'train_loss': [2.326033462524414,
                2.0539182434082033,
                2.0127281311035157,
                1.9645008544921876,
                1.9479048309326172,
                1.9327814372062684,
                1.8950315155029296,
                1.8753048736572266,
                1.8672217339515687,
                1.8318313613891601,
                1.7760307242393494,
                1.735482334804535,
                1.6616251173973084,
                1.4786832658290863,
                1.1778849575042725,
                1.0063882896661758,
                0.8841121549844742,
                0.7952214593172073,
                0.7365865060925484,
                0.6683504303455353,
                0.6278304683446884,
                0.5844931870937348,
                0.5376224076390267,
                0.5011538100361824,
                0.46863174087405207,
                0.4330073257297277,
                0.4082994262248278,
                0.37790866471529005,
                0.3617685905843973,
                0.3356365688741207,
                0.3174362778484821,
                0.2958101069509983,
                0.288112797281146,
                0.2624661784529686,
                0.25569608822166917,
                0.23501091201901436,
                0.2247560220569372,
                0.21951306509077548,
                0.21644164247214795,
                0.20071102596521379,
                0.18841556832194328,
                0.19805256915986538,
                0.17433802019953729,
                0.17386590805351734,
                0.16096212057471276,
                0.15974639518857003,
                0.1622056651443243,
                0.15108854891359805,
                0.1533267298281193,
                0.14359560829997062,
                0.14434874868392944,
                0.13835382165908813,
                0.13390409474372864,
                0.12582911858558654,
                0.12763954542577266,
                0.12624994773864745,
                0.12692325660586357,
                0.12173986706137657,
                0.11341022970676422,
                0.11806865494549275,
                0.11145166303217412,
                0.11298678324520588,
                0.11169760246276855,
                0.10668407175540924,
                0.10240874201357365,
                0.1093020317196846,
                0.10334892293214798,
                0.10038743601739407,
                0.11356953257620335,
                0.09767484279870987,
                0.09392793090939522,
                0.10146165556013584,
                0.0914937890380621,
                0.09599235569834709,
                0.08827283857762813,
                0.09458956009149551,
                0.09235051701664924,
                0.08315027400851249,
                0.08703762114346027,
                0.08659378823637963,
                0.08852972481548786,
                0.08431957675218582,
                0.08554014118611812,
                0.08184937122762204,
                0.08136408534646035,
                0.08485820758342742,
                0.08262357258498669,
                0.07560306605994702,
                0.08325926666557788,
                0.07971543446779251,
                0.07349721403419972,
                0.08135561400651932,
                0.07611187353432179,
                0.08724847474694251,
                0.07527247611284256,
                0.08021354888975621,
                0.0809052679926157,
                0.07093491787016391,
                0.07209028508365155,
                0.06878711622357368],
 'val_loss': [2.1182395217895507,
              2.0564303113937377,
              1.9598783405303954,
              1.942398168182373,
              1.8884746889114379,
              1.8348392635345459,
              1.9081265228271485,
              1.8326002731323243,
              1.7913451705932617,
              1.75036096534729,
              1.783675594329834,
              1.6405277690887452,
              1.6033670886993407,
              1.269368257522583,
              1.1487375593185425,
              1.170508519935608,
              0.8877777485847473,
              0.7764234422683716,
              0.7399538298606873,
              0.8321264227867127,
              0.6684529737472534,
              0.7157380451202393,
              0.6798519574642181,
              0.6612658009529114,
              0.6780993472099304,
              0.6195021769523621,
              0.6318772480964661,
              0.6652390655040741,
              0.6920778087854386,
              0.6749455214977265,
              0.6166287036657333,
              0.75913815908432,
              0.6859689739227295,
              0.6098167386293412,
              0.6329094537258149,
              0.646925405216217,
              0.6294212791919708,
              0.6424148235082626,
              0.7108503046989441,
              0.6332642207145691,
              0.6576570084810257,
              0.6319839037418366,
              0.6709957312345505,
              0.7852601150274277,
              0.6265435689210892,
              0.6545328705787659,
              0.726431486582756,
              0.6652149670362473,
              0.63246739372015,
              0.6962653107643128,
              0.714704098534584,
              0.6615014882147312,
              0.6334512444257736,
              0.7551509688615798,
              0.9816417651414872,
              0.7548118794828653,
              0.6787093587875366,
              0.7181829864501953,
              0.6804045594215393,
              0.7148195631742478,
              0.7213523770332336,
              0.7029774092674256,
              0.6967541243314743,
              0.7061336977005005,
              0.726993879032135,
              0.7058147246837616,
              0.8236826464176178,
              0.6897205457210541,
              0.692133764076233,
              0.7936740294218063,
              0.8271798293232918,
              0.7534234078884124,
              0.8938590287446976,
              0.8142082316815853,
              0.7716515335798264,
              0.751390380859375,
              0.7882193229198455,
              0.9108350144267082,
              0.7312053076028824,
              0.8339260102421046,
              0.7135952661275864,
              0.906541862475872,
              0.7763978172063828,
              0.7888440956830979,
              0.8122626767873764,
              0.761730721950531,
              0.7459494581818581,
              0.874232849252224,
              0.7866749951362609,
              0.8311931800544262,
              0.7536649668693542,
              0.7090084392935038,
              0.8663070087194443,
              0.7425542665004731,
              0.7104715891361236,
              0.9141750707626343,
              0.816863122856617,
              0.7889081498146057,
              1.0269593318462371,
              0.8756844629347325]}
2023-09-08 02:04:48,383 - root - INFO - --------------------- Iniciando Teste 81 ---------------------
2023-09-08 02:04:48,383 - root - INFO - Rodando evaluation
2023-09-08 02:04:48,386 - root - INFO - Construindo dataset para a rede ALEXNET
2023-09-08 03:47:32,085 - root - INFO - --------------------- Iniciando Teste 81 ---------------------
2023-09-08 03:47:32,085 - root - INFO - Rodando evaluation
2023-09-08 03:47:32,089 - root - INFO - Construindo dataset para a rede ALEXNET
2023-09-08 14:55:48,434 - root - INFO - --------------------- Iniciando Novo Treinamento 81 ---------------------
2023-09-08 14:55:48,436 - root - INFO - Parametros
2023-09-08 14:55:48,436 - root - INFO - {'batch_size': 32,
 'dataset': 'CIFAR10',
 'epochs': 100,
 'learning_rate': 0.001,
 'network': 'ALEXNET',
 'num_workers': 1}
2023-09-08 14:55:48,436 - root - INFO - Construindo dataset para a rede ALEXNET
2023-09-08 14:55:53,656 - root - INFO - AlexNet(
  (layer1): Sequential(
    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer2): Sequential(
    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer3): Sequential(
    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer4): Sequential(
    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer5): Sequential(
    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU()
  )
  (fc1): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=4096, out_features=4096, bias=True)
    (2): ReLU()
  )
  (fc2): Sequential(
    (0): Linear(in_features=4096, out_features=10, bias=True)
  )
)
2023-09-08 14:55:53,657 - root - INFO - Iniciando treinamento
2023-09-08 14:55:53,657 - root - INFO - Epoch 1
-------------------------------
2023-09-08 14:59:02,696 - root - INFO - Validation loss decreased from : inf ----> 2.0369311241149903 ----> Saving Model.......
2023-09-08 14:59:02,696 - root - INFO - Validation acc:  17.21
2023-09-08 14:59:02,696 - root - INFO - Best Test acc from 0 ----> 16.99
2023-09-08 14:59:09,816 - root - INFO - Época 1/100
2023-09-08 14:59:09,817 - root - INFO - loss: 2.327380446434021 - accuracy: 15.6825 - val_loss: 2.0369311241149903 - val_accuracy: 17.21
2023-09-08 14:59:09,817 - root - INFO - [Test] ---> accuracy: 16.99 - loss: 2.035172769355774
2023-09-08 14:59:09,817 - root - INFO - test acc from best model : 16.99
2023-09-08 14:59:09,817 - root - INFO - Epoch 2
-------------------------------
2023-09-08 15:02:08,006 - root - INFO - Validation loss decreased from : 2.0369311241149903 ----> 1.9709011137008667 ----> Saving Model.......
2023-09-08 15:02:08,006 - root - INFO - Validation acc:  20.51
2023-09-08 15:02:08,006 - root - INFO - Best Test acc from 16.99 ----> 21.19
2023-09-08 15:02:14,661 - root - INFO - Época 2/100
2023-09-08 15:02:14,661 - root - INFO - loss: 2.0653532775878904 - accuracy: 17.66 - val_loss: 1.9709011137008667 - val_accuracy: 20.51
2023-09-08 15:02:14,661 - root - INFO - [Test] ---> accuracy: 21.19 - loss: 1.9698109775543213
2023-09-08 15:02:14,662 - root - INFO - test acc from best model : 21.19
2023-09-08 15:02:14,662 - root - INFO - Epoch 3
-------------------------------
2023-09-08 15:05:11,754 - root - INFO - Época 3/100
2023-09-08 15:05:11,754 - root - INFO - loss: 2.0113272052764892 - accuracy: 19.8375 - val_loss: 1.9836784076690674 - val_accuracy: 21.29
2023-09-08 15:05:11,754 - root - INFO - [Test] ---> accuracy: 21.07 - loss: 1.9830413570404053
2023-09-08 15:05:11,754 - root - INFO - test acc from best model : 21.19
2023-09-08 15:05:11,754 - root - INFO - Epoch 4
-------------------------------
2023-09-08 15:08:08,440 - root - INFO - Época 4/100
2023-09-08 15:08:08,440 - root - INFO - loss: 1.9907211059570313 - accuracy: 21.3425 - val_loss: 1.9882496318817138 - val_accuracy: 21.78
2023-09-08 15:08:08,440 - root - INFO - [Test] ---> accuracy: 21.69 - loss: 1.9916964183807373
2023-09-08 15:08:08,440 - root - INFO - test acc from best model : 21.19
2023-09-08 15:08:08,440 - root - INFO - Epoch 5
-------------------------------
2023-09-08 15:11:05,166 - root - INFO - Validation loss decreased from : 1.9709011137008667 ----> 1.9265107006073 ----> Saving Model.......
2023-09-08 15:11:05,166 - root - INFO - Validation acc:  25.590000000000003
2023-09-08 15:11:05,166 - root - INFO - Best Test acc from 21.19 ----> 25.069999999999997
2023-09-08 15:11:12,085 - root - INFO - Época 5/100
2023-09-08 15:11:12,085 - root - INFO - loss: 1.9537285400390625 - accuracy: 23.025 - val_loss: 1.9265107006073 - val_accuracy: 25.590000000000003
2023-09-08 15:11:12,085 - root - INFO - [Test] ---> accuracy: 25.069999999999997 - loss: 1.9238570152282715
2023-09-08 15:11:12,085 - root - INFO - test acc from best model : 25.069999999999997
2023-09-08 15:11:12,465 - root - INFO - Epoch 6
-------------------------------
2023-09-08 15:14:16,867 - root - INFO - Validation loss decreased from : 1.9265107006073 ----> 1.8649197931289674 ----> Saving Model.......
2023-09-08 15:14:16,867 - root - INFO - Validation acc:  27.63
2023-09-08 15:14:16,867 - root - INFO - Best Test acc from 25.069999999999997 ----> 27.41
2023-09-08 15:14:23,851 - root - INFO - Época 6/100
2023-09-08 15:14:23,851 - root - INFO - loss: 1.922080062866211 - accuracy: 24.7625 - val_loss: 1.8649197931289674 - val_accuracy: 27.63
2023-09-08 15:14:23,851 - root - INFO - [Test] ---> accuracy: 27.41 - loss: 1.8628646827697755
2023-09-08 15:14:23,851 - root - INFO - test acc from best model : 27.41
2023-09-08 15:14:23,851 - root - INFO - Epoch 7
-------------------------------
2023-09-08 15:17:28,238 - root - INFO - Época 7/100
2023-09-08 15:17:28,238 - root - INFO - loss: 1.8919677715301513 - accuracy: 26.235 - val_loss: 1.9047248699188233 - val_accuracy: 26.99
2023-09-08 15:17:28,238 - root - INFO - [Test] ---> accuracy: 26.57 - loss: 1.9085555545806885
2023-09-08 15:17:28,238 - root - INFO - test acc from best model : 27.41
2023-09-08 15:17:28,238 - root - INFO - Epoch 8
-------------------------------
2023-09-08 15:20:32,542 - root - INFO - Validation loss decreased from : 1.8649197931289674 ----> 1.7695789957046508 ----> Saving Model.......
2023-09-08 15:20:32,543 - root - INFO - Validation acc:  30.330000000000002
2023-09-08 15:20:32,543 - root - INFO - Best Test acc from 27.41 ----> 30.240000000000002
2023-09-08 15:20:39,322 - root - INFO - Época 8/100
2023-09-08 15:20:39,322 - root - INFO - loss: 1.8510816076278687 - accuracy: 27.7675 - val_loss: 1.7695789957046508 - val_accuracy: 30.330000000000002
2023-09-08 15:20:39,322 - root - INFO - [Test] ---> accuracy: 30.240000000000002 - loss: 1.7749256187438964
2023-09-08 15:20:39,322 - root - INFO - test acc from best model : 30.240000000000002
2023-09-08 15:20:39,322 - root - INFO - Epoch 9
-------------------------------
2023-09-08 15:23:42,949 - root - INFO - Validation loss decreased from : 1.7695789957046508 ----> 1.7555222415924072 ----> Saving Model.......
2023-09-08 15:23:42,949 - root - INFO - Validation acc:  30.78
2023-09-08 15:23:42,949 - root - INFO - Best Test acc from 30.240000000000002 ----> 31.419999999999998
2023-09-08 15:23:49,740 - root - INFO - Época 9/100
2023-09-08 15:23:49,741 - root - INFO - loss: 1.816442316532135 - accuracy: 30.0175 - val_loss: 1.7555222415924072 - val_accuracy: 30.78
2023-09-08 15:23:49,741 - root - INFO - [Test] ---> accuracy: 31.419999999999998 - loss: 1.763641325187683
2023-09-08 15:23:49,741 - root - INFO - test acc from best model : 31.419999999999998
2023-09-08 15:23:49,741 - root - INFO - Epoch 10
-------------------------------
2023-09-08 15:26:53,669 - root - INFO - Validation loss decreased from : 1.7555222415924072 ----> 1.7048199138641358 ----> Saving Model.......
2023-09-08 15:26:53,669 - root - INFO - Validation acc:  31.540000000000003
2023-09-08 15:26:53,669 - root - INFO - Best Test acc from 31.419999999999998 ----> 31.46
2023-09-08 15:27:00,587 - root - INFO - Época 10/100
2023-09-08 15:27:00,587 - root - INFO - loss: 1.7374155264854432 - accuracy: 32.35 - val_loss: 1.7048199138641358 - val_accuracy: 31.540000000000003
2023-09-08 15:27:00,587 - root - INFO - [Test] ---> accuracy: 31.46 - loss: 1.7098366804122924
2023-09-08 15:27:00,587 - root - INFO - test acc from best model : 31.46
2023-09-08 15:27:00,934 - root - INFO - Epoch 11
-------------------------------
2023-09-08 15:30:11,576 - root - INFO - Validation loss decreased from : 1.7048199138641358 ----> 1.629403426551819 ----> Saving Model.......
2023-09-08 15:30:11,576 - root - INFO - Validation acc:  36.88
2023-09-08 15:30:11,576 - root - INFO - Best Test acc from 31.46 ----> 36.67
2023-09-08 15:30:18,366 - root - INFO - Época 11/100
2023-09-08 15:30:18,367 - root - INFO - loss: 1.7099829559326172 - accuracy: 33.66 - val_loss: 1.629403426551819 - val_accuracy: 36.88
2023-09-08 15:30:18,367 - root - INFO - [Test] ---> accuracy: 36.67 - loss: 1.6318211357116699
2023-09-08 15:30:18,367 - root - INFO - test acc from best model : 36.67
2023-09-08 15:30:18,367 - root - INFO - Epoch 12
-------------------------------
2023-09-08 15:33:27,838 - root - INFO - Época 12/100
2023-09-08 15:33:27,838 - root - INFO - loss: 1.6561635581970215 - accuracy: 35.0375 - val_loss: 1.6448889556884765 - val_accuracy: 36.04
2023-09-08 15:33:27,838 - root - INFO - [Test] ---> accuracy: 35.89 - loss: 1.650234722518921
2023-09-08 15:33:27,838 - root - INFO - test acc from best model : 36.67
2023-09-08 15:33:27,838 - root - INFO - Epoch 13
-------------------------------
2023-09-08 15:36:37,955 - root - INFO - Validation loss decreased from : 1.629403426551819 ----> 1.5720264892578124 ----> Saving Model.......
2023-09-08 15:36:37,955 - root - INFO - Validation acc:  37.76
2023-09-08 15:36:37,955 - root - INFO - Best Test acc from 36.67 ----> 37.76
2023-09-08 15:36:44,691 - root - INFO - Época 13/100
2023-09-08 15:36:44,691 - root - INFO - loss: 1.6445924494743347 - accuracy: 35.875 - val_loss: 1.5720264892578124 - val_accuracy: 37.76
2023-09-08 15:36:44,691 - root - INFO - [Test] ---> accuracy: 37.76 - loss: 1.5798143896102905
2023-09-08 15:36:44,691 - root - INFO - test acc from best model : 37.76
2023-09-08 15:36:44,691 - root - INFO - Epoch 14
-------------------------------
2023-09-08 15:39:54,374 - root - INFO - Época 14/100
2023-09-08 15:39:54,375 - root - INFO - loss: 1.6249516102790833 - accuracy: 37.0725 - val_loss: 1.5762370391845704 - val_accuracy: 40.26
2023-09-08 15:39:54,375 - root - INFO - [Test] ---> accuracy: 40.21 - loss: 1.5768300464630127
2023-09-08 15:39:54,375 - root - INFO - test acc from best model : 37.76
2023-09-08 15:39:54,375 - root - INFO - Epoch 15
-------------------------------
2023-09-08 15:43:04,810 - root - INFO - Validation loss decreased from : 1.5720264892578124 ----> 1.4787694248199463 ----> Saving Model.......
2023-09-08 15:43:04,810 - root - INFO - Validation acc:  46.2
2023-09-08 15:43:04,810 - root - INFO - Best Test acc from 37.76 ----> 45.050000000000004
2023-09-08 15:43:11,768 - root - INFO - Época 15/100
2023-09-08 15:43:11,768 - root - INFO - loss: 1.5362846866607667 - accuracy: 41.0 - val_loss: 1.4787694248199463 - val_accuracy: 46.2
2023-09-08 15:43:11,768 - root - INFO - [Test] ---> accuracy: 45.050000000000004 - loss: 1.4896912115097045
2023-09-08 15:43:11,768 - root - INFO - test acc from best model : 45.050000000000004
2023-09-08 15:43:12,136 - root - INFO - Epoch 16
-------------------------------
2023-09-08 15:46:28,302 - root - INFO - Época 16/100
2023-09-08 15:46:28,302 - root - INFO - loss: 1.4668784328460693 - accuracy: 43.7775 - val_loss: 1.58886392288208 - val_accuracy: 40.32
2023-09-08 15:46:28,302 - root - INFO - [Test] ---> accuracy: 40.03 - loss: 1.5929228084564209
2023-09-08 15:46:28,302 - root - INFO - test acc from best model : 45.050000000000004
2023-09-08 15:46:28,302 - root - INFO - Epoch 17
-------------------------------
2023-09-08 15:49:43,865 - root - INFO - Validation loss decreased from : 1.4787694248199463 ----> 1.2324202653884888 ----> Saving Model.......
2023-09-08 15:49:43,865 - root - INFO - Validation acc:  57.32000000000001
2023-09-08 15:49:43,865 - root - INFO - Best Test acc from 45.050000000000004 ----> 57.440000000000005
2023-09-08 15:49:50,555 - root - INFO - Época 17/100
2023-09-08 15:49:50,555 - root - INFO - loss: 1.3151786757469177 - accuracy: 51.335 - val_loss: 1.2324202653884888 - val_accuracy: 57.32000000000001
2023-09-08 15:49:50,555 - root - INFO - [Test] ---> accuracy: 57.440000000000005 - loss: 1.2214871461868286
2023-09-08 15:49:50,555 - root - INFO - test acc from best model : 57.440000000000005
2023-09-08 15:49:50,555 - root - INFO - Epoch 18
-------------------------------
2023-09-08 15:53:10,607 - root - INFO - Validation loss decreased from : 1.2324202653884888 ----> 1.015370093345642 ----> Saving Model.......
2023-09-08 15:53:10,607 - root - INFO - Validation acc:  64.13
2023-09-08 15:53:10,608 - root - INFO - Best Test acc from 57.440000000000005 ----> 64.02
2023-09-08 15:53:17,479 - root - INFO - Época 18/100
2023-09-08 15:53:17,480 - root - INFO - loss: 1.0641412907361985 - accuracy: 63.1825 - val_loss: 1.015370093345642 - val_accuracy: 64.13
2023-09-08 15:53:17,480 - root - INFO - [Test] ---> accuracy: 64.02 - loss: 1.0156470615386963
2023-09-08 15:53:17,480 - root - INFO - test acc from best model : 64.02
2023-09-08 15:53:17,480 - root - INFO - Epoch 19
-------------------------------
2023-09-08 15:56:39,433 - root - INFO - Validation loss decreased from : 1.015370093345642 ----> 0.9325812507629394 ----> Saving Model.......
2023-09-08 15:56:39,434 - root - INFO - Validation acc:  68.35
2023-09-08 15:56:39,434 - root - INFO - Best Test acc from 64.02 ----> 68.46
2023-09-08 15:56:46,465 - root - INFO - Época 19/100
2023-09-08 15:56:46,465 - root - INFO - loss: 0.9044234835386277 - accuracy: 68.99 - val_loss: 0.9325812507629394 - val_accuracy: 68.35
2023-09-08 15:56:46,465 - root - INFO - [Test] ---> accuracy: 68.46 - loss: 0.9363869753837586
2023-09-08 15:56:46,465 - root - INFO - test acc from best model : 68.46
2023-09-08 15:56:46,465 - root - INFO - Epoch 20
-------------------------------
2023-09-08 16:00:05,217 - root - INFO - Validation loss decreased from : 0.9325812507629394 ----> 0.8752803047180175 ----> Saving Model.......
2023-09-08 16:00:05,218 - root - INFO - Validation acc:  71.16
2023-09-08 16:00:05,218 - root - INFO - Best Test acc from 68.46 ----> 71.02000000000001
2023-09-08 16:00:12,006 - root - INFO - Época 20/100
2023-09-08 16:00:12,006 - root - INFO - loss: 0.8063048356294632 - accuracy: 72.4075 - val_loss: 0.8752803047180175 - val_accuracy: 71.16
2023-09-08 16:00:12,006 - root - INFO - [Test] ---> accuracy: 71.02000000000001 - loss: 0.8775035544395446
2023-09-08 16:00:12,006 - root - INFO - test acc from best model : 71.02000000000001
2023-09-08 16:00:12,389 - root - INFO - Epoch 21
-------------------------------
2023-09-08 16:03:39,025 - root - INFO - Validation loss decreased from : 0.8752803047180175 ----> 0.7357996195793152 ----> Saving Model.......
2023-09-08 16:03:39,025 - root - INFO - Validation acc:  75.22
2023-09-08 16:03:39,025 - root - INFO - Best Test acc from 71.02000000000001 ----> 75.86
2023-09-08 16:03:45,874 - root - INFO - Época 21/100
2023-09-08 16:03:45,874 - root - INFO - loss: 0.7333401283860207 - accuracy: 75.1875 - val_loss: 0.7357996195793152 - val_accuracy: 75.22
2023-09-08 16:03:45,874 - root - INFO - [Test] ---> accuracy: 75.86 - loss: 0.7254797939300537
2023-09-08 16:03:45,874 - root - INFO - test acc from best model : 75.86
2023-09-08 16:03:45,875 - root - INFO - Epoch 22
-------------------------------
2023-09-08 16:07:09,385 - root - INFO - Época 22/100
2023-09-08 16:07:09,385 - root - INFO - loss: 0.6688307131767273 - accuracy: 77.3325 - val_loss: 0.8342181217193604 - val_accuracy: 71.44
2023-09-08 16:07:09,385 - root - INFO - [Test] ---> accuracy: 70.73 - loss: 0.835503337097168
2023-09-08 16:07:09,385 - root - INFO - test acc from best model : 75.86
2023-09-08 16:07:09,385 - root - INFO - Epoch 23
-------------------------------
2023-09-08 16:10:32,583 - root - INFO - Validation loss decreased from : 0.7357996195793152 ----> 0.7015190236091614 ----> Saving Model.......
2023-09-08 16:10:32,583 - root - INFO - Validation acc:  75.91
2023-09-08 16:10:32,584 - root - INFO - Best Test acc from 75.86 ----> 75.76
2023-09-08 16:10:39,590 - root - INFO - Época 23/100
2023-09-08 16:10:39,590 - root - INFO - loss: 0.6047717936754227 - accuracy: 79.49 - val_loss: 0.7015190236091614 - val_accuracy: 75.91
2023-09-08 16:10:39,590 - root - INFO - [Test] ---> accuracy: 75.76 - loss: 0.701475903224945
2023-09-08 16:10:39,590 - root - INFO - test acc from best model : 75.76
2023-09-08 16:10:39,591 - root - INFO - Epoch 24
-------------------------------
2023-09-08 16:14:04,078 - root - INFO - Época 24/100
2023-09-08 16:14:04,078 - root - INFO - loss: 0.5595427941858768 - accuracy: 81.045 - val_loss: 0.7245643667221069 - val_accuracy: 76.01
2023-09-08 16:14:04,078 - root - INFO - [Test] ---> accuracy: 75.3 - loss: 0.7145742201805114
2023-09-08 16:14:04,078 - root - INFO - test acc from best model : 75.76
2023-09-08 16:14:04,078 - root - INFO - Epoch 25
-------------------------------
2023-09-08 16:17:27,783 - root - INFO - Validation loss decreased from : 0.7015190236091614 ----> 0.6897346259117126 ----> Saving Model.......
2023-09-08 16:17:27,783 - root - INFO - Validation acc:  76.84
2023-09-08 16:17:27,783 - root - INFO - Best Test acc from 75.76 ----> 76.74
2023-09-08 16:17:34,757 - root - INFO - Época 25/100
2023-09-08 16:17:34,757 - root - INFO - loss: 0.5197633607208729 - accuracy: 82.4025 - val_loss: 0.6897346259117126 - val_accuracy: 76.84
2023-09-08 16:17:34,757 - root - INFO - [Test] ---> accuracy: 76.74 - loss: 0.6958864019393921
2023-09-08 16:17:34,757 - root - INFO - test acc from best model : 76.74
2023-09-08 16:17:35,112 - root - INFO - Epoch 26
-------------------------------
2023-09-08 16:21:05,184 - root - INFO - Época 26/100
2023-09-08 16:21:05,184 - root - INFO - loss: 0.4801275310456753 - accuracy: 83.75 - val_loss: 0.8141880714416504 - val_accuracy: 72.14
2023-09-08 16:21:05,184 - root - INFO - [Test] ---> accuracy: 72.39999999999999 - loss: 0.8148795312404633
2023-09-08 16:21:05,184 - root - INFO - test acc from best model : 76.74
2023-09-08 16:21:05,184 - root - INFO - Epoch 27
-------------------------------
2023-09-08 16:24:22,968 - root - INFO - Época 27/100
2023-09-08 16:24:22,968 - root - INFO - loss: 0.4480174139022827 - accuracy: 84.875 - val_loss: 0.7042673814296723 - val_accuracy: 76.63
2023-09-08 16:24:22,968 - root - INFO - [Test] ---> accuracy: 76.64 - loss: 0.7170697629928589
2023-09-08 16:24:22,968 - root - INFO - test acc from best model : 76.74
2023-09-08 16:24:22,968 - root - INFO - Epoch 28
-------------------------------
2023-09-08 16:27:39,174 - root - INFO - Validation loss decreased from : 0.6897346259117126 ----> 0.6091819674491882 ----> Saving Model.......
2023-09-08 16:27:39,174 - root - INFO - Validation acc:  80.22
2023-09-08 16:27:39,174 - root - INFO - Best Test acc from 76.74 ----> 80.13
2023-09-08 16:27:45,918 - root - INFO - Época 28/100
2023-09-08 16:27:45,918 - root - INFO - loss: 0.4087160478711128 - accuracy: 85.97 - val_loss: 0.6091819674491882 - val_accuracy: 80.22
2023-09-08 16:27:45,918 - root - INFO - [Test] ---> accuracy: 80.13 - loss: 0.6204772177219391
2023-09-08 16:27:45,918 - root - INFO - test acc from best model : 80.13
2023-09-08 16:27:45,918 - root - INFO - Epoch 29
-------------------------------
2023-09-08 16:31:02,246 - root - INFO - Época 29/100
2023-09-08 16:31:02,246 - root - INFO - loss: 0.38312381764948367 - accuracy: 86.8975 - val_loss: 0.6880000712394715 - val_accuracy: 78.14
2023-09-08 16:31:02,246 - root - INFO - [Test] ---> accuracy: 77.94 - loss: 0.693137110710144
2023-09-08 16:31:02,246 - root - INFO - test acc from best model : 80.13
2023-09-08 16:31:02,246 - root - INFO - Epoch 30
-------------------------------
2023-09-08 16:34:19,234 - root - INFO - Época 30/100
2023-09-08 16:34:19,234 - root - INFO - loss: 0.35012420085668566 - accuracy: 87.8975 - val_loss: 0.6105192315101624 - val_accuracy: 79.9
2023-09-08 16:34:19,234 - root - INFO - [Test] ---> accuracy: 80.23 - loss: 0.6013777949810029
2023-09-08 16:34:19,234 - root - INFO - test acc from best model : 80.13
2023-09-08 16:34:19,600 - root - INFO - Epoch 31
-------------------------------
2023-09-08 16:37:41,831 - root - INFO - Época 31/100
2023-09-08 16:37:41,831 - root - INFO - loss: 0.3318242059469223 - accuracy: 88.69 - val_loss: 0.6506590530872345 - val_accuracy: 79.43
2023-09-08 16:37:41,831 - root - INFO - [Test] ---> accuracy: 79.62 - loss: 0.6488700201511383
2023-09-08 16:37:41,831 - root - INFO - test acc from best model : 80.13
2023-09-08 16:37:41,831 - root - INFO - Epoch 32
-------------------------------
2023-09-08 16:41:04,218 - root - INFO - Época 32/100
2023-09-08 16:41:04,219 - root - INFO - loss: 0.30516962498426436 - accuracy: 89.5825 - val_loss: 0.6248331498146057 - val_accuracy: 80.04
2023-09-08 16:41:04,219 - root - INFO - [Test] ---> accuracy: 80.4 - loss: 0.6335166896820068
2023-09-08 16:41:04,219 - root - INFO - test acc from best model : 80.13
2023-09-08 16:41:04,219 - root - INFO - Epoch 33
-------------------------------
2023-09-08 16:44:42,423 - root - INFO - Época 33/100
2023-09-08 16:44:42,423 - root - INFO - loss: 0.2908138322085142 - accuracy: 90.0225 - val_loss: 0.6398728283882141 - val_accuracy: 79.11
2023-09-08 16:44:42,424 - root - INFO - [Test] ---> accuracy: 79.46 - loss: 0.6515860565185547
2023-09-08 16:44:42,424 - root - INFO - test acc from best model : 80.13
2023-09-08 16:44:42,424 - root - INFO - Epoch 34
-------------------------------
2023-09-08 16:48:31,947 - root - INFO - Época 34/100
2023-09-08 16:48:31,947 - root - INFO - loss: 0.27080880345702174 - accuracy: 90.8175 - val_loss: 0.7167877215385438 - val_accuracy: 77.4
2023-09-08 16:48:31,947 - root - INFO - [Test] ---> accuracy: 77.69 - loss: 0.7059971185684204
2023-09-08 16:48:31,947 - root - INFO - test acc from best model : 80.13
2023-09-08 16:48:31,948 - root - INFO - Epoch 35
-------------------------------
2023-09-08 16:52:21,101 - root - INFO - Época 35/100
2023-09-08 16:52:21,101 - root - INFO - loss: 0.2533373071104288 - accuracy: 91.4925 - val_loss: 0.6503914151668548 - val_accuracy: 80.41
2023-09-08 16:52:21,101 - root - INFO - [Test] ---> accuracy: 80.42 - loss: 0.653361478805542
2023-09-08 16:52:21,101 - root - INFO - test acc from best model : 80.13
2023-09-08 16:52:21,464 - root - INFO - Epoch 36
-------------------------------
2023-09-08 16:56:17,870 - root - INFO - Época 36/100
2023-09-08 16:56:17,870 - root - INFO - loss: 0.2486801879286766 - accuracy: 91.62 - val_loss: 0.6263428528785706 - val_accuracy: 81.34
2023-09-08 16:56:17,870 - root - INFO - [Test] ---> accuracy: 81.35 - loss: 0.6366687269449234
2023-09-08 16:56:17,870 - root - INFO - test acc from best model : 80.13
2023-09-08 16:56:17,870 - root - INFO - Epoch 37
-------------------------------
2023-09-08 17:00:13,103 - root - INFO - Época 37/100
2023-09-08 17:00:13,103 - root - INFO - loss: 0.22139255056381227 - accuracy: 92.5675 - val_loss: 0.6943111898422242 - val_accuracy: 79.80000000000001
2023-09-08 17:00:13,103 - root - INFO - [Test] ---> accuracy: 79.47999999999999 - loss: 0.7088124859333038
2023-09-08 17:00:13,103 - root - INFO - test acc from best model : 80.13
2023-09-08 17:00:13,103 - root - INFO - Epoch 38
-------------------------------
2023-09-08 17:04:08,784 - root - INFO - Época 38/100
2023-09-08 17:04:08,784 - root - INFO - loss: 0.2202467669993639 - accuracy: 92.6525 - val_loss: 0.6449348286151886 - val_accuracy: 80.71000000000001
2023-09-08 17:04:08,784 - root - INFO - [Test] ---> accuracy: 80.71000000000001 - loss: 0.6413949376106263
2023-09-08 17:04:08,784 - root - INFO - test acc from best model : 80.13
2023-09-08 17:04:08,784 - root - INFO - Epoch 39
-------------------------------
2023-09-08 17:08:07,607 - root - INFO - Época 39/100
2023-09-08 17:08:07,607 - root - INFO - loss: 0.20564508617520333 - accuracy: 93.0225 - val_loss: 0.6446483021020889 - val_accuracy: 81.78999999999999
2023-09-08 17:08:07,607 - root - INFO - [Test] ---> accuracy: 81.69999999999999 - loss: 0.6534037899494172
2023-09-08 17:08:07,607 - root - INFO - test acc from best model : 80.13
2023-09-08 17:08:07,608 - root - INFO - Epoch 40
-------------------------------
2023-09-08 17:12:05,924 - root - INFO - Época 40/100
2023-09-08 17:12:05,924 - root - INFO - loss: 0.20229418558478354 - accuracy: 93.2475 - val_loss: 0.6623102923870087 - val_accuracy: 80.36999999999999
2023-09-08 17:12:05,924 - root - INFO - [Test] ---> accuracy: 80.2 - loss: 0.6707899446964264
2023-09-08 17:12:05,924 - root - INFO - test acc from best model : 80.13
2023-09-08 17:12:06,295 - root - INFO - Epoch 41
-------------------------------
2023-09-08 17:16:08,918 - root - INFO - Época 41/100
2023-09-08 17:16:08,918 - root - INFO - loss: 0.18489215287864208 - accuracy: 93.795 - val_loss: 0.6661652676582337 - val_accuracy: 81.22
2023-09-08 17:16:08,918 - root - INFO - [Test] ---> accuracy: 81.28 - loss: 0.6756449707508088
2023-09-08 17:16:08,918 - root - INFO - test acc from best model : 80.13
2023-09-08 17:16:08,918 - root - INFO - Epoch 42
-------------------------------
2023-09-08 17:20:12,143 - root - INFO - Época 42/100
2023-09-08 17:20:12,143 - root - INFO - loss: 0.18711787809729577 - accuracy: 93.795 - val_loss: 0.7096001428604126 - val_accuracy: 80.41
2023-09-08 17:20:12,143 - root - INFO - [Test] ---> accuracy: 80.7 - loss: 0.7114373791217804
2023-09-08 17:20:12,143 - root - INFO - test acc from best model : 80.13
2023-09-08 17:20:12,143 - root - INFO - Epoch 43
-------------------------------
2023-09-08 17:24:14,722 - root - INFO - Época 43/100
2023-09-08 17:24:14,723 - root - INFO - loss: 0.16814238321483135 - accuracy: 94.425 - val_loss: 0.6668591962218284 - val_accuracy: 81.47
2023-09-08 17:24:14,723 - root - INFO - [Test] ---> accuracy: 81.36 - loss: 0.6810454605102539
2023-09-08 17:24:14,723 - root - INFO - test acc from best model : 80.13
2023-09-08 17:24:14,723 - root - INFO - Epoch 44
-------------------------------
2023-09-08 17:28:15,380 - root - INFO - Época 44/100
2023-09-08 17:28:15,380 - root - INFO - loss: 0.1671355530142784 - accuracy: 94.4075 - val_loss: 0.818317725276947 - val_accuracy: 78.43
2023-09-08 17:28:15,380 - root - INFO - [Test] ---> accuracy: 77.97 - loss: 0.8219686415195465
2023-09-08 17:28:15,380 - root - INFO - test acc from best model : 80.13
2023-09-08 17:28:15,380 - root - INFO - Epoch 45
-------------------------------
2023-09-08 17:32:04,327 - root - INFO - Época 45/100
2023-09-08 17:32:04,327 - root - INFO - loss: 0.16880420135855675 - accuracy: 94.4875 - val_loss: 0.6777291301727295 - val_accuracy: 80.83
2023-09-08 17:32:04,327 - root - INFO - [Test] ---> accuracy: 81.2 - loss: 0.6836932627439499
2023-09-08 17:32:04,327 - root - INFO - test acc from best model : 80.13
2023-09-08 17:32:04,657 - root - INFO - Epoch 46
-------------------------------
2023-09-08 17:35:39,388 - root - INFO - Época 46/100
2023-09-08 17:35:39,389 - root - INFO - loss: 0.1546455265700817 - accuracy: 94.9825 - val_loss: 0.7006740327119827 - val_accuracy: 80.69
2023-09-08 17:35:39,389 - root - INFO - [Test] ---> accuracy: 80.9 - loss: 0.714225617313385
2023-09-08 17:35:39,389 - root - INFO - test acc from best model : 80.13
2023-09-08 17:35:39,389 - root - INFO - Epoch 47
-------------------------------
2023-09-08 17:39:13,837 - root - INFO - Época 47/100
2023-09-08 17:39:13,837 - root - INFO - loss: 0.15221142301559448 - accuracy: 95.0775 - val_loss: 0.7562240699768067 - val_accuracy: 79.46
2023-09-08 17:39:13,837 - root - INFO - [Test] ---> accuracy: 79.45 - loss: 0.754423534989357
2023-09-08 17:39:13,837 - root - INFO - test acc from best model : 80.13
2023-09-08 17:39:13,837 - root - INFO - Epoch 48
-------------------------------
2023-09-08 17:42:48,174 - root - INFO - Época 48/100
2023-09-08 17:42:48,174 - root - INFO - loss: 0.14233618096411227 - accuracy: 95.3125 - val_loss: 0.7935766897916794 - val_accuracy: 79.35
2023-09-08 17:42:48,174 - root - INFO - [Test] ---> accuracy: 79.14999999999999 - loss: 0.8145017569065094
2023-09-08 17:42:48,174 - root - INFO - test acc from best model : 80.13
2023-09-08 17:42:48,174 - root - INFO - Epoch 49
-------------------------------
2023-09-08 17:46:24,401 - root - INFO - Época 49/100
2023-09-08 17:46:24,402 - root - INFO - loss: 0.13678871170580387 - accuracy: 95.5175 - val_loss: 0.7086049896240234 - val_accuracy: 81.12
2023-09-08 17:46:24,402 - root - INFO - [Test] ---> accuracy: 81.13 - loss: 0.708555783700943
2023-09-08 17:46:24,402 - root - INFO - test acc from best model : 80.13
2023-09-08 17:46:24,402 - root - INFO - Epoch 50
-------------------------------
2023-09-08 17:49:58,378 - root - INFO - Época 50/100
2023-09-08 17:49:58,379 - root - INFO - loss: 0.1370536282747984 - accuracy: 95.5125 - val_loss: 0.700550547504425 - val_accuracy: 81.52000000000001
2023-09-08 17:49:58,379 - root - INFO - [Test] ---> accuracy: 81.34 - loss: 0.709943261051178
2023-09-08 17:49:58,379 - root - INFO - test acc from best model : 80.13
2023-09-08 17:49:58,717 - root - INFO - Epoch 51
-------------------------------
2023-09-08 17:53:40,633 - root - INFO - Época 51/100
2023-09-08 17:53:40,634 - root - INFO - loss: 0.13486548064053058 - accuracy: 95.62 - val_loss: 0.7745154982566833 - val_accuracy: 81.07
2023-09-08 17:53:40,634 - root - INFO - [Test] ---> accuracy: 80.87 - loss: 0.7886709589481353
2023-09-08 17:53:40,634 - root - INFO - test acc from best model : 80.13
2023-09-08 17:53:40,634 - root - INFO - Epoch 52
-------------------------------
2023-09-08 17:57:21,537 - root - INFO - Época 52/100
2023-09-08 17:57:21,538 - root - INFO - loss: 0.12153038983345031 - accuracy: 96.1125 - val_loss: 0.7631533897638321 - val_accuracy: 80.2
2023-09-08 17:57:21,538 - root - INFO - [Test] ---> accuracy: 80.36999999999999 - loss: 0.7786237410068512
2023-09-08 17:57:21,538 - root - INFO - test acc from best model : 80.13
2023-09-08 17:57:21,538 - root - INFO - Epoch 53
-------------------------------
2023-09-08 18:01:02,101 - root - INFO - Época 53/100
2023-09-08 18:01:02,101 - root - INFO - loss: 0.13019261388778686 - accuracy: 95.765 - val_loss: 0.7234059594631195 - val_accuracy: 80.87
2023-09-08 18:01:02,101 - root - INFO - [Test] ---> accuracy: 81.26 - loss: 0.7600370081424713
2023-09-08 18:01:02,101 - root - INFO - test acc from best model : 80.13
2023-09-08 18:01:02,101 - root - INFO - Epoch 54
-------------------------------
2023-09-08 18:04:42,631 - root - INFO - Época 54/100
2023-09-08 18:04:42,631 - root - INFO - loss: 0.11828512204289436 - accuracy: 96.195 - val_loss: 0.7252176184177399 - val_accuracy: 80.55
2023-09-08 18:04:42,631 - root - INFO - [Test] ---> accuracy: 80.49 - loss: 0.734585421037674
2023-09-08 18:04:42,631 - root - INFO - test acc from best model : 80.13
2023-09-08 18:04:42,631 - root - INFO - Epoch 55
-------------------------------
2023-09-08 18:08:23,667 - root - INFO - Época 55/100
2023-09-08 18:08:23,667 - root - INFO - loss: 0.11961232400238514 - accuracy: 96.25 - val_loss: 0.717426248550415 - val_accuracy: 82.04
2023-09-08 18:08:23,667 - root - INFO - [Test] ---> accuracy: 82.1 - loss: 0.7480907451152802
2023-09-08 18:08:23,668 - root - INFO - test acc from best model : 80.13
2023-09-08 18:08:24,012 - root - INFO - Epoch 56
-------------------------------
2023-09-08 18:12:10,340 - root - INFO - Época 56/100
2023-09-08 18:12:10,341 - root - INFO - loss: 0.11741101111769676 - accuracy: 96.1475 - val_loss: 0.7217968771457672 - val_accuracy: 80.42
2023-09-08 18:12:10,341 - root - INFO - [Test] ---> accuracy: 80.65 - loss: 0.7288716949462891
2023-09-08 18:12:10,341 - root - INFO - test acc from best model : 80.13
2023-09-08 18:12:10,341 - root - INFO - Epoch 57
-------------------------------
2023-09-08 18:15:57,985 - root - INFO - Época 57/100
2023-09-08 18:15:57,985 - root - INFO - loss: 0.11697397049069405 - accuracy: 96.29 - val_loss: 0.7437931023359299 - val_accuracy: 81.3
2023-09-08 18:15:57,985 - root - INFO - [Test] ---> accuracy: 81.6 - loss: 0.7572420130252838
2023-09-08 18:15:57,985 - root - INFO - test acc from best model : 80.13
2023-09-08 18:15:57,985 - root - INFO - Epoch 58
-------------------------------
2023-09-08 18:19:44,421 - root - INFO - Época 58/100
2023-09-08 18:19:44,421 - root - INFO - loss: 0.11461018067598343 - accuracy: 96.4625 - val_loss: 0.7944245104670524 - val_accuracy: 81.02000000000001
2023-09-08 18:19:44,421 - root - INFO - [Test] ---> accuracy: 80.78999999999999 - loss: 0.8236994908094406
2023-09-08 18:19:44,421 - root - INFO - test acc from best model : 80.13
2023-09-08 18:19:44,421 - root - INFO - Epoch 59
-------------------------------
2023-09-08 18:23:31,244 - root - INFO - Época 59/100
2023-09-08 18:23:31,244 - root - INFO - loss: 0.11369157385230065 - accuracy: 96.4675 - val_loss: 0.6777690537929535 - val_accuracy: 81.88
2023-09-08 18:23:31,244 - root - INFO - [Test] ---> accuracy: 81.87 - loss: 0.7069728053569794
2023-09-08 18:23:31,244 - root - INFO - test acc from best model : 80.13
2023-09-08 18:23:31,245 - root - INFO - Epoch 60
-------------------------------
2023-09-08 18:27:18,692 - root - INFO - Época 60/100
2023-09-08 18:27:18,693 - root - INFO - loss: 0.10064909045994282 - accuracy: 96.835 - val_loss: 0.6771936376333236 - val_accuracy: 82.22
2023-09-08 18:27:18,693 - root - INFO - [Test] ---> accuracy: 82.39999999999999 - loss: 0.6916377032518387
2023-09-08 18:27:18,693 - root - INFO - test acc from best model : 80.13
2023-09-08 18:27:19,052 - root - INFO - Epoch 61
-------------------------------
2023-09-08 18:31:12,987 - root - INFO - Época 61/100
2023-09-08 18:31:12,987 - root - INFO - loss: 0.10710056546032429 - accuracy: 96.81 - val_loss: 0.7884258711338044 - val_accuracy: 80.69
2023-09-08 18:31:12,987 - root - INFO - [Test] ---> accuracy: 80.53 - loss: 0.8135745657444
2023-09-08 18:31:12,987 - root - INFO - test acc from best model : 80.13
2023-09-08 18:31:12,987 - root - INFO - Epoch 62
-------------------------------
2023-09-08 18:35:05,740 - root - INFO - Época 62/100
2023-09-08 18:35:05,740 - root - INFO - loss: 0.1039189079284668 - accuracy: 96.6875 - val_loss: 0.7138667917490006 - val_accuracy: 82.13000000000001
2023-09-08 18:35:05,740 - root - INFO - [Test] ---> accuracy: 82.17999999999999 - loss: 0.7317109363079071
2023-09-08 18:35:05,740 - root - INFO - test acc from best model : 80.13
2023-09-08 18:35:05,740 - root - INFO - Epoch 63
-------------------------------
2023-09-08 18:38:57,749 - root - INFO - Época 63/100
2023-09-08 18:38:57,749 - root - INFO - loss: 0.10602141113877296 - accuracy: 96.53 - val_loss: 0.6976681490898132 - val_accuracy: 82.08
2023-09-08 18:38:57,749 - root - INFO - [Test] ---> accuracy: 81.92 - loss: 0.7046034040689468
2023-09-08 18:38:57,749 - root - INFO - test acc from best model : 80.13
2023-09-08 18:38:57,749 - root - INFO - Epoch 64
-------------------------------
2023-09-08 18:42:50,841 - root - INFO - Época 64/100
2023-09-08 18:42:50,841 - root - INFO - loss: 0.10186958143115044 - accuracy: 96.8725 - val_loss: 0.7971824180066586 - val_accuracy: 82.08
2023-09-08 18:42:50,841 - root - INFO - [Test] ---> accuracy: 82.55 - loss: 0.79307605407238
2023-09-08 18:42:50,841 - root - INFO - test acc from best model : 80.13
2023-09-08 18:42:50,841 - root - INFO - Epoch 65
-------------------------------
2023-09-08 18:46:53,574 - root - INFO - Época 65/100
2023-09-08 18:46:53,574 - root - INFO - loss: 0.09207444333136082 - accuracy: 97.115 - val_loss: 0.7529013433098793 - val_accuracy: 82.06
2023-09-08 18:46:53,574 - root - INFO - [Test] ---> accuracy: 82.3 - loss: 0.7514316759586335
2023-09-08 18:46:53,574 - root - INFO - test acc from best model : 80.13
2023-09-08 18:46:53,932 - root - INFO - Epoch 66
-------------------------------
2023-09-08 18:50:54,479 - root - INFO - Época 66/100
2023-09-08 18:50:54,479 - root - INFO - loss: 0.09390458327531814 - accuracy: 97.1425 - val_loss: 0.762228721666336 - val_accuracy: 81.39
2023-09-08 18:50:54,479 - root - INFO - [Test] ---> accuracy: 81.26 - loss: 0.7670163813591003
2023-09-08 18:50:54,479 - root - INFO - test acc from best model : 80.13
2023-09-08 18:50:54,479 - root - INFO - Epoch 67
-------------------------------
2023-09-08 18:55:02,389 - root - INFO - Época 67/100
2023-09-08 18:55:02,389 - root - INFO - loss: 0.10055199463367462 - accuracy: 96.955 - val_loss: 0.9143064185142518 - val_accuracy: 80.88
2023-09-08 18:55:02,389 - root - INFO - [Test] ---> accuracy: 80.35 - loss: 0.9350821047782898
2023-09-08 18:55:02,389 - root - INFO - test acc from best model : 80.13
2023-09-08 18:55:02,389 - root - INFO - Epoch 68
-------------------------------
2023-09-08 18:59:01,473 - root - INFO - Época 68/100
2023-09-08 18:59:01,473 - root - INFO - loss: 0.08638818722367286 - accuracy: 97.285 - val_loss: 0.7129817245483399 - val_accuracy: 82.66
2023-09-08 18:59:01,473 - root - INFO - [Test] ---> accuracy: 82.44 - loss: 0.7276045699596405
2023-09-08 18:59:01,473 - root - INFO - test acc from best model : 80.13
2023-09-08 18:59:01,474 - root - INFO - Epoch 69
-------------------------------
2023-09-08 19:03:03,740 - root - INFO - Época 69/100
2023-09-08 19:03:03,740 - root - INFO - loss: 0.09027695081532001 - accuracy: 97.1925 - val_loss: 0.8048967419624329 - val_accuracy: 82.66
2023-09-08 19:03:03,740 - root - INFO - [Test] ---> accuracy: 81.89 - loss: 0.8328008637428284
2023-09-08 19:03:03,740 - root - INFO - test acc from best model : 80.13
2023-09-08 19:03:03,741 - root - INFO - Epoch 70
-------------------------------
2023-09-08 19:07:10,427 - root - INFO - Época 70/100
2023-09-08 19:07:10,427 - root - INFO - loss: 0.09398877756595611 - accuracy: 97.1075 - val_loss: 0.7020457527935505 - val_accuracy: 82.31
2023-09-08 19:07:10,427 - root - INFO - [Test] ---> accuracy: 82.52000000000001 - loss: 0.7252092637538909
2023-09-08 19:07:10,427 - root - INFO - test acc from best model : 80.13
2023-09-08 19:07:10,813 - root - INFO - Epoch 71
-------------------------------
2023-09-08 19:11:45,322 - root - INFO - Época 71/100
2023-09-08 19:11:45,322 - root - INFO - loss: 0.0913416663914919 - accuracy: 97.295 - val_loss: 0.9016426364183426 - val_accuracy: 81.26
2023-09-08 19:11:45,322 - root - INFO - [Test] ---> accuracy: 81.3 - loss: 0.9085741553544998
2023-09-08 19:11:45,322 - root - INFO - test acc from best model : 80.13
2023-09-08 19:11:45,322 - root - INFO - Epoch 72
-------------------------------
2023-09-08 19:16:19,532 - root - INFO - Época 72/100
2023-09-08 19:16:19,532 - root - INFO - loss: 0.09010371545851231 - accuracy: 97.22 - val_loss: 0.8008632425308227 - val_accuracy: 82.19
2023-09-08 19:16:19,532 - root - INFO - [Test] ---> accuracy: 81.88 - loss: 0.810608446931839
2023-09-08 19:16:19,532 - root - INFO - test acc from best model : 80.13
2023-09-08 19:16:19,532 - root - INFO - Epoch 73
-------------------------------
2023-09-08 19:20:28,947 - root - INFO - Época 73/100
2023-09-08 19:20:28,947 - root - INFO - loss: 0.09085941435992717 - accuracy: 97.1625 - val_loss: 0.820520201086998 - val_accuracy: 80.13
2023-09-08 19:20:28,947 - root - INFO - [Test] ---> accuracy: 80.19 - loss: 0.8529302649974823
2023-09-08 19:20:28,947 - root - INFO - test acc from best model : 80.13
2023-09-08 19:20:28,947 - root - INFO - Epoch 74
-------------------------------
2023-09-08 19:24:45,710 - root - INFO - Época 74/100
2023-09-08 19:24:45,711 - root - INFO - loss: 0.08131711658835411 - accuracy: 97.615 - val_loss: 0.7675333526134491 - val_accuracy: 82.23
2023-09-08 19:24:45,711 - root - INFO - [Test] ---> accuracy: 82.35 - loss: 0.7682879574775696
2023-09-08 19:24:45,711 - root - INFO - test acc from best model : 80.13
2023-09-08 19:24:45,711 - root - INFO - Epoch 75
-------------------------------
2023-09-08 19:29:05,053 - root - INFO - Época 75/100
2023-09-08 19:29:05,053 - root - INFO - loss: 0.08185684128403664 - accuracy: 97.4375 - val_loss: 0.730688544011116 - val_accuracy: 82.21000000000001
2023-09-08 19:29:05,053 - root - INFO - [Test] ---> accuracy: 82.72 - loss: 0.7535188682079316
2023-09-08 19:29:05,053 - root - INFO - test acc from best model : 80.13
2023-09-08 19:29:05,415 - root - INFO - Epoch 76
-------------------------------
2023-09-08 19:33:17,472 - root - INFO - Época 76/100
2023-09-08 19:33:17,472 - root - INFO - loss: 0.07976028271317483 - accuracy: 97.6975 - val_loss: 0.7863497843027115 - val_accuracy: 82.31
2023-09-08 19:33:17,472 - root - INFO - [Test] ---> accuracy: 82.21000000000001 - loss: 0.8213721140861511
2023-09-08 19:33:17,472 - root - INFO - test acc from best model : 80.13
2023-09-08 19:33:17,472 - root - INFO - Epoch 77
-------------------------------
2023-09-08 19:37:33,433 - root - INFO - Época 77/100
2023-09-08 19:37:33,433 - root - INFO - loss: 0.08517062147557736 - accuracy: 97.375 - val_loss: 0.7796001212358474 - val_accuracy: 82.63000000000001
2023-09-08 19:37:33,433 - root - INFO - [Test] ---> accuracy: 82.23 - loss: 0.7977497365236282
2023-09-08 19:37:33,433 - root - INFO - test acc from best model : 80.13
2023-09-08 19:37:33,433 - root - INFO - Epoch 78
-------------------------------
2023-09-08 19:42:15,493 - root - INFO - Época 78/100
2023-09-08 19:42:15,493 - root - INFO - loss: 0.08139857447743416 - accuracy: 97.6525 - val_loss: 0.8174777220726013 - val_accuracy: 82.58
2023-09-08 19:42:15,493 - root - INFO - [Test] ---> accuracy: 82.45 - loss: 0.8547689731359481
2023-09-08 19:42:15,493 - root - INFO - test acc from best model : 80.13
2023-09-08 19:42:15,493 - root - INFO - Epoch 79
-------------------------------
2023-09-08 19:46:57,748 - root - INFO - Época 79/100
2023-09-08 19:46:57,749 - root - INFO - loss: 0.07860814101099968 - accuracy: 97.59 - val_loss: 0.8173296003341675 - val_accuracy: 82.98
2023-09-08 19:46:57,749 - root - INFO - [Test] ---> accuracy: 82.85 - loss: 0.8440439289808274
2023-09-08 19:46:57,749 - root - INFO - test acc from best model : 80.13
2023-09-08 19:46:57,749 - root - INFO - Epoch 80
-------------------------------
2023-09-08 19:51:40,222 - root - INFO - Época 80/100
2023-09-08 19:51:40,222 - root - INFO - loss: 0.08659347749650478 - accuracy: 97.405 - val_loss: 0.7515605951309204 - val_accuracy: 81.65
2023-09-08 19:51:40,222 - root - INFO - [Test] ---> accuracy: 81.35 - loss: 0.7551301528215408
2023-09-08 19:51:40,222 - root - INFO - test acc from best model : 80.13
2023-09-08 19:51:40,609 - root - INFO - Epoch 81
-------------------------------
2023-09-08 19:56:28,742 - root - INFO - Época 81/100
2023-09-08 19:56:28,743 - root - INFO - loss: 0.07947246384620667 - accuracy: 97.68 - val_loss: 0.7623056239128113 - val_accuracy: 81.75
2023-09-08 19:56:28,743 - root - INFO - [Test] ---> accuracy: 81.84 - loss: 0.7468726360797882
2023-09-08 19:56:28,743 - root - INFO - test acc from best model : 80.13
2023-09-08 19:56:28,743 - root - INFO - Epoch 82
-------------------------------
2023-09-08 20:01:17,149 - root - INFO - Época 82/100
2023-09-08 20:01:17,149 - root - INFO - loss: 0.08203779413700103 - accuracy: 97.59 - val_loss: 0.8882147315859794 - val_accuracy: 81.86
2023-09-08 20:01:17,149 - root - INFO - [Test] ---> accuracy: 81.99 - loss: 0.8841926532506943
2023-09-08 20:01:17,149 - root - INFO - test acc from best model : 80.13
2023-09-08 20:01:17,149 - root - INFO - Epoch 83
-------------------------------
2023-09-08 20:05:56,015 - root - INFO - Época 83/100
2023-09-08 20:05:56,015 - root - INFO - loss: 0.06717222075462341 - accuracy: 97.89 - val_loss: 0.8727516239881515 - val_accuracy: 82.23
2023-09-08 20:05:56,015 - root - INFO - [Test] ---> accuracy: 82.69999999999999 - loss: 0.8344179603934287
2023-09-08 20:05:56,015 - root - INFO - test acc from best model : 80.13
2023-09-08 20:05:56,015 - root - INFO - Epoch 84
-------------------------------
2023-09-08 20:10:21,436 - root - INFO - Época 84/100
2023-09-08 20:10:21,436 - root - INFO - loss: 0.082574853977561 - accuracy: 97.6825 - val_loss: 0.7688094380378723 - val_accuracy: 81.72
2023-09-08 20:10:21,436 - root - INFO - [Test] ---> accuracy: 81.83 - loss: 0.7640778168678284
2023-09-08 20:10:21,436 - root - INFO - test acc from best model : 80.13
2023-09-08 20:10:21,436 - root - INFO - Epoch 85
-------------------------------
2023-09-08 20:14:41,649 - root - INFO - Época 85/100
2023-09-08 20:14:41,650 - root - INFO - loss: 0.07815874792039394 - accuracy: 97.71 - val_loss: 0.7601692723155021 - val_accuracy: 82.65
2023-09-08 20:14:41,650 - root - INFO - [Test] ---> accuracy: 82.63000000000001 - loss: 0.8007720551729203
2023-09-08 20:14:41,650 - root - INFO - test acc from best model : 80.13
2023-09-08 20:14:41,970 - root - INFO - Epoch 86
-------------------------------
2023-09-08 20:19:06,393 - root - INFO - Época 86/100
2023-09-08 20:19:06,393 - root - INFO - loss: 0.07935529689192772 - accuracy: 97.6375 - val_loss: 0.70678417339921 - val_accuracy: 82.49
2023-09-08 20:19:06,393 - root - INFO - [Test] ---> accuracy: 82.91 - loss: 0.7111735110878944
2023-09-08 20:19:06,393 - root - INFO - test acc from best model : 80.13
2023-09-08 20:19:06,393 - root - INFO - Epoch 87
-------------------------------
2023-09-08 20:23:29,700 - root - INFO - Época 87/100
2023-09-08 20:23:29,701 - root - INFO - loss: 0.07827833214700222 - accuracy: 97.815 - val_loss: 0.8256251266479492 - val_accuracy: 81.72
2023-09-08 20:23:29,701 - root - INFO - [Test] ---> accuracy: 82.0 - loss: 0.8519282079458237
2023-09-08 20:23:29,701 - root - INFO - test acc from best model : 80.13
2023-09-08 20:23:29,701 - root - INFO - Epoch 88
-------------------------------
2023-09-08 20:27:53,531 - root - INFO - Época 88/100
2023-09-08 20:27:53,531 - root - INFO - loss: 0.07487845846712589 - accuracy: 97.6825 - val_loss: 0.8863437630161644 - val_accuracy: 82.31
2023-09-08 20:27:53,531 - root - INFO - [Test] ---> accuracy: 81.87 - loss: 0.9484106359958648
2023-09-08 20:27:53,531 - root - INFO - test acc from best model : 80.13
2023-09-08 20:27:53,531 - root - INFO - Epoch 89
-------------------------------
2023-09-08 20:32:17,943 - root - INFO - Época 89/100
2023-09-08 20:32:17,943 - root - INFO - loss: 0.06738318757116794 - accuracy: 98.0125 - val_loss: 0.9116222620487213 - val_accuracy: 82.97
2023-09-08 20:32:17,943 - root - INFO - [Test] ---> accuracy: 82.37 - loss: 0.9497194389104843
2023-09-08 20:32:17,943 - root - INFO - test acc from best model : 80.13
2023-09-08 20:32:17,943 - root - INFO - Epoch 90
-------------------------------
2023-09-08 20:36:42,141 - root - INFO - Época 90/100
2023-09-08 20:36:42,141 - root - INFO - loss: 0.0729805407166481 - accuracy: 97.85 - val_loss: 0.9588630675062537 - val_accuracy: 82.96
2023-09-08 20:36:42,141 - root - INFO - [Test] ---> accuracy: 82.94 - loss: 1.0137188796401024
2023-09-08 20:36:42,141 - root - INFO - test acc from best model : 80.13
2023-09-08 20:36:42,461 - root - INFO - Epoch 91
-------------------------------
2023-09-08 20:41:13,292 - root - INFO - Época 91/100
2023-09-08 20:41:13,292 - root - INFO - loss: 0.07651397749483585 - accuracy: 97.6925 - val_loss: 0.7670956010341644 - val_accuracy: 81.98
2023-09-08 20:41:13,292 - root - INFO - [Test] ---> accuracy: 82.42 - loss: 0.7501118386745453
2023-09-08 20:41:13,292 - root - INFO - test acc from best model : 80.13
2023-09-08 20:41:13,292 - root - INFO - Epoch 92
-------------------------------
2023-09-08 20:45:44,327 - root - INFO - Época 92/100
2023-09-08 20:45:44,327 - root - INFO - loss: 0.07840021773278713 - accuracy: 97.735 - val_loss: 0.798266951072216 - val_accuracy: 82.74000000000001
2023-09-08 20:45:44,327 - root - INFO - [Test] ---> accuracy: 82.05 - loss: 0.8608672156095505
2023-09-08 20:45:44,327 - root - INFO - test acc from best model : 80.13
2023-09-08 20:45:44,328 - root - INFO - Epoch 93
-------------------------------
2023-09-08 20:50:14,661 - root - INFO - Época 93/100
2023-09-08 20:50:14,661 - root - INFO - loss: 0.06937918047904969 - accuracy: 97.895 - val_loss: 1.092771293234825 - val_accuracy: 79.71000000000001
2023-09-08 20:50:14,662 - root - INFO - [Test] ---> accuracy: 80.02 - loss: 1.1494865315198899
2023-09-08 20:50:14,662 - root - INFO - test acc from best model : 80.13
2023-09-08 20:50:14,662 - root - INFO - Epoch 94
-------------------------------
2023-09-08 20:54:44,326 - root - INFO - Época 94/100
2023-09-08 20:54:44,326 - root - INFO - loss: 0.06651225988864899 - accuracy: 98.07 - val_loss: 0.7989609157562256 - val_accuracy: 83.06
2023-09-08 20:54:44,326 - root - INFO - [Test] ---> accuracy: 82.67 - loss: 0.865667302107811
2023-09-08 20:54:44,326 - root - INFO - test acc from best model : 80.13
2023-09-08 20:54:44,326 - root - INFO - Epoch 95
-------------------------------
2023-09-08 20:59:15,225 - root - INFO - Época 95/100
2023-09-08 20:59:15,226 - root - INFO - loss: 0.06459609283804893 - accuracy: 98.14 - val_loss: 0.9653728953659535 - val_accuracy: 83.0
2023-09-08 20:59:15,226 - root - INFO - [Test] ---> accuracy: 82.73 - loss: 1.051004495203495
2023-09-08 20:59:15,226 - root - INFO - test acc from best model : 80.13
2023-09-08 20:59:15,547 - root - INFO - Epoch 96
-------------------------------
2023-09-08 21:03:51,294 - root - INFO - Época 96/100
2023-09-08 21:03:51,294 - root - INFO - loss: 0.08292579208016396 - accuracy: 97.7175 - val_loss: 0.8488177462875843 - val_accuracy: 83.63000000000001
2023-09-08 21:03:51,294 - root - INFO - [Test] ---> accuracy: 83.13000000000001 - loss: 0.8819879571378231
2023-09-08 21:03:51,294 - root - INFO - test acc from best model : 80.13
2023-09-08 21:03:51,294 - root - INFO - Epoch 97
-------------------------------
2023-09-08 21:08:27,153 - root - INFO - Época 97/100
2023-09-08 21:08:27,154 - root - INFO - loss: 0.06548812446296215 - accuracy: 98.0775 - val_loss: 0.9699466258049011 - val_accuracy: 82.16
2023-09-08 21:08:27,154 - root - INFO - [Test] ---> accuracy: 81.94 - loss: 1.0285272444367408
2023-09-08 21:08:27,154 - root - INFO - test acc from best model : 80.13
2023-09-08 21:08:27,154 - root - INFO - Epoch 98
-------------------------------
2023-09-08 21:13:02,179 - root - INFO - Época 98/100
2023-09-08 21:13:02,179 - root - INFO - loss: 0.0665127301543951 - accuracy: 97.9925 - val_loss: 0.9536656082630157 - val_accuracy: 82.41000000000001
2023-09-08 21:13:02,180 - root - INFO - [Test] ---> accuracy: 82.41000000000001 - loss: 0.9851112855553626
2023-09-08 21:13:02,180 - root - INFO - test acc from best model : 80.13
2023-09-08 21:13:02,180 - root - INFO - Epoch 99
-------------------------------
2023-09-08 21:17:39,543 - root - INFO - Época 99/100
2023-09-08 21:17:39,543 - root - INFO - loss: 0.06953383325338364 - accuracy: 97.91 - val_loss: 0.9648754827737808 - val_accuracy: 79.66
2023-09-08 21:17:39,543 - root - INFO - [Test] ---> accuracy: 80.17999999999999 - loss: 1.0029547373771668
2023-09-08 21:17:39,543 - root - INFO - test acc from best model : 80.13
2023-09-08 21:17:39,543 - root - INFO - Epoch 100
-------------------------------
2023-09-08 21:22:14,289 - root - INFO - Época 100/100
2023-09-08 21:22:14,289 - root - INFO - loss: 0.061673700377345084 - accuracy: 98.2225 - val_loss: 0.8959157596111298 - val_accuracy: 82.67
2023-09-08 21:22:14,289 - root - INFO - [Test] ---> accuracy: 82.62 - loss: 0.9263300744056702
2023-09-08 21:22:14,289 - root - INFO - test acc from best model : 80.13
2023-09-08 21:22:14,620 - root - INFO - Tempo treinamento:  23180.96 seconds
2023-09-08 21:22:14,620 - root - INFO - Menor loss: 0.6091819674491882
2023-09-08 21:22:14,620 - root - INFO - Acurácia de teste do melhor modelo: 80.13
2023-09-08 21:22:14,620 - root - INFO - Métricas
2023-09-08 21:22:14,620 - root - INFO - ACC
2023-09-08 21:22:14,622 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100],
 'test_acc': [16.99,
              21.19,
              21.07,
              21.69,
              25.069999999999997,
              27.41,
              26.57,
              30.240000000000002,
              31.419999999999998,
              31.46,
              36.67,
              35.89,
              37.76,
              40.21,
              45.050000000000004,
              40.03,
              57.440000000000005,
              64.02,
              68.46,
              71.02000000000001,
              75.86,
              70.73,
              75.76,
              75.3,
              76.74,
              72.39999999999999,
              76.64,
              80.13,
              77.94,
              80.23,
              79.62,
              80.4,
              79.46,
              77.69,
              80.42,
              81.35,
              79.47999999999999,
              80.71000000000001,
              81.69999999999999,
              80.2,
              81.28,
              80.7,
              81.36,
              77.97,
              81.2,
              80.9,
              79.45,
              79.14999999999999,
              81.13,
              81.34,
              80.87,
              80.36999999999999,
              81.26,
              80.49,
              82.1,
              80.65,
              81.6,
              80.78999999999999,
              81.87,
              82.39999999999999,
              80.53,
              82.17999999999999,
              81.92,
              82.55,
              82.3,
              81.26,
              80.35,
              82.44,
              81.89,
              82.52000000000001,
              81.3,
              81.88,
              80.19,
              82.35,
              82.72,
              82.21000000000001,
              82.23,
              82.45,
              82.85,
              81.35,
              81.84,
              81.99,
              82.69999999999999,
              81.83,
              82.63000000000001,
              82.91,
              82.0,
              81.87,
              82.37,
              82.94,
              82.42,
              82.05,
              80.02,
              82.67,
              82.73,
              83.13000000000001,
              81.94,
              82.41000000000001,
              80.17999999999999,
              82.62],
 'train_acc': [15.6825,
               17.66,
               19.8375,
               21.3425,
               23.025,
               24.7625,
               26.235,
               27.7675,
               30.0175,
               32.35,
               33.66,
               35.0375,
               35.875,
               37.0725,
               41.0,
               43.7775,
               51.335,
               63.1825,
               68.99,
               72.4075,
               75.1875,
               77.3325,
               79.49,
               81.045,
               82.4025,
               83.75,
               84.875,
               85.97,
               86.8975,
               87.8975,
               88.69,
               89.5825,
               90.0225,
               90.8175,
               91.4925,
               91.62,
               92.5675,
               92.6525,
               93.0225,
               93.2475,
               93.795,
               93.795,
               94.425,
               94.4075,
               94.4875,
               94.9825,
               95.0775,
               95.3125,
               95.5175,
               95.5125,
               95.62,
               96.1125,
               95.765,
               96.195,
               96.25,
               96.1475,
               96.29,
               96.4625,
               96.4675,
               96.835,
               96.81,
               96.6875,
               96.53,
               96.8725,
               97.115,
               97.1425,
               96.955,
               97.285,
               97.1925,
               97.1075,
               97.295,
               97.22,
               97.1625,
               97.615,
               97.4375,
               97.6975,
               97.375,
               97.6525,
               97.59,
               97.405,
               97.68,
               97.59,
               97.89,
               97.6825,
               97.71,
               97.6375,
               97.815,
               97.6825,
               98.0125,
               97.85,
               97.6925,
               97.735,
               97.895,
               98.07,
               98.14,
               97.7175,
               98.0775,
               97.9925,
               97.91,
               98.2225],
 'val_acc': [17.21,
             20.51,
             21.29,
             21.78,
             25.590000000000003,
             27.63,
             26.99,
             30.330000000000002,
             30.78,
             31.540000000000003,
             36.88,
             36.04,
             37.76,
             40.26,
             46.2,
             40.32,
             57.32000000000001,
             64.13,
             68.35,
             71.16,
             75.22,
             71.44,
             75.91,
             76.01,
             76.84,
             72.14,
             76.63,
             80.22,
             78.14,
             79.9,
             79.43,
             80.04,
             79.11,
             77.4,
             80.41,
             81.34,
             79.80000000000001,
             80.71000000000001,
             81.78999999999999,
             80.36999999999999,
             81.22,
             80.41,
             81.47,
             78.43,
             80.83,
             80.69,
             79.46,
             79.35,
             81.12,
             81.52000000000001,
             81.07,
             80.2,
             80.87,
             80.55,
             82.04,
             80.42,
             81.3,
             81.02000000000001,
             81.88,
             82.22,
             80.69,
             82.13000000000001,
             82.08,
             82.08,
             82.06,
             81.39,
             80.88,
             82.66,
             82.66,
             82.31,
             81.26,
             82.19,
             80.13,
             82.23,
             82.21000000000001,
             82.31,
             82.63000000000001,
             82.58,
             82.98,
             81.65,
             81.75,
             81.86,
             82.23,
             81.72,
             82.65,
             82.49,
             81.72,
             82.31,
             82.97,
             82.96,
             81.98,
             82.74000000000001,
             79.71000000000001,
             83.06,
             83.0,
             83.63000000000001,
             82.16,
             82.41000000000001,
             79.66,
             82.67]}
2023-09-08 21:22:14,622 - root - INFO - LOSS
2023-09-08 21:22:14,623 - root - INFO - {'epoch': [1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100],
 'test_loss': [2.035172769355774,
               1.9698109775543213,
               1.9830413570404053,
               1.9916964183807373,
               1.9238570152282715,
               1.8628646827697755,
               1.9085555545806885,
               1.7749256187438964,
               1.763641325187683,
               1.7098366804122924,
               1.6318211357116699,
               1.650234722518921,
               1.5798143896102905,
               1.5768300464630127,
               1.4896912115097045,
               1.5929228084564209,
               1.2214871461868286,
               1.0156470615386963,
               0.9363869753837586,
               0.8775035544395446,
               0.7254797939300537,
               0.835503337097168,
               0.701475903224945,
               0.7145742201805114,
               0.6958864019393921,
               0.8148795312404633,
               0.7170697629928589,
               0.6204772177219391,
               0.693137110710144,
               0.6013777949810029,
               0.6488700201511383,
               0.6335166896820068,
               0.6515860565185547,
               0.7059971185684204,
               0.653361478805542,
               0.6366687269449234,
               0.7088124859333038,
               0.6413949376106263,
               0.6534037899494172,
               0.6707899446964264,
               0.6756449707508088,
               0.7114373791217804,
               0.6810454605102539,
               0.8219686415195465,
               0.6836932627439499,
               0.714225617313385,
               0.754423534989357,
               0.8145017569065094,
               0.708555783700943,
               0.709943261051178,
               0.7886709589481353,
               0.7786237410068512,
               0.7600370081424713,
               0.734585421037674,
               0.7480907451152802,
               0.7288716949462891,
               0.7572420130252838,
               0.8236994908094406,
               0.7069728053569794,
               0.6916377032518387,
               0.8135745657444,
               0.7317109363079071,
               0.7046034040689468,
               0.79307605407238,
               0.7514316759586335,
               0.7670163813591003,
               0.9350821047782898,
               0.7276045699596405,
               0.8328008637428284,
               0.7252092637538909,
               0.9085741553544998,
               0.810608446931839,
               0.8529302649974823,
               0.7682879574775696,
               0.7535188682079316,
               0.8213721140861511,
               0.7977497365236282,
               0.8547689731359481,
               0.8440439289808274,
               0.7551301528215408,
               0.7468726360797882,
               0.8841926532506943,
               0.8344179603934287,
               0.7640778168678284,
               0.8007720551729203,
               0.7111735110878944,
               0.8519282079458237,
               0.9484106359958648,
               0.9497194389104843,
               1.0137188796401024,
               0.7501118386745453,
               0.8608672156095505,
               1.1494865315198899,
               0.865667302107811,
               1.051004495203495,
               0.8819879571378231,
               1.0285272444367408,
               0.9851112855553626,
               1.0029547373771668,
               0.9263300744056702],
 'train_loss': [2.327380446434021,
                2.0653532775878904,
                2.0113272052764892,
                1.9907211059570313,
                1.9537285400390625,
                1.922080062866211,
                1.8919677715301513,
                1.8510816076278687,
                1.816442316532135,
                1.7374155264854432,
                1.7099829559326172,
                1.6561635581970215,
                1.6445924494743347,
                1.6249516102790833,
                1.5362846866607667,
                1.4668784328460693,
                1.3151786757469177,
                1.0641412907361985,
                0.9044234835386277,
                0.8063048356294632,
                0.7333401283860207,
                0.6688307131767273,
                0.6047717936754227,
                0.5595427941858768,
                0.5197633607208729,
                0.4801275310456753,
                0.4480174139022827,
                0.4087160478711128,
                0.38312381764948367,
                0.35012420085668566,
                0.3318242059469223,
                0.30516962498426436,
                0.2908138322085142,
                0.27080880345702174,
                0.2533373071104288,
                0.2486801879286766,
                0.22139255056381227,
                0.2202467669993639,
                0.20564508617520333,
                0.20229418558478354,
                0.18489215287864208,
                0.18711787809729577,
                0.16814238321483135,
                0.1671355530142784,
                0.16880420135855675,
                0.1546455265700817,
                0.15221142301559448,
                0.14233618096411227,
                0.13678871170580387,
                0.1370536282747984,
                0.13486548064053058,
                0.12153038983345031,
                0.13019261388778686,
                0.11828512204289436,
                0.11961232400238514,
                0.11741101111769676,
                0.11697397049069405,
                0.11461018067598343,
                0.11369157385230065,
                0.10064909045994282,
                0.10710056546032429,
                0.1039189079284668,
                0.10602141113877296,
                0.10186958143115044,
                0.09207444333136082,
                0.09390458327531814,
                0.10055199463367462,
                0.08638818722367286,
                0.09027695081532001,
                0.09398877756595611,
                0.0913416663914919,
                0.09010371545851231,
                0.09085941435992717,
                0.08131711658835411,
                0.08185684128403664,
                0.07976028271317483,
                0.08517062147557736,
                0.08139857447743416,
                0.07860814101099968,
                0.08659347749650478,
                0.07947246384620667,
                0.08203779413700103,
                0.06717222075462341,
                0.082574853977561,
                0.07815874792039394,
                0.07935529689192772,
                0.07827833214700222,
                0.07487845846712589,
                0.06738318757116794,
                0.0729805407166481,
                0.07651397749483585,
                0.07840021773278713,
                0.06937918047904969,
                0.06651225988864899,
                0.06459609283804893,
                0.08292579208016396,
                0.06548812446296215,
                0.0665127301543951,
                0.06953383325338364,
                0.061673700377345084],
 'val_loss': [2.0369311241149903,
              1.9709011137008667,
              1.9836784076690674,
              1.9882496318817138,
              1.9265107006073,
              1.8649197931289674,
              1.9047248699188233,
              1.7695789957046508,
              1.7555222415924072,
              1.7048199138641358,
              1.629403426551819,
              1.6448889556884765,
              1.5720264892578124,
              1.5762370391845704,
              1.4787694248199463,
              1.58886392288208,
              1.2324202653884888,
              1.015370093345642,
              0.9325812507629394,
              0.8752803047180175,
              0.7357996195793152,
              0.8342181217193604,
              0.7015190236091614,
              0.7245643667221069,
              0.6897346259117126,
              0.8141880714416504,
              0.7042673814296723,
              0.6091819674491882,
              0.6880000712394715,
              0.6105192315101624,
              0.6506590530872345,
              0.6248331498146057,
              0.6398728283882141,
              0.7167877215385438,
              0.6503914151668548,
              0.6263428528785706,
              0.6943111898422242,
              0.6449348286151886,
              0.6446483021020889,
              0.6623102923870087,
              0.6661652676582337,
              0.7096001428604126,
              0.6668591962218284,
              0.818317725276947,
              0.6777291301727295,
              0.7006740327119827,
              0.7562240699768067,
              0.7935766897916794,
              0.7086049896240234,
              0.700550547504425,
              0.7745154982566833,
              0.7631533897638321,
              0.7234059594631195,
              0.7252176184177399,
              0.717426248550415,
              0.7217968771457672,
              0.7437931023359299,
              0.7944245104670524,
              0.6777690537929535,
              0.6771936376333236,
              0.7884258711338044,
              0.7138667917490006,
              0.6976681490898132,
              0.7971824180066586,
              0.7529013433098793,
              0.762228721666336,
              0.9143064185142518,
              0.7129817245483399,
              0.8048967419624329,
              0.7020457527935505,
              0.9016426364183426,
              0.8008632425308227,
              0.820520201086998,
              0.7675333526134491,
              0.730688544011116,
              0.7863497843027115,
              0.7796001212358474,
              0.8174777220726013,
              0.8173296003341675,
              0.7515605951309204,
              0.7623056239128113,
              0.8882147315859794,
              0.8727516239881515,
              0.7688094380378723,
              0.7601692723155021,
              0.70678417339921,
              0.8256251266479492,
              0.8863437630161644,
              0.9116222620487213,
              0.9588630675062537,
              0.7670956010341644,
              0.798266951072216,
              1.092771293234825,
              0.7989609157562256,
              0.9653728953659535,
              0.8488177462875843,
              0.9699466258049011,
              0.9536656082630157,
              0.9648754827737808,
              0.8959157596111298]}
